{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T09:15:50.428501Z",
     "start_time": "2018-11-30T09:15:22.405169Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\narendran.thesma\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\narendran.thesma\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "import gensim\n",
    "import re, string\n",
    "import tinysegmenter\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "import pickle\n",
    "import feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T09:17:42.911165Z",
     "start_time": "2018-11-30T09:15:54.869132Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\narendran.thesma\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (20,24,25,27,34,42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>companyName</th>\n",
       "      <th>currency</th>\n",
       "      <th>language</th>\n",
       "      <th>countryName</th>\n",
       "      <th>distributorName</th>\n",
       "      <th>ageGroup</th>\n",
       "      <th>articleId</th>\n",
       "      <th>colors</th>\n",
       "      <th>...</th>\n",
       "      <th>CURRENT_PRICE_IN_EUR_OUTPUT</th>\n",
       "      <th>INITIAL_PRICE_IN_SELECTED_CURRENCY_OUTPUT</th>\n",
       "      <th>CURRENT_PRICE_IN_SELECTED_CURRENCY_OUTPUT</th>\n",
       "      <th>SELECTED_CURRENCY_OUTPUT</th>\n",
       "      <th>PRODUCT_INTRODUCTION_DATE_OUTPUT</th>\n",
       "      <th>DISCOUNTED_SINCE_OUTPUT</th>\n",
       "      <th>PRODUCT_EXIT_DATE_OUTPUT</th>\n",
       "      <th>PRODUCT_DESCRIPTION_OUTPUT</th>\n",
       "      <th>PRODUCT_URL_OUTPUT</th>\n",
       "      <th>IMAGE_SERVER_URL_OUTPUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>03/17/2016</td>\n",
       "      <td>adidas</td>\n",
       "      <td>JPY</td>\n",
       "      <td>ja-JP</td>\n",
       "      <td>jpn</td>\n",
       "      <td>own ecom</td>\n",
       "      <td>adults</td>\n",
       "      <td>AA0647</td>\n",
       "      <td>ホワイト</td>\n",
       "      <td>...</td>\n",
       "      <td>24.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2/29/2016</td>\n",
       "      <td>9/18/2017</td>\n",
       "      <td>11/21/2017</td>\n",
       "      <td>3æ¬ç·ã®ãã¶ã¤ã³ãæ°ãããªã£ãã¬...</td>\n",
       "      <td>https://shop.adidas.jp/products/AA0647/</td>\n",
       "      <td>http://usporamap287.am.adsint.biz/zoomimages/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>03/22/2016</td>\n",
       "      <td>adidas</td>\n",
       "      <td>JPY</td>\n",
       "      <td>ja-JP</td>\n",
       "      <td>jpn</td>\n",
       "      <td>own ecom</td>\n",
       "      <td>adults</td>\n",
       "      <td>AA0647</td>\n",
       "      <td>ホワイト</td>\n",
       "      <td>...</td>\n",
       "      <td>24.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2/29/2016</td>\n",
       "      <td>9/18/2017</td>\n",
       "      <td>11/21/2017</td>\n",
       "      <td>3æ¬ç·ã®ãã¶ã¤ã³ãæ°ãããªã£ãã¬...</td>\n",
       "      <td>https://shop.adidas.jp/products/AA0647/</td>\n",
       "      <td>http://usporamap287.am.adsint.biz/zoomimages/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>03/30/2016</td>\n",
       "      <td>adidas</td>\n",
       "      <td>JPY</td>\n",
       "      <td>ja-JP</td>\n",
       "      <td>jpn</td>\n",
       "      <td>own ecom</td>\n",
       "      <td>adults</td>\n",
       "      <td>AA0647</td>\n",
       "      <td>ホワイト</td>\n",
       "      <td>...</td>\n",
       "      <td>24.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2/29/2016</td>\n",
       "      <td>9/18/2017</td>\n",
       "      <td>11/21/2017</td>\n",
       "      <td>3æ¬ç·ã®ãã¶ã¤ã³ãæ°ãããªã£ãã¬...</td>\n",
       "      <td>https://shop.adidas.jp/products/AA0647/</td>\n",
       "      <td>http://usporamap287.am.adsint.biz/zoomimages/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>04/06/2016</td>\n",
       "      <td>adidas</td>\n",
       "      <td>JPY</td>\n",
       "      <td>ja-JP</td>\n",
       "      <td>jpn</td>\n",
       "      <td>own ecom</td>\n",
       "      <td>adults</td>\n",
       "      <td>AA0647</td>\n",
       "      <td>ホワイト</td>\n",
       "      <td>...</td>\n",
       "      <td>24.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2/29/2016</td>\n",
       "      <td>9/18/2017</td>\n",
       "      <td>11/21/2017</td>\n",
       "      <td>3æ¬ç·ã®ãã¶ã¤ã³ãæ°ãããªã£ãã¬...</td>\n",
       "      <td>https://shop.adidas.jp/products/AA0647/</td>\n",
       "      <td>http://usporamap287.am.adsint.biz/zoomimages/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>04/14/2016</td>\n",
       "      <td>adidas</td>\n",
       "      <td>JPY</td>\n",
       "      <td>ja-JP</td>\n",
       "      <td>jpn</td>\n",
       "      <td>own ecom</td>\n",
       "      <td>adults</td>\n",
       "      <td>AA0647</td>\n",
       "      <td>ホワイト</td>\n",
       "      <td>...</td>\n",
       "      <td>24.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2/29/2016</td>\n",
       "      <td>9/18/2017</td>\n",
       "      <td>11/21/2017</td>\n",
       "      <td>3æ¬ç·ã®ãã¶ã¤ã³ãæ°ãããªã£ãã¬...</td>\n",
       "      <td>https://shop.adidas.jp/products/AA0647/</td>\n",
       "      <td>http://usporamap287.am.adsint.biz/zoomimages/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date companyName currency language countryName  \\\n",
       "0           0  03/17/2016      adidas      JPY    ja-JP         jpn   \n",
       "1           1  03/22/2016      adidas      JPY    ja-JP         jpn   \n",
       "2           2  03/30/2016      adidas      JPY    ja-JP         jpn   \n",
       "3           3  04/06/2016      adidas      JPY    ja-JP         jpn   \n",
       "4           4  04/14/2016      adidas      JPY    ja-JP         jpn   \n",
       "\n",
       "  distributorName ageGroup articleId colors  \\\n",
       "0        own ecom   adults    AA0647   ホワイト   \n",
       "1        own ecom   adults    AA0647   ホワイト   \n",
       "2        own ecom   adults    AA0647   ホワイト   \n",
       "3        own ecom   adults    AA0647   ホワイト   \n",
       "4        own ecom   adults    AA0647   ホワイト   \n",
       "\n",
       "                         ...                          \\\n",
       "0                        ...                           \n",
       "1                        ...                           \n",
       "2                        ...                           \n",
       "3                        ...                           \n",
       "4                        ...                           \n",
       "\n",
       "  CURRENT_PRICE_IN_EUR_OUTPUT  INITIAL_PRICE_IN_SELECTED_CURRENCY_OUTPUT  \\\n",
       "0                        24.3                                       24.3   \n",
       "1                        24.3                                       24.3   \n",
       "2                        24.3                                       24.3   \n",
       "3                        24.3                                       24.3   \n",
       "4                        24.3                                       24.3   \n",
       "\n",
       "   CURRENT_PRICE_IN_SELECTED_CURRENCY_OUTPUT SELECTED_CURRENCY_OUTPUT  \\\n",
       "0                                       24.3                      EUR   \n",
       "1                                       24.3                      EUR   \n",
       "2                                       24.3                      EUR   \n",
       "3                                       24.3                      EUR   \n",
       "4                                       24.3                      EUR   \n",
       "\n",
       "  PRODUCT_INTRODUCTION_DATE_OUTPUT DISCOUNTED_SINCE_OUTPUT  \\\n",
       "0                        2/29/2016               9/18/2017   \n",
       "1                        2/29/2016               9/18/2017   \n",
       "2                        2/29/2016               9/18/2017   \n",
       "3                        2/29/2016               9/18/2017   \n",
       "4                        2/29/2016               9/18/2017   \n",
       "\n",
       "  PRODUCT_EXIT_DATE_OUTPUT                         PRODUCT_DESCRIPTION_OUTPUT  \\\n",
       "0               11/21/2017  3æ¬ç·ã®ãã¶ã¤ã³ãæ°ãããªã£ãã¬...   \n",
       "1               11/21/2017  3æ¬ç·ã®ãã¶ã¤ã³ãæ°ãããªã£ãã¬...   \n",
       "2               11/21/2017  3æ¬ç·ã®ãã¶ã¤ã³ãæ°ãããªã£ãã¬...   \n",
       "3               11/21/2017  3æ¬ç·ã®ãã¶ã¤ã³ãæ°ãããªã£ãã¬...   \n",
       "4               11/21/2017  3æ¬ç·ã®ãã¶ã¤ã³ãæ°ãããªã£ãã¬...   \n",
       "\n",
       "                        PRODUCT_URL_OUTPUT  \\\n",
       "0  https://shop.adidas.jp/products/AA0647/   \n",
       "1  https://shop.adidas.jp/products/AA0647/   \n",
       "2  https://shop.adidas.jp/products/AA0647/   \n",
       "3  https://shop.adidas.jp/products/AA0647/   \n",
       "4  https://shop.adidas.jp/products/AA0647/   \n",
       "\n",
       "                             IMAGE_SERVER_URL_OUTPUT  \n",
       "0  http://usporamap287.am.adsint.biz/zoomimages/1...  \n",
       "1  http://usporamap287.am.adsint.biz/zoomimages/1...  \n",
       "2  http://usporamap287.am.adsint.biz/zoomimages/1...  \n",
       "3  http://usporamap287.am.adsint.biz/zoomimages/1...  \n",
       "4  http://usporamap287.am.adsint.biz/zoomimages/1...  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Merged/JPN-1/data_joined_deu.csv\", encoding='utf-8')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T09:38:54.554075Z",
     "start_time": "2018-11-30T09:38:54.522056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2008008 entries, 0 to 2008007\n",
      "Data columns (total 62 columns):\n",
      "Unnamed: 0                                   int64\n",
      "date                                         object\n",
      "companyName                                  object\n",
      "currency                                     object\n",
      "language                                     object\n",
      "countryName                                  object\n",
      "distributorName                              object\n",
      "ageGroup                                     object\n",
      "articleId                                    object\n",
      "colors                                       object\n",
      "colorGroup                                   object\n",
      "consumerRating                               float64\n",
      "currentPrice                                 float64\n",
      "description                                  object\n",
      "discountedSince                              object\n",
      "division                                     object\n",
      "gender                                       object\n",
      "group                                        object\n",
      "imageUrl                                     object\n",
      "initialPrice                                 float64\n",
      "modelNumber                                  object\n",
      "name4                                        object\n",
      "ped                                          object\n",
      "pid                                          object\n",
      "sportsCategory                               object\n",
      "subBrand                                     object\n",
      "technologies                                 object\n",
      "type                                         object\n",
      "url                                          object\n",
      "key                                          object\n",
      "COMPANY                                      object\n",
      "COUNTRY_OUTPUT                               object\n",
      "DISTRIBUTOR_OUTPUT                           object\n",
      "ARTICLE_ID_OUTPUT                            object\n",
      "MODEL_NUMBER_OUTPUT                          object\n",
      "ARTICLE_NAME_OUTPUT                          object\n",
      "SUBBRAND_OUTPUT                              object\n",
      "SPORTS_CATEGORY_OUTPUT                       object\n",
      "PRODUCT_DIVISION_OUTPUT                      object\n",
      "PRODUCT_GROUP_OUTPUT                         object\n",
      "PRODUCT_TYPE_OUTPUT                          object\n",
      "FRANCHISE_OUTPUT                             object\n",
      "TECHNOLOGIES_OUTPUT                          object\n",
      "COLOUR_GROUP_OUTPUT                          object\n",
      "COLOUR_OUTPUT                                object\n",
      "GENDER_OUTPUT                                object\n",
      "AGE_GROUP_OUTPUT                             object\n",
      "CONSUMER_RATING_OUTPUT                       float64\n",
      "INITIAL_PRICE_IN_LOCAL_CURRENCY_OUTPUT       float64\n",
      "CURRENT_PRICE_IN_LOCAL_CURRENCY_OUTPUT       float64\n",
      "LOCAL_CURRENCY_OUTPUT                        object\n",
      "INITIAL_PRICE_IN_EUR_OUTPUT                  float64\n",
      "CURRENT_PRICE_IN_EUR_OUTPUT                  float64\n",
      "INITIAL_PRICE_IN_SELECTED_CURRENCY_OUTPUT    float64\n",
      "CURRENT_PRICE_IN_SELECTED_CURRENCY_OUTPUT    float64\n",
      "SELECTED_CURRENCY_OUTPUT                     object\n",
      "PRODUCT_INTRODUCTION_DATE_OUTPUT             object\n",
      "DISCOUNTED_SINCE_OUTPUT                      object\n",
      "PRODUCT_EXIT_DATE_OUTPUT                     object\n",
      "PRODUCT_DESCRIPTION_OUTPUT                   object\n",
      "PRODUCT_URL_OUTPUT                           object\n",
      "IMAGE_SERVER_URL_OUTPUT                      object\n",
      "dtypes: float64(10), int64(1), object(51)\n",
      "memory usage: 949.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T09:39:48.049999Z",
     "start_time": "2018-11-30T09:39:40.722700Z"
    }
   },
   "outputs": [],
   "source": [
    "data.date = pd.to_datetime(data.date, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T10:06:16.510944Z",
     "start_time": "2018-11-30T10:06:14.822779Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data[data.date.dt.year > 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T10:06:26.985769Z",
     "start_time": "2018-11-30T10:06:19.527383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-10-15 00:00:00')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(data.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "    :param actual: Array containing the actual target classes\n",
    "    :param predicted: Matrix with class predictions, one probability per class\n",
    "    \"\"\"\n",
    "    # Convert 'actual' to a binary array if it's not already:\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "\n",
    "    clip = np.clip(predicted, eps, 1 - eps)\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip))\n",
    "    return -1.0 / rows * vsota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'date', 'companyName', 'currency', 'language',\n",
       "       'countryName', 'distributorName', 'ageGroup', 'articleId', 'colors',\n",
       "       'colorGroup', 'consumerRating', 'currentPrice', 'description',\n",
       "       'discountedSince', 'division', 'gender', 'group', 'imageUrl',\n",
       "       'initialPrice', 'modelNumber', 'name4', 'ped', 'pid', 'sportsCategory',\n",
       "       'subBrand', 'technologies', 'type', 'url', 'key', 'COMPANY',\n",
       "       'COUNTRY_OUTPUT', 'DISTRIBUTOR_OUTPUT', 'ARTICLE_ID_OUTPUT',\n",
       "       'MODEL_NUMBER_OUTPUT', 'ARTICLE_NAME_OUTPUT', 'SUBBRAND_OUTPUT',\n",
       "       'SPORTS_CATEGORY_OUTPUT', 'PRODUCT_DIVISION_OUTPUT',\n",
       "       'PRODUCT_GROUP_OUTPUT', 'PRODUCT_TYPE_OUTPUT', 'FRANCHISE_OUTPUT',\n",
       "       'TECHNOLOGIES_OUTPUT', 'COLOUR_GROUP_OUTPUT', 'COLOUR_OUTPUT',\n",
       "       'GENDER_OUTPUT', 'AGE_GROUP_OUTPUT', 'CONSUMER_RATING_OUTPUT',\n",
       "       'INITIAL_PRICE_IN_LOCAL_CURRENCY_OUTPUT',\n",
       "       'CURRENT_PRICE_IN_LOCAL_CURRENCY_OUTPUT', 'LOCAL_CURRENCY_OUTPUT',\n",
       "       'INITIAL_PRICE_IN_EUR_OUTPUT', 'CURRENT_PRICE_IN_EUR_OUTPUT',\n",
       "       'INITIAL_PRICE_IN_SELECTED_CURRENCY_OUTPUT',\n",
       "       'CURRENT_PRICE_IN_SELECTED_CURRENCY_OUTPUT', 'SELECTED_CURRENCY_OUTPUT',\n",
       "       'PRODUCT_INTRODUCTION_DATE_OUTPUT', 'DISCOUNTED_SINCE_OUTPUT',\n",
       "       'PRODUCT_EXIT_DATE_OUTPUT', 'PRODUCT_DESCRIPTION_OUTPUT',\n",
       "       'PRODUCT_URL_OUTPUT', 'IMAGE_SERVER_URL_OUTPUT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req = data.loc[:,[\"date\", \"companyName\", \"distributorName\", \"ageGroup\",\"description\", \"division\", \"gender\", \"group\", \"name4\", \"sportsCategory\",\"subBrand\", \"SUBBRAND_OUTPUT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req[\"ID\"] = data_req.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_req = data_req.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_req[\"description\"]  = data_req[\"COMPANY\"] +\" \" + data_req[\"ARTICLE NAME\"] +\" \" + data_req[\"PRODUCT DESCRIPTION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_req = data_req.drop([\"COUNTRY\", \"ARTICLE NAME\", \"PRODUCT DESCRIPTION\", \"PRODUCT URL\"], axis = 1)\n",
    "# data_req.columns = [\"COMPANY\", \"subBrand\", \"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req[[\"companyName\", \"distributorName\", \"ageGroup\",\"description\", \"division\", \"gender\", \"group\",\"name4\", \"sportsCategory\", \"subBrand\"]] = data_req[[\"companyName\", \"distributorName\", \"ageGroup\",\"description\", \"division\", \"gender\", \"group\", \"name4\", \"sportsCategory\", \"subBrand\"]].fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req = data_req.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date               0\n",
       "companyName        0\n",
       "distributorName    0\n",
       "ageGroup           0\n",
       "description        0\n",
       "division           0\n",
       "gender             0\n",
       "group              0\n",
       "name4              0\n",
       "sportsCategory     0\n",
       "subBrand           0\n",
       "SUBBRAND_OUTPUT    0\n",
       "ID                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_req.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(data_req[\"SUBBRAND_OUTPUT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"y_label_enc.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(lbl_enc, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req[[\"companyName\", \"distributorName\", \"ageGroup\", \"division\", \"gender\", \"group\", \"sportsCategory\", \"subBrand\"]] = \\\n",
    "    data_req[[\"companyName\", \"distributorName\", \"ageGroup\", \"division\", \"gender\", \"group\", \"sportsCategory\", \"subBrand\"]].apply(preprocessing.LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_req[\"SUBRAND_OUTPUT_ENC\"] = data_req[[\"SUBBRAND_OUTPUT\"]].apply(preprocessing.LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [\"companyName\", \"distributorName\", \"ageGroup\",\"description\", \"division\", \"gender\", \"group\",\"name4\", \"sportsCategory\", \"subBrand\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "performance       870429\n",
       "sport inspired    648380\n",
       "Name: SUBBRAND_OUTPUT, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_req[\"SUBBRAND_OUTPUT\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req[\"SUBRAND_OUTPUT_ENC\"] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"SUBRAND_OUTPUT_ENC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>companyName</th>\n",
       "      <th>distributorName</th>\n",
       "      <th>ageGroup</th>\n",
       "      <th>description</th>\n",
       "      <th>division</th>\n",
       "      <th>gender</th>\n",
       "      <th>group</th>\n",
       "      <th>name4</th>\n",
       "      <th>sportsCategory</th>\n",
       "      <th>subBrand</th>\n",
       "      <th>SUBBRAND_OUTPUT</th>\n",
       "      <th>ID</th>\n",
       "      <th>SUBRAND_OUTPUT_ENC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>489199</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>幅の広めのラージサイズ。長時間の着用でも疲れを感じさせない人間工学から考えられたテンプル形状...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>サングラス a164 6050 adivista l</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>performance</td>\n",
       "      <td>489199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489200</th>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>幅の広めのラージサイズ。長時間の着用でも疲れを感じさせない人間工学から考えられたテンプル形状...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>サングラス a164 6050 adivista l</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>performance</td>\n",
       "      <td>489200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489201</th>\n",
       "      <td>2017-01-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>幅の広めのラージサイズ。長時間の着用でも疲れを感じさせない人間工学から考えられたテンプル形状...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>サングラス a164 6050 adivista l</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>performance</td>\n",
       "      <td>489201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489202</th>\n",
       "      <td>2017-01-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>幅の広めのラージサイズ。長時間の着用でも疲れを感じさせない人間工学から考えられたテンプル形状...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>サングラス a164 6050 adivista l</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>performance</td>\n",
       "      <td>489202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489203</th>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>幅の広めのラージサイズ。長時間の着用でも疲れを感じさせない人間工学から考えられたテンプル形状...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>サングラス a164 6050 adivista l</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>performance</td>\n",
       "      <td>489203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  companyName  distributorName  ageGroup  \\\n",
       "489199  2017-01-02            0                0         0   \n",
       "489200  2017-01-11            0                0         0   \n",
       "489201  2017-01-17            0                0         0   \n",
       "489202  2017-01-25            0                0         0   \n",
       "489203  2017-01-30            0                0         0   \n",
       "\n",
       "                                              description  division  gender  \\\n",
       "489199  幅の広めのラージサイズ。長時間の着用でも疲れを感じさせない人間工学から考えられたテンプル形状...         1       1   \n",
       "489200  幅の広めのラージサイズ。長時間の着用でも疲れを感じさせない人間工学から考えられたテンプル形状...         1       1   \n",
       "489201  幅の広めのラージサイズ。長時間の着用でも疲れを感じさせない人間工学から考えられたテンプル形状...         1       1   \n",
       "489202  幅の広めのラージサイズ。長時間の着用でも疲れを感じさせない人間工学から考えられたテンプル形状...         1       1   \n",
       "489203  幅の広めのラージサイズ。長時間の着用でも疲れを感じさせない人間工学から考えられたテンプル形状...         1       1   \n",
       "\n",
       "        group                       name4  sportsCategory  subBrand  \\\n",
       "489199     26  サングラス a164 6050 adivista l              12         5   \n",
       "489200     26  サングラス a164 6050 adivista l              12         5   \n",
       "489201     26  サングラス a164 6050 adivista l              21         5   \n",
       "489202     26  サングラス a164 6050 adivista l              12         5   \n",
       "489203     26  サングラス a164 6050 adivista l              12         5   \n",
       "\n",
       "       SUBBRAND_OUTPUT      ID  SUBRAND_OUTPUT_ENC  \n",
       "489199     performance  489199                   0  \n",
       "489200     performance  489200                   0  \n",
       "489201     performance  489201                   0  \n",
       "489202     performance  489202                   0  \n",
       "489203     performance  489203                   0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_req.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xtrain, xvalid, ytrain, yvalid = train_test_split(data_req[X], y, \n",
    "#                                                   stratify=y, \n",
    "#                                                   random_state=42, \n",
    "#                                                   test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_req[data_req.date < \"2018-05-01\"]\n",
    "valid = data_req[(data_req.date >= \"2018-05-01\") & (data_req.date <= \"2018-07-31\")]\n",
    "test = data_req[data_req.date >= \"2018-08-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feather.write_dataframe(train, \"train_japan_input_output\")\n",
    "feather.write_dataframe(valid, \"valid_japan_input_output\")\n",
    "feather.write_dataframe(test, \"test_japan_input_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2018-04-23', '2018-05-03', '2018-07-31', '2018-08-08')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(train.date), min(valid.date), max(valid.date), min(test.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = train[X]\n",
    "xvalid = valid[X]\n",
    "xtest = test[X]\n",
    "\n",
    "ytrain = train[y]\n",
    "yvalid = valid[y]\n",
    "ytest = test[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿|¡§£₤‘’])')\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data, data_req, train, test, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train = [tokenize(x) for x in xtrain.description]\n",
    "texts_valid = [tokenize(x) for x in xvalid.description]\n",
    "texts_test = [tokenize(x) for x in xtest.description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "del xtrain, xvalid, xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Use local data file or download from GitHub\n",
    "#docker_data_path = \"stopwords.csv\"\n",
    "docker_data_path = \"Japanese_SW_H2O.csv\"\n",
    "\n",
    "STOP_WORDS = pd.read_csv(docker_data_path, header = 0)\n",
    "STOP_WORDS = list(STOP_WORDS['STOP_WORD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = tinysegmenter.TinySegmenter()\n",
    "tokenized_text_train = [segmenter.tokenize(x) for x in texts_train]\n",
    "tokenized_text_valid = [segmenter.tokenize(x) for x in texts_valid]\n",
    "tokenized_text_test = [segmenter.tokenize(x) for x in texts_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text_train = [w for w in tokenized_text_train if not w in STOP_WORDS]\n",
    "tokenized_text_valid = [w for w in tokenized_text_valid if not w in STOP_WORDS]\n",
    "tokenized_text_test = [w for w in tokenized_text_test if not w in STOP_WORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "del texts_train, texts_valid, texts_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"train_tokenizer_japan.pkl\"\n",
    "# filehandler = open(filename, 'wb')\n",
    "# pickle.dump(tokenized_text_train, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"train_tokenizer_japan.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(tokenized_text_train, filehandler)\n",
    "\n",
    "filename = \"valid_tokenizer_japan.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(tokenized_text_valid, filehandler)\n",
    "\n",
    "filename = \"test_tokenizer_japan.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(tokenized_text_test, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_pi1 = open('train_tokenizer_japan.pkl', 'rb')\n",
    "# chk = pickle.load(file_pi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_pi1 = open('train_tokenizer_japan.pkl', 'rb')\n",
    "# tokenized_text_train = pickle.load(file_pi1)\n",
    "\n",
    "# file_pi2 = open('valid_tokenizer_japan.pkl', 'rb')\n",
    "# tokenized_text_valid = pickle.load(file_pi2)\n",
    "\n",
    "# file_pi3 = open('test_tokenizer_japan.pkl', 'rb')\n",
    "# tokenized_text_test = pickle.load(file_pi3)\n",
    "\n",
    "train = feather.read_dataframe(\"train_japan_input_output\")\n",
    "valid = feather.read_dataframe(\"valid_japan_input_output\")\n",
    "test = feather.read_dataframe(\"test_japan_input_output\")\n",
    "\n",
    "X = [\"companyName\", \"distributorName\", \"ageGroup\",\"description\", \"division\", \"gender\", \"group\",\"name4\", \"sportsCategory\", \"subBrand\"]\n",
    "y = \"SUBRAND_OUTPUT_ENC\"\n",
    "\n",
    "xtrain = train[X]\n",
    "xvalid = valid[X]\n",
    "xtest = test[X]\n",
    "\n",
    "ytrain = train[y]\n",
    "yvalid = valid[y]\n",
    "ytest = test[y]\n",
    "\n",
    "del train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_token_train = [' '.join(x) for x in tokenized_text_train]\n",
    "joined_token_valid = [' '.join(x) for x in tokenized_text_valid]\n",
    "joined_token_test = [' '.join(x) for x in tokenized_text_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tokenized_text_train,tokenized_text_valid, tokenized_text_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"joined_word_model.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(joined_token_train, filehandler)\n",
    "\n",
    "filename = \"joined_token_valid.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(joined_token_valid, filehandler)\n",
    "\n",
    "filename = \"joined_token_test.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(joined_token_test, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pi1 = open('joined_token_train.pkl', 'rb')\n",
    "joined_token_train = pickle.load(file_pi1)\n",
    "\n",
    "file_pi2 = open('joined_token_valid.pkl', 'rb')\n",
    "joined_token_valid = pickle.load(file_pi2)\n",
    "\n",
    "file_pi3 = open('joined_token_test.pkl', 'rb')\n",
    "joined_token_test = pickle.load(file_pi3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using keras tokenizer here\n",
    "token = text.Tokenizer(num_words=None)\n",
    "max_len = 300\n",
    "\n",
    "token.fit_on_texts(joined_token_train + joined_token_valid + joined_token_test)\n",
    "xtrain_seq = token.texts_to_sequences(joined_token_train)\n",
    "xvalid_seq = token.texts_to_sequences(joined_token_valid)\n",
    "xtest_seq = token.texts_to_sequences(joined_token_test)\n",
    "\n",
    "# zero pad the sequences\n",
    "xtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\n",
    "xvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\n",
    "xtest_pad = sequence.pad_sequences(xtest_seq, maxlen=max_len)\n",
    "\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"japan_xtrain_pad.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(xtrain_pad, filehandler)\n",
    "\n",
    "filename = \"japan_xvalid_pad.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(xvalid_pad, filehandler)\n",
    "\n",
    "filename = \"japan_xtest_pad.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(xtest_pad, filehandler)\n",
    "\n",
    "filename = \"japan_word_index.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(word_index, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute\n",
    "file_pi1 = open('japan_word_index.pkl', 'rb')\n",
    "word_index = pickle.load(file_pi1)\n",
    "\n",
    "file_pi1 = open('japan_xtrain_pad.pkl', 'rb')\n",
    "xtrain_pad = pickle.load(file_pi1)\n",
    "\n",
    "file_pi1 = open('japan_xvalid_pad.pkl', 'rb')\n",
    "xvalid_pad = pickle.load(file_pi1)\n",
    "\n",
    "file_pi1 = open('japan_xtest_pad.pkl', 'rb')\n",
    "xtest_pad = pickle.load(file_pi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_keras_words = list(token.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "keras_tokenised_words = [text_to_word_sequence(x, lower=False) for x in (joined_token_train + joined_token_valid + joined_token_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "del joined_token_train, joined_token_test, joined_token_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model = gensim.models.Word2Vec(keras_tokenised_words, size=300, min_count=1, window=5, iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del keras_tokenised_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"joined_word_model.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(word_model, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute\n",
    "file_pi1 = open('joined_word_model.pkl', 'rb')\n",
    "word_model = pickle.load(file_pi1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Everything together here. MY REFERENCE\n",
    "\n",
    "train = feather.read_dataframe(\"train_japan_input_output\")\n",
    "valid = feather.read_dataframe(\"valid_japan_input_output\")\n",
    "test = feather.read_dataframe(\"test_japan_input_output\")\n",
    "\n",
    "X = [\"companyName\", \"distributorName\", \"ageGroup\",\"description\", \"division\", \"gender\", \"group\",\"name4\", \"sportsCategory\", \"subBrand\"]\n",
    "y = \"SUBRAND_OUTPUT_ENC\"\n",
    "\n",
    "xtrain = train[X]\n",
    "xvalid = valid[X]\n",
    "xtest = test[X]\n",
    "\n",
    "ytrain = train[y]\n",
    "yvalid = valid[y]\n",
    "ytest = test[y]\n",
    "\n",
    "del train, valid, test\n",
    "\n",
    "\n",
    "file_pi1 = open('japan_word_index.pkl', 'rb')\n",
    "word_index = pickle.load(file_pi1)\n",
    "\n",
    "file_pi1 = open('japan_xtrain_pad.pkl', 'rb')\n",
    "xtrain_pad = pickle.load(file_pi1)\n",
    "\n",
    "file_pi1 = open('japan_xvalid_pad.pkl', 'rb')\n",
    "xvalid_pad = pickle.load(file_pi1)\n",
    "\n",
    "file_pi1 = open('japan_xtest_pad.pkl', 'rb')\n",
    "xtest_pad = pickle.load(file_pi1)\n",
    "\n",
    "file_pi1 = open('joined_word_model.pkl', 'rb')\n",
    "word_model = pickle.load(file_pi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 35613/35613 [00:00<00:00, 227953.46it/s]\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = word_model.wv[word]\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-2.01717353, -0.99233973, -1.08852887, ..., -3.06032372,\n",
       "         1.49680293, -1.42993021],\n",
       "       [-0.50516093, -0.59006751, -1.52408195, ..., -1.79377186,\n",
       "         0.24416398, -3.26893067],\n",
       "       ...,\n",
       "       [ 0.04895103, -0.03756456, -0.01938329, ..., -0.00814213,\n",
       "        -0.04584658, -0.08762853],\n",
       "       [ 0.00822348, -0.0179678 ,  0.033421  , ..., -0.03149183,\n",
       "        -0.02039536,  0.0701666 ],\n",
       "       [ 0.05051522,  0.02162825, -0.04719217, ..., -0.00573608,\n",
       "         0.04827156, -0.06946177]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: meant to receive sequences of 300 integers\n",
    "main_input = Input(shape=(300,), name='main_input')\n",
    "max_len = 300\n",
    "# This embedding layer will encode the input sequence\n",
    "# into a sequence of dense 300-dimensional vectors.\n",
    "x = Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False)(main_input)\n",
    "\n",
    "x = SpatialDropout1D(0.3)(x)\n",
    "\n",
    "\n",
    "# A LSTM will transform the vector sequence into a single vector,\n",
    "# containing information about the entire sequence\n",
    "lstm_out = LSTM(100, dropout=0.3, recurrent_dropout=0.3)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_input_1 = Input((1,), name='aux_input_1')\n",
    "auxiliary_input_2 = Input((1,), name='aux_input_2')\n",
    "auxiliary_input_3 = Input((1,), name='aux_input_3')\n",
    "auxiliary_input_4 = Input((1,), name='aux_input_4')\n",
    "auxiliary_input_5 = Input((1,), name='aux_input_5')\n",
    "auxiliary_input_6 = Input((1,), name='aux_input_6')\n",
    "auxiliary_input_7 = Input((1,), name='aux_input_7')\n",
    "auxiliary_input_8 = Input((1,), name='aux_input_8')\n",
    "auxiliary_input_9 = Input((1,), name='aux_input_9')\n",
    "\n",
    "x = keras.layers.concatenate([lstm_out, auxiliary_input_1, auxiliary_input_2, auxiliary_input_3, auxiliary_input_4, \n",
    "                             auxiliary_input_5, auxiliary_input_6, auxiliary_input_7, \n",
    "                             auxiliary_input_8, auxiliary_input_9], axis = 1)\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(1024, activation='tanh')(x)\n",
    "x = Dropout(0.7)(x)\n",
    "x = Dense(1024, activation='tanh')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='tanh')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "# x = Dense(256, activation='relu')(x)\n",
    "# x = Dropout(0.4)(x)\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# x = Dropout(0.3)(x)\n",
    "\n",
    "# Output softmax layer\n",
    "main_output = Dense(2, activation='softmax', name='main_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[main_input, auxiliary_input_1, auxiliary_input_2, auxiliary_input_3, auxiliary_input_4, auxiliary_input_5, auxiliary_input_6, auxiliary_input_7, auxiliary_input_8, auxiliary_input_9], outputs=main_output)\n",
    "# rmsprop = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy', optimizer= 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to binarize the labels for the neural net\n",
    "ytrain_enc = np_utils.to_categorical(ytrain)\n",
    "yvalid_enc = np_utils.to_categorical(yvalid)\n",
    "ytest_enc = np_utils.to_categorical(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "xtrain_companyName = np.array(xtrain.companyName)\n",
    "xtrain_companyName = le.fit_transform(xtrain_companyName)\n",
    "# xtrain_companyName = (xtrain_companyName - xtrain_companyName.mean())/xtrain_companyName.std()\n",
    "\n",
    "xtrain_distributorName = np.array(xtrain.distributorName)\n",
    "xtrain_distributorName = le.fit_transform(xtrain_distributorName)\n",
    "# xtrain_distributorName = (xtrain_distributorName - xtrain_distributorName.mean())/xtrain_distributorName.std()\n",
    "\n",
    "xtrain_ageGroup = np.array(xtrain.ageGroup)\n",
    "xtrain_ageGroup = le.fit_transform(xtrain_ageGroup)\n",
    "# xtrain_ageGroup = (xtrain_ageGroup - xtrain_ageGroup.mean())/xtrain_ageGroup.std()\n",
    "\n",
    "xtrain_division = np.array(xtrain.division)\n",
    "xtrain_division = le.fit_transform(xtrain_division)\n",
    "# xtrain_division = (xtrain_division - xtrain_division.mean())/xtrain_division.std()\n",
    "\n",
    "xtrain_gender = np.array(xtrain.gender)\n",
    "xtrain_gender = le.fit_transform(xtrain_gender)\n",
    "# xtrain_gender = (xtrain_gender - xtrain_gender.mean())/xtrain_gender.std()\n",
    "\n",
    "xtrain_group = np.array(xtrain.group)\n",
    "xtrain_group = le.fit_transform(xtrain_group)\n",
    "# xtrain_group = (xtrain_group - xtrain_group.mean())/xtrain_group.std()\n",
    "\n",
    "xtrain_name4 = np.array(xtrain.name4)\n",
    "xtrain_name4 = le.fit_transform(xtrain_name4)\n",
    "# xtrain_name4 = (xtrain_name4 - xtrain_name4.mean())/xtrain_name4.std()\n",
    "\n",
    "\n",
    "xtrain_sportsCategory = np.array(xtrain.sportsCategory)\n",
    "xtrain_sportsCategory = le.fit_transform(xtrain_sportsCategory)\n",
    "# xtrain_sportsCategory = (xtrain_sportsCategory - xtrain_sportsCategory.mean())/xtrain_sportsCategory.std()\n",
    "\n",
    "\n",
    "xtrain_subBrand = np.array(xtrain.subBrand)\n",
    "xtrain_subBrand = le.fit_transform(xtrain_subBrand)\n",
    "# xtrain_subBrand = (xtrain_subBrand - xtrain_subBrand.mean())/xtrain_subBrand.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvalid_companyName = np.array(xvalid.companyName)\n",
    "xvalid_companyName = le.fit_transform(xvalid_companyName)\n",
    "# xvalid_companyName = (xvalid_companyName - xvalid_companyName.mean())/xvalid_companyName.std()\n",
    "\n",
    "xvalid_distributorName = np.array(xvalid.distributorName)\n",
    "xvalid_distributorName = le.fit_transform(xvalid_distributorName)\n",
    "# xvalid_distributorName = (xvalid_distributorName - xvalid_distributorName.mean())/xvalid_distributorName.std()\n",
    "\n",
    "xvalid_ageGroup = np.array(xvalid.ageGroup)\n",
    "xvalid_ageGroup = le.fit_transform(xvalid_ageGroup)\n",
    "# xvalid_ageGroup = (xvalid_ageGroup - xvalid_ageGroup.mean())/xvalid_ageGroup.std()\n",
    "\n",
    "xvalid_division = np.array(xvalid.division)\n",
    "xvalid_division = le.fit_transform(xvalid_division)\n",
    "# xvalid_division = (xvalid_division - xvalid_division.mean())/xvalid_division.std()\n",
    "\n",
    "xvalid_gender = np.array(xvalid.gender)\n",
    "xvalid_gender = le.fit_transform(xvalid_gender)\n",
    "# xvalid_gender = (xvalid_gender - xvalid_gender.mean())/xvalid_gender.std()\n",
    "\n",
    "xvalid_group = np.array(xvalid.group)\n",
    "xvalid_group = le.fit_transform(xvalid_group)\n",
    "# xvalid_group = (xvalid_group - xvalid_group.mean())/xvalid_group.std()\n",
    "\n",
    "xvalid_name4 = np.array(xvalid.name4)\n",
    "xvalid_name4 = le.fit_transform(xvalid_name4)\n",
    "# xvalid_name4 = (xvalid_name4 - xvalid_name4.mean())/xvalid_name4.std()\n",
    "\n",
    "xvalid_sportsCategory = np.array(xvalid.sportsCategory)\n",
    "xvalid_sportsCategory = le.fit_transform(xvalid_sportsCategory)\n",
    "# xvalid_sportsCategory = (xvalid_sportsCategory - xvalid_sportsCategory.mean())/xvalid_sportsCategory.std()\n",
    "\n",
    "xvalid_subBrand = np.array(xvalid.subBrand)\n",
    "xvalid_subBrand = le.fit_transform(xvalid_subBrand)\n",
    "# xvalid_subBrand = (xvalid_subBrand - xvalid_subBrand.mean())/xvalid_subBrand.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_companyName = np.array(xtest.companyName)\n",
    "xtest_companyName = le.fit_transform(xtest_companyName)\n",
    "# xtest_companyName = (xtest_companyName - xtest_companyName.mean())/xtest_companyName.std()\n",
    "\n",
    "xtest_distributorName = np.array(xtest.distributorName)\n",
    "xtest_distributorName = le.fit_transform(xtest_distributorName)\n",
    "# xtest_distributorName = (xtest_distributorName - xtest_distributorName.mean())/xtest_distributorName.std()\n",
    "\n",
    "xtest_ageGroup = np.array(xtest.ageGroup)\n",
    "xtest_ageGroup = le.fit_transform(xtest_ageGroup)\n",
    "# xtest_ageGroup = (xtest_ageGroup - xtest_ageGroup.mean())/xtest_ageGroup.std()\n",
    "\n",
    "xtest_division = np.array(xtest.division)\n",
    "xtest_division = le.fit_transform(xtest_division)\n",
    "# xtest_division = (xtest_division - xtest_division.mean())/xtest_division.std()\n",
    "\n",
    "xtest_gender = np.array(xtest.gender)\n",
    "xtest_gender = le.fit_transform(xtest_gender)\n",
    "# xtest_gender = (xtest_gender - xtest_gender.mean())/xtest_gender.std()\n",
    "\n",
    "xtest_group = np.array(xtest.group)\n",
    "xtest_group = le.fit_transform(xtest_group)\n",
    "# xtest_group = (xtest_group - xtest_group.mean())/xtest_group.std()\n",
    "\n",
    "\n",
    "xtest_name4 = np.array(xtest.name4)\n",
    "xtest_name4 = le.fit_transform(xtest_name4)\n",
    "# xtest_name4 = (xtest_name4 - xtest_name4.mean())/xtest_name4.std()\n",
    "\n",
    "xtest_sportsCategory = np.array(xtest.sportsCategory)\n",
    "xtest_sportsCategory = le.fit_transform(xtest_sportsCategory)\n",
    "# xtest_sportsCategory = (xtest_sportsCategory - xtest_sportsCategory.mean())/xtest_sportsCategory.std()\n",
    "\n",
    "xtest_subBrand = np.array(xtest.subBrand)\n",
    "xtest_subBrand = le.fit_transform(xtest_subBrand)\n",
    "# xtest_subBrand = (xtest_subBrand - xtest_subBrand.mean())/xtest_subBrand.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 300, 300)     10684200    main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 300, 300)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 100)          160400      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "aux_input_1 (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aux_input_2 (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aux_input_3 (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aux_input_4 (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aux_input_5 (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aux_input_6 (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aux_input_7 (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aux_input_8 (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aux_input_9 (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 109)          0           lstm_1[0][0]                     \n",
      "                                                                 aux_input_1[0][0]                \n",
      "                                                                 aux_input_2[0][0]                \n",
      "                                                                 aux_input_3[0][0]                \n",
      "                                                                 aux_input_4[0][0]                \n",
      "                                                                 aux_input_5[0][0]                \n",
      "                                                                 aux_input_6[0][0]                \n",
      "                                                                 aux_input_7[0][0]                \n",
      "                                                                 aux_input_8[0][0]                \n",
      "                                                                 aux_input_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         112640      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1024)         1049600     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024)         0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 512)          524800      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 512)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 2)            1026        dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 12,532,666\n",
      "Trainable params: 1,848,466\n",
      "Non-trainable params: 10,684,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1125047 samples, validate on 222889 samples\n",
      "Epoch 1/5\n",
      " 318464/1125047 [=======>......................] - ETA: 56:35 - loss: 0.94 - ETA: 38:41 - loss: 1.52 - ETA: 32:43 - loss: 1.66 - ETA: 29:43 - loss: 1.50 - ETA: 27:54 - loss: 1.47 - ETA: 26:41 - loss: 1.43 - ETA: 25:50 - loss: 1.35 - ETA: 25:10 - loss: 1.33 - ETA: 24:39 - loss: 1.29 - ETA: 24:12 - loss: 1.25 - ETA: 23:50 - loss: 1.24 - ETA: 23:33 - loss: 1.22 - ETA: 23:20 - loss: 1.19 - ETA: 23:07 - loss: 1.18 - ETA: 22:58 - loss: 1.16 - ETA: 22:50 - loss: 1.14 - ETA: 22:44 - loss: 1.13 - ETA: 22:36 - loss: 1.12 - ETA: 22:30 - loss: 1.11 - ETA: 22:25 - loss: 1.09 - ETA: 22:17 - loss: 1.08 - ETA: 22:10 - loss: 1.07 - ETA: 22:08 - loss: 1.06 - ETA: 22:06 - loss: 1.05 - ETA: 22:04 - loss: 1.05 - ETA: 22:03 - loss: 1.04 - ETA: 21:58 - loss: 1.03 - ETA: 21:54 - loss: 1.02 - ETA: 21:49 - loss: 1.02 - ETA: 21:45 - loss: 1.01 - ETA: 21:42 - loss: 1.01 - ETA: 21:38 - loss: 1.00 - ETA: 21:34 - loss: 0.99 - ETA: 21:33 - loss: 0.99 - ETA: 21:32 - loss: 0.99 - ETA: 21:30 - loss: 0.98 - ETA: 21:29 - loss: 0.98 - ETA: 21:28 - loss: 0.97 - ETA: 21:27 - loss: 0.97 - ETA: 21:26 - loss: 0.96 - ETA: 21:24 - loss: 0.96 - ETA: 21:21 - loss: 0.96 - ETA: 21:18 - loss: 0.95 - ETA: 21:15 - loss: 0.95 - ETA: 21:12 - loss: 0.95 - ETA: 21:10 - loss: 0.95 - ETA: 21:08 - loss: 0.94 - ETA: 21:06 - loss: 0.94 - ETA: 21:03 - loss: 0.94 - ETA: 21:01 - loss: 0.93 - ETA: 20:58 - loss: 0.93 - ETA: 20:56 - loss: 0.93 - ETA: 20:54 - loss: 0.93 - ETA: 20:52 - loss: 0.92 - ETA: 20:49 - loss: 0.92 - ETA: 20:48 - loss: 0.92 - ETA: 20:46 - loss: 0.92 - ETA: 20:43 - loss: 0.92 - ETA: 20:42 - loss: 0.92 - ETA: 20:40 - loss: 0.91 - ETA: 20:39 - loss: 0.91 - ETA: 20:37 - loss: 0.91 - ETA: 20:35 - loss: 0.91 - ETA: 20:33 - loss: 0.91 - ETA: 20:31 - loss: 0.90 - ETA: 20:30 - loss: 0.90 - ETA: 20:28 - loss: 0.90 - ETA: 20:26 - loss: 0.90 - ETA: 20:25 - loss: 0.90 - ETA: 20:23 - loss: 0.90 - ETA: 20:21 - loss: 0.89 - ETA: 20:19 - loss: 0.89 - ETA: 20:18 - loss: 0.89 - ETA: 20:16 - loss: 0.89 - ETA: 20:15 - loss: 0.89 - ETA: 20:14 - loss: 0.89 - ETA: 20:13 - loss: 0.89 - ETA: 20:11 - loss: 0.88 - ETA: 20:09 - loss: 0.88 - ETA: 20:07 - loss: 0.88 - ETA: 20:05 - loss: 0.88 - ETA: 20:04 - loss: 0.88 - ETA: 20:02 - loss: 0.88 - ETA: 20:01 - loss: 0.88 - ETA: 20:00 - loss: 0.87 - ETA: 19:58 - loss: 0.87 - ETA: 19:56 - loss: 0.87 - ETA: 19:55 - loss: 0.87 - ETA: 19:53 - loss: 0.87 - ETA: 19:52 - loss: 0.87 - ETA: 19:50 - loss: 0.87 - ETA: 19:49 - loss: 0.87 - ETA: 19:48 - loss: 0.87 - ETA: 19:46 - loss: 0.87 - ETA: 19:45 - loss: 0.86 - ETA: 19:44 - loss: 0.86 - ETA: 19:42 - loss: 0.86 - ETA: 19:41 - loss: 0.86 - ETA: 19:39 - loss: 0.86 - ETA: 19:37 - loss: 0.86 - ETA: 19:36 - loss: 0.86 - ETA: 19:34 - loss: 0.86 - ETA: 19:33 - loss: 0.86 - ETA: 19:32 - loss: 0.86 - ETA: 19:31 - loss: 0.86 - ETA: 19:30 - loss: 0.86 - ETA: 19:29 - loss: 0.85 - ETA: 19:27 - loss: 0.85 - ETA: 19:26 - loss: 0.85 - ETA: 19:25 - loss: 0.85 - ETA: 19:25 - loss: 0.85 - ETA: 19:24 - loss: 0.85 - ETA: 19:23 - loss: 0.85 - ETA: 19:21 - loss: 0.85 - ETA: 19:20 - loss: 0.85 - ETA: 19:19 - loss: 0.85 - ETA: 19:17 - loss: 0.85 - ETA: 19:15 - loss: 0.85 - ETA: 19:15 - loss: 0.85 - ETA: 19:13 - loss: 0.84 - ETA: 19:12 - loss: 0.84 - ETA: 19:11 - loss: 0.84 - ETA: 19:11 - loss: 0.84 - ETA: 19:10 - loss: 0.84 - ETA: 19:09 - loss: 0.84 - ETA: 19:07 - loss: 0.84 - ETA: 19:06 - loss: 0.84 - ETA: 19:04 - loss: 0.84 - ETA: 19:03 - loss: 0.84 - ETA: 19:01 - loss: 0.84 - ETA: 19:00 - loss: 0.84 - ETA: 18:58 - loss: 0.84 - ETA: 18:57 - loss: 0.84 - ETA: 18:55 - loss: 0.84 - ETA: 18:54 - loss: 0.83 - ETA: 18:52 - loss: 0.83 - ETA: 18:51 - loss: 0.83 - ETA: 18:49 - loss: 0.83 - ETA: 18:48 - loss: 0.83 - ETA: 18:48 - loss: 0.83 - ETA: 18:47 - loss: 0.83 - ETA: 18:45 - loss: 0.83 - ETA: 18:44 - loss: 0.83 - ETA: 18:44 - loss: 0.83 - ETA: 18:42 - loss: 0.83 - ETA: 18:41 - loss: 0.83 - ETA: 18:39 - loss: 0.83 - ETA: 18:38 - loss: 0.83 - ETA: 18:36 - loss: 0.83 - ETA: 18:35 - loss: 0.83 - ETA: 18:33 - loss: 0.82 - ETA: 18:32 - loss: 0.82 - ETA: 18:30 - loss: 0.82 - ETA: 18:29 - loss: 0.82 - ETA: 18:27 - loss: 0.82 - ETA: 18:26 - loss: 0.82 - ETA: 18:24 - loss: 0.82 - ETA: 18:23 - loss: 0.82 - ETA: 18:21 - loss: 0.82 - ETA: 18:20 - loss: 0.82 - ETA: 18:19 - loss: 0.82 - ETA: 18:18 - loss: 0.82 - ETA: 18:16 - loss: 0.82 - ETA: 18:15 - loss: 0.82 - ETA: 18:14 - loss: 0.82 - ETA: 18:12 - loss: 0.82 - ETA: 18:11 - loss: 0.82 - ETA: 18:10 - loss: 0.82 - ETA: 18:09 - loss: 0.82 - ETA: 18:07 - loss: 0.82 - ETA: 18:06 - loss: 0.82 - ETA: 18:05 - loss: 0.81 - ETA: 18:03 - loss: 0.81 - ETA: 18:02 - loss: 0.81 - ETA: 18:01 - loss: 0.81 - ETA: 18:00 - loss: 0.81 - ETA: 17:58 - loss: 0.81 - ETA: 17:57 - loss: 0.81 - ETA: 17:56 - loss: 0.81 - ETA: 17:54 - loss: 0.81 - ETA: 17:53 - loss: 0.81 - ETA: 17:52 - loss: 0.81 - ETA: 17:51 - loss: 0.81 - ETA: 17:50 - loss: 0.81 - ETA: 17:49 - loss: 0.81 - ETA: 17:48 - loss: 0.81 - ETA: 17:47 - loss: 0.81 - ETA: 17:46 - loss: 0.81 - ETA: 17:45 - loss: 0.81 - ETA: 17:44 - loss: 0.81 - ETA: 17:43 - loss: 0.80 - ETA: 17:41 - loss: 0.80 - ETA: 17:40 - loss: 0.80 - ETA: 17:39 - loss: 0.80 - ETA: 17:37 - loss: 0.80 - ETA: 17:36 - loss: 0.80 - ETA: 17:35 - loss: 0.80 - ETA: 17:34 - loss: 0.80 - ETA: 17:33 - loss: 0.80 - ETA: 17:31 - loss: 0.80 - ETA: 17:30 - loss: 0.80 - ETA: 17:29 - loss: 0.80 - ETA: 17:28 - loss: 0.80 - ETA: 17:27 - loss: 0.80 - ETA: 17:25 - loss: 0.80 - ETA: 17:24 - loss: 0.80 - ETA: 17:23 - loss: 0.80 - ETA: 17:22 - loss: 0.80 - ETA: 17:20 - loss: 0.80 - ETA: 17:19 - loss: 0.80 - ETA: 17:18 - loss: 0.80 - ETA: 17:17 - loss: 0.80 - ETA: 17:15 - loss: 0.80 - ETA: 17:14 - loss: 0.79 - ETA: 17:13 - loss: 0.79 - ETA: 17:12 - loss: 0.79 - ETA: 17:10 - loss: 0.79 - ETA: 17:09 - loss: 0.79 - ETA: 17:08 - loss: 0.79 - ETA: 17:07 - loss: 0.79 - ETA: 17:05 - loss: 0.79 - ETA: 17:04 - loss: 0.79 - ETA: 17:03 - loss: 0.79 - ETA: 17:02 - loss: 0.79 - ETA: 17:01 - loss: 0.79 - ETA: 17:00 - loss: 0.79 - ETA: 16:59 - loss: 0.79 - ETA: 16:57 - loss: 0.79 - ETA: 16:56 - loss: 0.79 - ETA: 16:55 - loss: 0.79 - ETA: 16:54 - loss: 0.79 - ETA: 16:53 - loss: 0.79 - ETA: 16:51 - loss: 0.79 - ETA: 16:50 - loss: 0.79 - ETA: 16:49 - loss: 0.79 - ETA: 16:48 - loss: 0.79 - ETA: 16:47 - loss: 0.79 - ETA: 16:45 - loss: 0.79 - ETA: 16:44 - loss: 0.79 - ETA: 16:43 - loss: 0.78 - ETA: 16:42 - loss: 0.78 - ETA: 16:40 - loss: 0.78 - ETA: 16:39 - loss: 0.78 - ETA: 16:38 - loss: 0.78 - ETA: 16:37 - loss: 0.78 - ETA: 16:35 - loss: 0.78 - ETA: 16:34 - loss: 0.78 - ETA: 16:33 - loss: 0.78 - ETA: 16:32 - loss: 0.78 - ETA: 16:31 - loss: 0.78 - ETA: 16:30 - loss: 0.78 - ETA: 16:28 - loss: 0.78 - ETA: 16:27 - loss: 0.78 - ETA: 16:26 - loss: 0.78 - ETA: 16:25 - loss: 0.78 - ETA: 16:23 - loss: 0.78 - ETA: 16:22 - loss: 0.78 - ETA: 16:21 - loss: 0.78 - ETA: 16:20 - loss: 0.78 - ETA: 16:19 - loss: 0.78 - ETA: 16:17 - loss: 0.78 - ETA: 16:16 - loss: 0.78 - ETA: 16:15 - loss: 0.78 - ETA: 16:14 - loss: 0.78 - ETA: 16:12 - loss: 0.78 - ETA: 16:11 - loss: 0.78 - ETA: 16:10 - loss: 0.78 - ETA: 16:09 - loss: 0.78 - ETA: 16:08 - loss: 0.78 - ETA: 16:06 - loss: 0.77 - ETA: 16:05 - loss: 0.77 - ETA: 16:04 - loss: 0.77 - ETA: 16:02 - loss: 0.77 - ETA: 16:01 - loss: 0.77 - ETA: 16:00 - loss: 0.77 - ETA: 15:59 - loss: 0.77 - ETA: 15:58 - loss: 0.77 - ETA: 15:56 - loss: 0.77 - ETA: 15:55 - loss: 0.77 - ETA: 15:54 - loss: 0.77 - ETA: 15:53 - loss: 0.77 - ETA: 15:52 - loss: 0.77 - ETA: 15:51 - loss: 0.77 - ETA: 15:49 - loss: 0.77 - ETA: 15:49 - loss: 0.77 - ETA: 15:48 - loss: 0.77 - ETA: 15:47 - loss: 0.77 - ETA: 15:45 - loss: 0.77 - ETA: 15:44 - loss: 0.77 - ETA: 15:43 - loss: 0.77 - ETA: 15:42 - loss: 0.77 - ETA: 15:41 - loss: 0.77 - ETA: 15:40 - loss: 0.77 - ETA: 15:39 - loss: 0.77 - ETA: 15:38 - loss: 0.77 - ETA: 15:37 - loss: 0.77 - ETA: 15:36 - loss: 0.77 - ETA: 15:35 - loss: 0.77 - ETA: 15:33 - loss: 0.77 - ETA: 15:32 - loss: 0.77 - ETA: 15:31 - loss: 0.77 - ETA: 15:30 - loss: 0.77 - ETA: 15:29 - loss: 0.77 - ETA: 15:27 - loss: 0.77 - ETA: 15:26 - loss: 0.77 - ETA: 15:25 - loss: 0.76 - ETA: 15:24 - loss: 0.76 - ETA: 15:23 - loss: 0.76 - ETA: 15:21 - loss: 0.76 - ETA: 15:20 - loss: 0.76 - ETA: 15:19 - loss: 0.76 640000/1125047 [================>.............] - ETA: 15:18 - loss: 0.76 - ETA: 15:16 - loss: 0.76 - ETA: 15:15 - loss: 0.76 - ETA: 15:14 - loss: 0.76 - ETA: 15:13 - loss: 0.76 - ETA: 15:12 - loss: 0.76 - ETA: 15:10 - loss: 0.76 - ETA: 15:09 - loss: 0.76 - ETA: 15:08 - loss: 0.76 - ETA: 15:07 - loss: 0.76 - ETA: 15:05 - loss: 0.76 - ETA: 15:04 - loss: 0.76 - ETA: 15:03 - loss: 0.76 - ETA: 15:02 - loss: 0.76 - ETA: 15:01 - loss: 0.76 - ETA: 14:59 - loss: 0.76 - ETA: 14:58 - loss: 0.76 - ETA: 14:57 - loss: 0.76 - ETA: 14:56 - loss: 0.76 - ETA: 14:55 - loss: 0.76 - ETA: 14:53 - loss: 0.76 - ETA: 14:52 - loss: 0.76 - ETA: 14:51 - loss: 0.76 - ETA: 14:50 - loss: 0.76 - ETA: 14:49 - loss: 0.76 - ETA: 14:47 - loss: 0.76 - ETA: 14:46 - loss: 0.76 - ETA: 14:45 - loss: 0.76 - ETA: 14:44 - loss: 0.76 - ETA: 14:42 - loss: 0.76 - ETA: 14:41 - loss: 0.76 - ETA: 14:40 - loss: 0.76 - ETA: 14:39 - loss: 0.76 - ETA: 14:38 - loss: 0.76 - ETA: 14:37 - loss: 0.76 - ETA: 14:36 - loss: 0.76 - ETA: 14:34 - loss: 0.76 - ETA: 14:33 - loss: 0.76 - ETA: 14:32 - loss: 0.76 - ETA: 14:31 - loss: 0.75 - ETA: 14:29 - loss: 0.75 - ETA: 14:28 - loss: 0.75 - ETA: 14:27 - loss: 0.75 - ETA: 14:26 - loss: 0.75 - ETA: 14:25 - loss: 0.75 - ETA: 14:23 - loss: 0.75 - ETA: 14:22 - loss: 0.75 - ETA: 14:21 - loss: 0.75 - ETA: 14:20 - loss: 0.75 - ETA: 14:19 - loss: 0.75 - ETA: 14:18 - loss: 0.75 - ETA: 14:17 - loss: 0.75 - ETA: 14:16 - loss: 0.75 - ETA: 14:14 - loss: 0.75 - ETA: 14:13 - loss: 0.75 - ETA: 14:12 - loss: 0.75 - ETA: 14:11 - loss: 0.75 - ETA: 14:10 - loss: 0.75 - ETA: 14:09 - loss: 0.75 - ETA: 14:08 - loss: 0.75 - ETA: 14:07 - loss: 0.75 - ETA: 14:06 - loss: 0.75 - ETA: 14:05 - loss: 0.75 - ETA: 14:03 - loss: 0.75 - ETA: 14:02 - loss: 0.75 - ETA: 14:01 - loss: 0.75 - ETA: 14:00 - loss: 0.75 - ETA: 13:59 - loss: 0.75 - ETA: 13:57 - loss: 0.75 - ETA: 13:56 - loss: 0.75 - ETA: 13:55 - loss: 0.75 - ETA: 13:54 - loss: 0.75 - ETA: 13:53 - loss: 0.75 - ETA: 13:52 - loss: 0.75 - ETA: 13:50 - loss: 0.75 - ETA: 13:49 - loss: 0.75 - ETA: 13:48 - loss: 0.75 - ETA: 13:47 - loss: 0.75 - ETA: 13:46 - loss: 0.75 - ETA: 13:44 - loss: 0.75 - ETA: 13:43 - loss: 0.75 - ETA: 13:42 - loss: 0.75 - ETA: 13:41 - loss: 0.75 - ETA: 13:40 - loss: 0.75 - ETA: 13:39 - loss: 0.75 - ETA: 13:37 - loss: 0.75 - ETA: 13:36 - loss: 0.75 - ETA: 13:35 - loss: 0.75 - ETA: 13:34 - loss: 0.75 - ETA: 13:33 - loss: 0.75 - ETA: 13:32 - loss: 0.75 - ETA: 13:30 - loss: 0.75 - ETA: 13:29 - loss: 0.75 - ETA: 13:28 - loss: 0.75 - ETA: 13:27 - loss: 0.75 - ETA: 13:26 - loss: 0.74 - ETA: 13:24 - loss: 0.74 - ETA: 13:23 - loss: 0.74 - ETA: 13:22 - loss: 0.74 - ETA: 13:21 - loss: 0.74 - ETA: 13:20 - loss: 0.74 - ETA: 13:18 - loss: 0.74 - ETA: 13:17 - loss: 0.74 - ETA: 13:16 - loss: 0.74 - ETA: 13:15 - loss: 0.74 - ETA: 13:14 - loss: 0.74 - ETA: 13:13 - loss: 0.74 - ETA: 13:12 - loss: 0.74 - ETA: 13:11 - loss: 0.74 - ETA: 13:09 - loss: 0.74 - ETA: 13:08 - loss: 0.74 - ETA: 13:07 - loss: 0.74 - ETA: 13:06 - loss: 0.74 - ETA: 13:05 - loss: 0.74 - ETA: 13:04 - loss: 0.74 - ETA: 13:02 - loss: 0.74 - ETA: 13:01 - loss: 0.74 - ETA: 13:00 - loss: 0.74 - ETA: 12:59 - loss: 0.74 - ETA: 12:58 - loss: 0.74 - ETA: 12:57 - loss: 0.74 - ETA: 12:55 - loss: 0.74 - ETA: 12:54 - loss: 0.74 - ETA: 12:53 - loss: 0.74 - ETA: 12:52 - loss: 0.74 - ETA: 12:51 - loss: 0.74 - ETA: 12:50 - loss: 0.74 - ETA: 12:48 - loss: 0.74 - ETA: 12:47 - loss: 0.74 - ETA: 12:46 - loss: 0.74 - ETA: 12:45 - loss: 0.74 - ETA: 12:44 - loss: 0.74 - ETA: 12:43 - loss: 0.74 - ETA: 12:42 - loss: 0.74 - ETA: 12:40 - loss: 0.74 - ETA: 12:39 - loss: 0.74 - ETA: 12:38 - loss: 0.74 - ETA: 12:37 - loss: 0.74 - ETA: 12:36 - loss: 0.74 - ETA: 12:34 - loss: 0.74 - ETA: 12:33 - loss: 0.74 - ETA: 12:32 - loss: 0.74 - ETA: 12:31 - loss: 0.74 - ETA: 12:30 - loss: 0.74 - ETA: 12:29 - loss: 0.74 - ETA: 12:28 - loss: 0.74 - ETA: 12:26 - loss: 0.74 - ETA: 12:25 - loss: 0.74 - ETA: 12:24 - loss: 0.74 - ETA: 12:23 - loss: 0.74 - ETA: 12:22 - loss: 0.74 - ETA: 12:20 - loss: 0.74 - ETA: 12:19 - loss: 0.74 - ETA: 12:18 - loss: 0.74 - ETA: 12:17 - loss: 0.74 - ETA: 12:16 - loss: 0.74 - ETA: 12:15 - loss: 0.74 - ETA: 12:14 - loss: 0.74 - ETA: 12:13 - loss: 0.74 - ETA: 12:12 - loss: 0.74 - ETA: 12:11 - loss: 0.74 - ETA: 12:09 - loss: 0.74 - ETA: 12:08 - loss: 0.74 - ETA: 12:07 - loss: 0.74 - ETA: 12:06 - loss: 0.74 - ETA: 12:05 - loss: 0.74 - ETA: 12:04 - loss: 0.74 - ETA: 12:03 - loss: 0.74 - ETA: 12:02 - loss: 0.74 - ETA: 12:01 - loss: 0.74 - ETA: 11:59 - loss: 0.73 - ETA: 11:58 - loss: 0.73 - ETA: 11:57 - loss: 0.73 - ETA: 11:56 - loss: 0.73 - ETA: 11:55 - loss: 0.73 - ETA: 11:54 - loss: 0.73 - ETA: 11:52 - loss: 0.73 - ETA: 11:51 - loss: 0.73 - ETA: 11:50 - loss: 0.73 - ETA: 11:49 - loss: 0.73 - ETA: 11:48 - loss: 0.73 - ETA: 11:47 - loss: 0.73 - ETA: 11:45 - loss: 0.73 - ETA: 11:44 - loss: 0.73 - ETA: 11:43 - loss: 0.73 - ETA: 11:42 - loss: 0.73 - ETA: 11:41 - loss: 0.73 - ETA: 11:39 - loss: 0.73 - ETA: 11:38 - loss: 0.73 - ETA: 11:37 - loss: 0.73 - ETA: 11:36 - loss: 0.73 - ETA: 11:35 - loss: 0.73 - ETA: 11:34 - loss: 0.73 - ETA: 11:32 - loss: 0.73 - ETA: 11:31 - loss: 0.73 - ETA: 11:30 - loss: 0.73 - ETA: 11:29 - loss: 0.73 - ETA: 11:28 - loss: 0.73 - ETA: 11:27 - loss: 0.73 - ETA: 11:25 - loss: 0.73 - ETA: 11:24 - loss: 0.73 - ETA: 11:23 - loss: 0.73 - ETA: 11:22 - loss: 0.73 - ETA: 11:21 - loss: 0.73 - ETA: 11:20 - loss: 0.73 - ETA: 11:18 - loss: 0.73 - ETA: 11:17 - loss: 0.73 - ETA: 11:16 - loss: 0.73 - ETA: 11:15 - loss: 0.73 - ETA: 11:14 - loss: 0.73 - ETA: 11:13 - loss: 0.73 - ETA: 11:12 - loss: 0.73 - ETA: 11:10 - loss: 0.73 - ETA: 11:09 - loss: 0.73 - ETA: 11:08 - loss: 0.73 - ETA: 11:07 - loss: 0.73 - ETA: 11:06 - loss: 0.73 - ETA: 11:05 - loss: 0.73 - ETA: 11:03 - loss: 0.73 - ETA: 11:02 - loss: 0.73 - ETA: 11:01 - loss: 0.73 - ETA: 11:00 - loss: 0.73 - ETA: 10:59 - loss: 0.73 - ETA: 10:58 - loss: 0.73 - ETA: 10:56 - loss: 0.73 - ETA: 10:55 - loss: 0.73 - ETA: 10:54 - loss: 0.73 - ETA: 10:53 - loss: 0.73 - ETA: 10:52 - loss: 0.73 - ETA: 10:50 - loss: 0.73 - ETA: 10:49 - loss: 0.73 - ETA: 10:48 - loss: 0.73 - ETA: 10:47 - loss: 0.73 - ETA: 10:46 - loss: 0.73 - ETA: 10:45 - loss: 0.73 - ETA: 10:43 - loss: 0.73 - ETA: 10:42 - loss: 0.73 - ETA: 10:41 - loss: 0.73 - ETA: 10:40 - loss: 0.73 - ETA: 10:39 - loss: 0.73 - ETA: 10:38 - loss: 0.73 - ETA: 10:36 - loss: 0.73 - ETA: 10:35 - loss: 0.73 - ETA: 10:34 - loss: 0.73 - ETA: 10:33 - loss: 0.73 - ETA: 10:32 - loss: 0.73 - ETA: 10:30 - loss: 0.73 - ETA: 10:29 - loss: 0.73 - ETA: 10:28 - loss: 0.73 - ETA: 10:27 - loss: 0.73 - ETA: 10:26 - loss: 0.73 - ETA: 10:25 - loss: 0.73 - ETA: 10:23 - loss: 0.73 - ETA: 10:22 - loss: 0.73 - ETA: 10:21 - loss: 0.73 - ETA: 10:20 - loss: 0.73 - ETA: 10:19 - loss: 0.73 - ETA: 10:17 - loss: 0.73 - ETA: 10:16 - loss: 0.73 - ETA: 10:15 - loss: 0.73 - ETA: 10:14 - loss: 0.73 - ETA: 10:13 - loss: 0.73 - ETA: 10:12 - loss: 0.73 - ETA: 10:10 - loss: 0.73 - ETA: 10:09 - loss: 0.73 - ETA: 10:08 - loss: 0.73 - ETA: 10:07 - loss: 0.73 - ETA: 10:06 - loss: 0.73 - ETA: 10:04 - loss: 0.73 - ETA: 10:03 - loss: 0.73 - ETA: 10:02 - loss: 0.73 - ETA: 10:01 - loss: 0.72 - ETA: 10:00 - loss: 0.72 - ETA: 9:59 - loss: 0.7297 - ETA: 9:57 - loss: 0.729 - ETA: 9:56 - loss: 0.729 - ETA: 9:55 - loss: 0.729 - ETA: 9:54 - loss: 0.729 - ETA: 9:53 - loss: 0.729 - ETA: 9:52 - loss: 0.729 - ETA: 9:50 - loss: 0.729 - ETA: 9:49 - loss: 0.729 - ETA: 9:48 - loss: 0.729 - ETA: 9:47 - loss: 0.729 - ETA: 9:46 - loss: 0.728 - ETA: 9:45 - loss: 0.728 - ETA: 9:43 - loss: 0.728 - ETA: 9:42 - loss: 0.728 - ETA: 9:41 - loss: 0.728 - ETA: 9:40 - loss: 0.728 - ETA: 9:39 - loss: 0.728 - ETA: 9:37 - loss: 0.728 - ETA: 9:36 - loss: 0.728 - ETA: 9:35 - loss: 0.728 - ETA: 9:34 - loss: 0.728 - ETA: 9:33 - loss: 0.728 - ETA: 9:32 - loss: 0.728 - ETA: 9:30 - loss: 0.728 - ETA: 9:29 - loss: 0.727 - ETA: 9:28 - loss: 0.727 - ETA: 9:27 - loss: 0.727 - ETA: 9:26 - loss: 0.727 - ETA: 9:25 - loss: 0.727 - ETA: 9:24 - loss: 0.727 - ETA: 9:22 - loss: 0.727 - ETA: 9:21 - loss: 0.727 - ETA: 9:20 - loss: 0.727 - ETA: 9:19 - loss: 0.727 - ETA: 9:18 - loss: 0.727 - ETA: 9:17 - loss: 0.727 - ETA: 9:15 - loss: 0.727 - ETA: 9:14 - loss: 0.727 - ETA: 9:13 - loss: 0.727 - ETA: 9:12 - loss: 0.7269 961536/1125047 [========================>.....] - ETA: 9:11 - loss: 0.726 - ETA: 9:10 - loss: 0.726 - ETA: 9:08 - loss: 0.726 - ETA: 9:07 - loss: 0.726 - ETA: 9:06 - loss: 0.726 - ETA: 9:05 - loss: 0.726 - ETA: 9:04 - loss: 0.726 - ETA: 9:03 - loss: 0.726 - ETA: 9:01 - loss: 0.726 - ETA: 9:00 - loss: 0.726 - ETA: 8:59 - loss: 0.726 - ETA: 8:58 - loss: 0.726 - ETA: 8:57 - loss: 0.726 - ETA: 8:55 - loss: 0.725 - ETA: 8:54 - loss: 0.725 - ETA: 8:53 - loss: 0.725 - ETA: 8:52 - loss: 0.725 - ETA: 8:51 - loss: 0.725 - ETA: 8:50 - loss: 0.725 - ETA: 8:48 - loss: 0.725 - ETA: 8:47 - loss: 0.725 - ETA: 8:46 - loss: 0.725 - ETA: 8:45 - loss: 0.725 - ETA: 8:44 - loss: 0.725 - ETA: 8:43 - loss: 0.725 - ETA: 8:41 - loss: 0.725 - ETA: 8:40 - loss: 0.725 - ETA: 8:39 - loss: 0.724 - ETA: 8:38 - loss: 0.724 - ETA: 8:37 - loss: 0.724 - ETA: 8:35 - loss: 0.724 - ETA: 8:34 - loss: 0.724 - ETA: 8:33 - loss: 0.724 - ETA: 8:32 - loss: 0.724 - ETA: 8:31 - loss: 0.724 - ETA: 8:30 - loss: 0.724 - ETA: 8:28 - loss: 0.724 - ETA: 8:27 - loss: 0.724 - ETA: 8:26 - loss: 0.724 - ETA: 8:25 - loss: 0.724 - ETA: 8:24 - loss: 0.724 - ETA: 8:23 - loss: 0.724 - ETA: 8:22 - loss: 0.724 - ETA: 8:20 - loss: 0.723 - ETA: 8:19 - loss: 0.723 - ETA: 8:18 - loss: 0.723 - ETA: 8:17 - loss: 0.723 - ETA: 8:16 - loss: 0.723 - ETA: 8:15 - loss: 0.723 - ETA: 8:13 - loss: 0.723 - ETA: 8:12 - loss: 0.723 - ETA: 8:11 - loss: 0.723 - ETA: 8:10 - loss: 0.723 - ETA: 8:09 - loss: 0.723 - ETA: 8:08 - loss: 0.723 - ETA: 8:06 - loss: 0.723 - ETA: 8:05 - loss: 0.723 - ETA: 8:04 - loss: 0.723 - ETA: 8:03 - loss: 0.723 - ETA: 8:02 - loss: 0.722 - ETA: 8:01 - loss: 0.722 - ETA: 7:59 - loss: 0.722 - ETA: 7:58 - loss: 0.722 - ETA: 7:57 - loss: 0.722 - ETA: 7:56 - loss: 0.722 - ETA: 7:55 - loss: 0.722 - ETA: 7:53 - loss: 0.722 - ETA: 7:52 - loss: 0.722 - ETA: 7:51 - loss: 0.722 - ETA: 7:50 - loss: 0.722 - ETA: 7:49 - loss: 0.722 - ETA: 7:48 - loss: 0.722 - ETA: 7:47 - loss: 0.722 - ETA: 7:45 - loss: 0.722 - ETA: 7:44 - loss: 0.722 - ETA: 7:43 - loss: 0.722 - ETA: 7:42 - loss: 0.722 - ETA: 7:41 - loss: 0.721 - ETA: 7:40 - loss: 0.721 - ETA: 7:38 - loss: 0.721 - ETA: 7:37 - loss: 0.721 - ETA: 7:36 - loss: 0.721 - ETA: 7:35 - loss: 0.721 - ETA: 7:34 - loss: 0.721 - ETA: 7:33 - loss: 0.721 - ETA: 7:31 - loss: 0.721 - ETA: 7:30 - loss: 0.721 - ETA: 7:29 - loss: 0.721 - ETA: 7:28 - loss: 0.721 - ETA: 7:27 - loss: 0.721 - ETA: 7:26 - loss: 0.721 - ETA: 7:24 - loss: 0.721 - ETA: 7:23 - loss: 0.721 - ETA: 7:22 - loss: 0.720 - ETA: 7:21 - loss: 0.720 - ETA: 7:20 - loss: 0.720 - ETA: 7:18 - loss: 0.720 - ETA: 7:17 - loss: 0.720 - ETA: 7:16 - loss: 0.720 - ETA: 7:15 - loss: 0.720 - ETA: 7:14 - loss: 0.720 - ETA: 7:13 - loss: 0.720 - ETA: 7:12 - loss: 0.720 - ETA: 7:10 - loss: 0.720 - ETA: 7:09 - loss: 0.720 - ETA: 7:08 - loss: 0.720 - ETA: 7:07 - loss: 0.720 - ETA: 7:06 - loss: 0.720 - ETA: 7:04 - loss: 0.720 - ETA: 7:03 - loss: 0.720 - ETA: 7:02 - loss: 0.719 - ETA: 7:01 - loss: 0.719 - ETA: 7:00 - loss: 0.719 - ETA: 6:59 - loss: 0.719 - ETA: 6:57 - loss: 0.719 - ETA: 6:56 - loss: 0.719 - ETA: 6:55 - loss: 0.719 - ETA: 6:54 - loss: 0.719 - ETA: 6:53 - loss: 0.719 - ETA: 6:52 - loss: 0.719 - ETA: 6:50 - loss: 0.719 - ETA: 6:49 - loss: 0.719 - ETA: 6:48 - loss: 0.719 - ETA: 6:47 - loss: 0.719 - ETA: 6:46 - loss: 0.719 - ETA: 6:45 - loss: 0.719 - ETA: 6:43 - loss: 0.719 - ETA: 6:42 - loss: 0.719 - ETA: 6:41 - loss: 0.719 - ETA: 6:40 - loss: 0.719 - ETA: 6:39 - loss: 0.718 - ETA: 6:38 - loss: 0.718 - ETA: 6:36 - loss: 0.718 - ETA: 6:35 - loss: 0.718 - ETA: 6:34 - loss: 0.718 - ETA: 6:33 - loss: 0.718 - ETA: 6:32 - loss: 0.718 - ETA: 6:31 - loss: 0.718 - ETA: 6:29 - loss: 0.718 - ETA: 6:28 - loss: 0.718 - ETA: 6:27 - loss: 0.718 - ETA: 6:26 - loss: 0.718 - ETA: 6:25 - loss: 0.718 - ETA: 6:24 - loss: 0.718 - ETA: 6:22 - loss: 0.718 - ETA: 6:21 - loss: 0.718 - ETA: 6:20 - loss: 0.718 - ETA: 6:19 - loss: 0.718 - ETA: 6:18 - loss: 0.717 - ETA: 6:17 - loss: 0.717 - ETA: 6:15 - loss: 0.717 - ETA: 6:14 - loss: 0.717 - ETA: 6:13 - loss: 0.717 - ETA: 6:12 - loss: 0.717 - ETA: 6:11 - loss: 0.717 - ETA: 6:10 - loss: 0.717 - ETA: 6:08 - loss: 0.717 - ETA: 6:07 - loss: 0.717 - ETA: 6:06 - loss: 0.717 - ETA: 6:05 - loss: 0.717 - ETA: 6:04 - loss: 0.717 - ETA: 6:03 - loss: 0.717 - ETA: 6:01 - loss: 0.717 - ETA: 6:00 - loss: 0.717 - ETA: 5:59 - loss: 0.716 - ETA: 5:58 - loss: 0.716 - ETA: 5:57 - loss: 0.716 - ETA: 5:56 - loss: 0.716 - ETA: 5:54 - loss: 0.716 - ETA: 5:53 - loss: 0.716 - ETA: 5:52 - loss: 0.716 - ETA: 5:51 - loss: 0.716 - ETA: 5:50 - loss: 0.716 - ETA: 5:49 - loss: 0.716 - ETA: 5:47 - loss: 0.716 - ETA: 5:46 - loss: 0.716 - ETA: 5:45 - loss: 0.716 - ETA: 5:44 - loss: 0.716 - ETA: 5:43 - loss: 0.716 - ETA: 5:42 - loss: 0.716 - ETA: 5:40 - loss: 0.715 - ETA: 5:39 - loss: 0.715 - ETA: 5:38 - loss: 0.715 - ETA: 5:37 - loss: 0.715 - ETA: 5:36 - loss: 0.715 - ETA: 5:34 - loss: 0.715 - ETA: 5:33 - loss: 0.715 - ETA: 5:32 - loss: 0.715 - ETA: 5:31 - loss: 0.715 - ETA: 5:30 - loss: 0.715 - ETA: 5:29 - loss: 0.715 - ETA: 5:27 - loss: 0.715 - ETA: 5:26 - loss: 0.715 - ETA: 5:25 - loss: 0.715 - ETA: 5:24 - loss: 0.715 - ETA: 5:23 - loss: 0.715 - ETA: 5:22 - loss: 0.714 - ETA: 5:20 - loss: 0.714 - ETA: 5:19 - loss: 0.714 - ETA: 5:18 - loss: 0.714 - ETA: 5:17 - loss: 0.714 - ETA: 5:16 - loss: 0.714 - ETA: 5:15 - loss: 0.714 - ETA: 5:13 - loss: 0.714 - ETA: 5:12 - loss: 0.714 - ETA: 5:11 - loss: 0.714 - ETA: 5:10 - loss: 0.714 - ETA: 5:09 - loss: 0.714 - ETA: 5:08 - loss: 0.714 - ETA: 5:06 - loss: 0.714 - ETA: 5:05 - loss: 0.714 - ETA: 5:04 - loss: 0.714 - ETA: 5:03 - loss: 0.713 - ETA: 5:02 - loss: 0.713 - ETA: 5:01 - loss: 0.713 - ETA: 5:00 - loss: 0.713 - ETA: 4:58 - loss: 0.713 - ETA: 4:57 - loss: 0.713 - ETA: 4:56 - loss: 0.713 - ETA: 4:55 - loss: 0.713 - ETA: 4:54 - loss: 0.713 - ETA: 4:53 - loss: 0.713 - ETA: 4:51 - loss: 0.713 - ETA: 4:50 - loss: 0.713 - ETA: 4:49 - loss: 0.713 - ETA: 4:48 - loss: 0.713 - ETA: 4:47 - loss: 0.713 - ETA: 4:46 - loss: 0.713 - ETA: 4:44 - loss: 0.712 - ETA: 4:43 - loss: 0.712 - ETA: 4:42 - loss: 0.712 - ETA: 4:41 - loss: 0.712 - ETA: 4:40 - loss: 0.712 - ETA: 4:39 - loss: 0.712 - ETA: 4:38 - loss: 0.712 - ETA: 4:36 - loss: 0.712 - ETA: 4:35 - loss: 0.712 - ETA: 4:34 - loss: 0.712 - ETA: 4:33 - loss: 0.712 - ETA: 4:32 - loss: 0.712 - ETA: 4:30 - loss: 0.712 - ETA: 4:29 - loss: 0.712 - ETA: 4:28 - loss: 0.712 - ETA: 4:27 - loss: 0.712 - ETA: 4:26 - loss: 0.711 - ETA: 4:25 - loss: 0.711 - ETA: 4:23 - loss: 0.711 - ETA: 4:22 - loss: 0.711 - ETA: 4:21 - loss: 0.711 - ETA: 4:20 - loss: 0.711 - ETA: 4:19 - loss: 0.711 - ETA: 4:18 - loss: 0.711 - ETA: 4:16 - loss: 0.711 - ETA: 4:15 - loss: 0.711 - ETA: 4:14 - loss: 0.711 - ETA: 4:13 - loss: 0.711 - ETA: 4:12 - loss: 0.711 - ETA: 4:11 - loss: 0.711 - ETA: 4:09 - loss: 0.711 - ETA: 4:08 - loss: 0.711 - ETA: 4:07 - loss: 0.711 - ETA: 4:06 - loss: 0.711 - ETA: 4:05 - loss: 0.711 - ETA: 4:04 - loss: 0.710 - ETA: 4:02 - loss: 0.710 - ETA: 4:01 - loss: 0.710 - ETA: 4:00 - loss: 0.710 - ETA: 3:59 - loss: 0.710 - ETA: 3:58 - loss: 0.710 - ETA: 3:57 - loss: 0.710 - ETA: 3:55 - loss: 0.710 - ETA: 3:54 - loss: 0.710 - ETA: 3:53 - loss: 0.710 - ETA: 3:52 - loss: 0.710 - ETA: 3:51 - loss: 0.710 - ETA: 3:50 - loss: 0.710 - ETA: 3:49 - loss: 0.710 - ETA: 3:47 - loss: 0.710 - ETA: 3:46 - loss: 0.710 - ETA: 3:45 - loss: 0.709 - ETA: 3:44 - loss: 0.709 - ETA: 3:43 - loss: 0.709 - ETA: 3:42 - loss: 0.709 - ETA: 3:40 - loss: 0.709 - ETA: 3:39 - loss: 0.709 - ETA: 3:38 - loss: 0.709 - ETA: 3:37 - loss: 0.709 - ETA: 3:36 - loss: 0.709 - ETA: 3:35 - loss: 0.709 - ETA: 3:33 - loss: 0.709 - ETA: 3:32 - loss: 0.709 - ETA: 3:31 - loss: 0.709 - ETA: 3:30 - loss: 0.708 - ETA: 3:29 - loss: 0.708 - ETA: 3:28 - loss: 0.708 - ETA: 3:26 - loss: 0.708 - ETA: 3:25 - loss: 0.708 - ETA: 3:24 - loss: 0.708 - ETA: 3:23 - loss: 0.708 - ETA: 3:22 - loss: 0.708 - ETA: 3:21 - loss: 0.708 - ETA: 3:19 - loss: 0.708 - ETA: 3:18 - loss: 0.708 - ETA: 3:17 - loss: 0.708 - ETA: 3:16 - loss: 0.708 - ETA: 3:15 - loss: 0.708 - ETA: 3:14 - loss: 0.708 - ETA: 3:12 - loss: 0.707 - ETA: 3:11 - loss: 0.707 - ETA: 3:10 - loss: 0.707 - ETA: 3:09 - loss: 0.707 - ETA: 3:08 - loss: 0.707 - ETA: 3:07 - loss: 0.707 - ETA: 3:05 - loss: 0.70751042432/1125047 [==========================>...] - ETA: 3:04 - loss: 0.707 - ETA: 3:03 - loss: 0.707 - ETA: 3:02 - loss: 0.707 - ETA: 3:01 - loss: 0.707 - ETA: 3:00 - loss: 0.707 - ETA: 2:58 - loss: 0.707 - ETA: 2:57 - loss: 0.707 - ETA: 2:56 - loss: 0.707 - ETA: 2:55 - loss: 0.707 - ETA: 2:54 - loss: 0.706 - ETA: 2:53 - loss: 0.706 - ETA: 2:51 - loss: 0.706 - ETA: 2:50 - loss: 0.706 - ETA: 2:49 - loss: 0.706 - ETA: 2:48 - loss: 0.706 - ETA: 2:47 - loss: 0.706 - ETA: 2:46 - loss: 0.706 - ETA: 2:44 - loss: 0.706 - ETA: 2:43 - loss: 0.706 - ETA: 2:42 - loss: 0.706 - ETA: 2:41 - loss: 0.706 - ETA: 2:40 - loss: 0.706 - ETA: 2:39 - loss: 0.706 - ETA: 2:37 - loss: 0.706 - ETA: 2:36 - loss: 0.705 - ETA: 2:35 - loss: 0.705 - ETA: 2:34 - loss: 0.705 - ETA: 2:33 - loss: 0.705 - ETA: 2:32 - loss: 0.705 - ETA: 2:31 - loss: 0.705 - ETA: 2:29 - loss: 0.705 - ETA: 2:28 - loss: 0.705 - ETA: 2:27 - loss: 0.705 - ETA: 2:26 - loss: 0.705 - ETA: 2:25 - loss: 0.705 - ETA: 2:24 - loss: 0.705 - ETA: 2:22 - loss: 0.705 - ETA: 2:21 - loss: 0.704 - ETA: 2:20 - loss: 0.704 - ETA: 2:19 - loss: 0.704 - ETA: 2:18 - loss: 0.704 - ETA: 2:17 - loss: 0.704 - ETA: 2:15 - loss: 0.704 - ETA: 2:14 - loss: 0.704 - ETA: 2:13 - loss: 0.704 - ETA: 2:12 - loss: 0.704 - ETA: 2:11 - loss: 0.704 - ETA: 2:10 - loss: 0.704 - ETA: 2:08 - loss: 0.704 - ETA: 2:07 - loss: 0.704 - ETA: 2:06 - loss: 0.704 - ETA: 2:05 - loss: 0.703 - ETA: 2:04 - loss: 0.703 - ETA: 2:03 - loss: 0.703 - ETA: 2:01 - loss: 0.703 - ETA: 2:00 - loss: 0.703 - ETA: 1:59 - loss: 0.703 - ETA: 1:58 - loss: 0.703 - ETA: 1:57 - loss: 0.703 - ETA: 1:56 - loss: 0.703 - ETA: 1:54 - loss: 0.703 - ETA: 1:53 - loss: 0.703 - ETA: 1:52 - loss: 0.703 - ETA: 1:51 - loss: 0.703 - ETA: 1:50 - loss: 0.703 - ETA: 1:49 - loss: 0.703 - ETA: 1:47 - loss: 0.703 - ETA: 1:46 - loss: 0.702 - ETA: 1:45 - loss: 0.702 - ETA: 1:44 - loss: 0.702 - ETA: 1:43 - loss: 0.702 - ETA: 1:42 - loss: 0.702 - ETA: 1:40 - loss: 0.702 - ETA: 1:39 - loss: 0.702 - ETA: 1:38 - loss: 0.702 - ETA: 1:37 - loss: 0.702 - ETA: 1:36 - loss: 0.702 - ETA: 1:35 - loss: 0.702 - ETA: 1:33 - loss: 0.7023"
     ]
    }
   ],
   "source": [
    "model.fit(x = [xtrain_pad, xtrain_companyName, xtrain_distributorName, xtrain_ageGroup, \\\n",
    "               xtrain_division, xtrain_gender, xtrain_group, xtrain_name4, xtrain_sportsCategory, \\\n",
    "               xtrain_subBrand] , y=ytrain_enc, batch_size=1024, epochs=5, verbose=1, \n",
    "               validation_data=([xvalid_pad, xvalid_companyName, xvalid_distributorName, xvalid_ageGroup, \\\n",
    "                                 xvalid_division, xvalid_gender, xvalid_group, xvalid_name4, xvalid_sportsCategory, \\\n",
    "                                 xvalid_subBrand], yvalid_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Keras_model_Adam_BS1024_tanh_V3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('Keras_model_Adam_BS512_V1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55381,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_company.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([xvalid_pad, xvalid_companyName, xvalid_distributorName, xvalid_ageGroup, \\\n",
    "                             xvalid_division, xvalid_gender, xvalid_group, xvalid_name4, xvalid_sportsCategory, \\\n",
    "                             xvalid_subBrand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([xtest_pad, xtest_companyName, xtest_distributorName, xtest_ageGroup, \\\n",
    "                             xtest_division, xtest_gender, xtest_group, xtest_name4, xtest_sportsCategory, \\\n",
    "                             xtest_subBrand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = [np.argmax(i) for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pi1 = open('y_Jpn_lbl_enc.pkl', 'rb')\n",
    "lbl_enc = pickle.load(file_pi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = lbl_enc.inverse_transform(predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvalid_label = lbl_enc.inverse_transform(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({'description' : xtest.description, 'actuals' : yvalid_label, 'predictions' : predict_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(test_df.actuals, test_df.predictions,average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_df.actuals, test_df.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
