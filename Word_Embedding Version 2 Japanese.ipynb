{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\narendran.thesma\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\narendran.thesma\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "import gensim\n",
    "import re, string\n",
    "import tinysegmenter\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPANY</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>DISTRIBUTOR</th>\n",
       "      <th>ARTICLE ID</th>\n",
       "      <th>MODEL NUMBER</th>\n",
       "      <th>ARTICLE NAME</th>\n",
       "      <th>SUBBRAND</th>\n",
       "      <th>SPORTS CATEGORY</th>\n",
       "      <th>PRODUCT DIVISION</th>\n",
       "      <th>PRODUCT GROUP</th>\n",
       "      <th>...</th>\n",
       "      <th>CURRENT PRICE IN EUR</th>\n",
       "      <th>INITIAL PRICE IN SELECTED CURRENCY</th>\n",
       "      <th>CURRENT PRICE IN SELECTED CURRENCY</th>\n",
       "      <th>SELECTED CURRENCY</th>\n",
       "      <th>PRODUCT INTRODUCTION DATE</th>\n",
       "      <th>DISCOUNTED SINCE</th>\n",
       "      <th>PRODUCT EXIT DATE</th>\n",
       "      <th>PRODUCT DESCRIPTION</th>\n",
       "      <th>PRODUCT URL</th>\n",
       "      <th>IMAGE-SERVER URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Own eCom</td>\n",
       "      <td>BG0387-001</td>\n",
       "      <td>BG0387</td>\n",
       "      <td>ナイキ コア ハーフ KV ゴルフバッグ</td>\n",
       "      <td>Performance</td>\n",
       "      <td>Golf</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Bags</td>\n",
       "      <td>...</td>\n",
       "      <td>99.144</td>\n",
       "      <td>116.640</td>\n",
       "      <td>99.144</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2/22/2016</td>\n",
       "      <td>12/26/2016</td>\n",
       "      <td>1/2/2017</td>\n",
       "      <td>整理しやすいゴルフバッグ。快適な持ち運び。 ナイキ コア ハーフ KV ゴルフバッグは、専用...</td>\n",
       "      <td>http://store.nike.com/jp/ja_jp/pd/%25E3%2583%2...</td>\n",
       "      <td>http://usporamap287.am.adsint.biz/zoomimages/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Own eCom</td>\n",
       "      <td>839240-001</td>\n",
       "      <td>839240</td>\n",
       "      <td>ナイキ コルテッツ QS キッズシューズ</td>\n",
       "      <td>Sport Inspired</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>Footwear</td>\n",
       "      <td>Sport Inspired Footwear</td>\n",
       "      <td>...</td>\n",
       "      <td>62.820</td>\n",
       "      <td>82.620</td>\n",
       "      <td>62.820</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2/22/2016</td>\n",
       "      <td>4/5/2016</td>\n",
       "      <td>7/26/2016</td>\n",
       "      <td>高級感のあるレトロスタイル   ナイキ コルテッツ QS キッズシューズは、上質なレザーのア...</td>\n",
       "      <td>http://store.nike.com/jp/ja_jp/pd/%25E3%2583%2...</td>\n",
       "      <td>http://usporamap287.am.adsint.biz/zoomimages/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Own eCom</td>\n",
       "      <td>GL0783-101</td>\n",
       "      <td>GL0783</td>\n",
       "      <td>ナイキ レジン スピード レッド ゴルフボール</td>\n",
       "      <td>Performance</td>\n",
       "      <td>Golf</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Sport Equipment</td>\n",
       "      <td>...</td>\n",
       "      <td>31.104</td>\n",
       "      <td>31.104</td>\n",
       "      <td>31.104</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2/15/2016</td>\n",
       "      <td>Not discounted yet</td>\n",
       "      <td>8/29/2016</td>\n",
       "      <td>高初速でより遠くへ ナイキ レジン スピード レッド ゴルフボールは、更にソフトになった新開...</td>\n",
       "      <td>http://store.nike.com/jp/ja_jp/pd/%25E3%2583%2...</td>\n",
       "      <td>http://usporamap287.am.adsint.biz/zoomimages/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Own eCom</td>\n",
       "      <td>GL0781-101</td>\n",
       "      <td>GL0781</td>\n",
       "      <td>ナイキ レジン ツアー ブラック ゴルフボール</td>\n",
       "      <td>Performance</td>\n",
       "      <td>Golf</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Sport Equipment</td>\n",
       "      <td>...</td>\n",
       "      <td>28.764</td>\n",
       "      <td>58.320</td>\n",
       "      <td>28.764</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2/15/2016</td>\n",
       "      <td>2/27/2017</td>\n",
       "      <td>6/27/2017</td>\n",
       "      <td>低スピンでより遠くへ ナイキ レジン ツアー ブラック ゴルフボールは、更にソフトになったR...</td>\n",
       "      <td>http://store.nike.com/jp/ja_jp/pd/%25E3%2583%2...</td>\n",
       "      <td>http://usporamap287.am.adsint.biz/zoomimages/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Own eCom</td>\n",
       "      <td>AC3877-005</td>\n",
       "      <td>AC3877</td>\n",
       "      <td>ナイキ ATG スピード ジャンプ ロープ</td>\n",
       "      <td>Performance</td>\n",
       "      <td>Training</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Sport Equipment</td>\n",
       "      <td>...</td>\n",
       "      <td>28.188</td>\n",
       "      <td>28.188</td>\n",
       "      <td>28.188</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2/15/2016</td>\n",
       "      <td>Not discounted yet</td>\n",
       "      <td>7/19/2016</td>\n",
       "      <td>軽く、速く、カスタマイズも可能。 ナイキ ATG スピード ジャンプ ロープは、滑りにくいボ...</td>\n",
       "      <td>http://store.nike.com/jp/ja_jp/pd/%25E3%2583%2...</td>\n",
       "      <td>http://usporamap287.am.adsint.biz/zoomimages/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  COMPANY COUNTRY DISTRIBUTOR  ARTICLE ID MODEL NUMBER  \\\n",
       "0    Nike   Japan    Own eCom  BG0387-001       BG0387   \n",
       "1    Nike   Japan    Own eCom  839240-001       839240   \n",
       "2    Nike   Japan    Own eCom  GL0783-101       GL0783   \n",
       "3    Nike   Japan    Own eCom  GL0781-101       GL0781   \n",
       "4    Nike   Japan    Own eCom  AC3877-005       AC3877   \n",
       "\n",
       "              ARTICLE NAME        SUBBRAND SPORTS CATEGORY PRODUCT DIVISION  \\\n",
       "0     ナイキ コア ハーフ KV ゴルフバッグ     Performance            Golf      Accessories   \n",
       "1     ナイキ コルテッツ QS キッズシューズ  Sport Inspired       Lifestyle         Footwear   \n",
       "2  ナイキ レジン スピード レッド ゴルフボール     Performance            Golf      Accessories   \n",
       "3  ナイキ レジン ツアー ブラック ゴルフボール     Performance            Golf      Accessories   \n",
       "4    ナイキ ATG スピード ジャンプ ロープ     Performance        Training      Accessories   \n",
       "\n",
       "             PRODUCT GROUP                        ...                          \\\n",
       "0                     Bags                        ...                           \n",
       "1  Sport Inspired Footwear                        ...                           \n",
       "2          Sport Equipment                        ...                           \n",
       "3          Sport Equipment                        ...                           \n",
       "4          Sport Equipment                        ...                           \n",
       "\n",
       "  CURRENT PRICE IN EUR INITIAL PRICE IN SELECTED CURRENCY  \\\n",
       "0               99.144                            116.640   \n",
       "1               62.820                             82.620   \n",
       "2               31.104                             31.104   \n",
       "3               28.764                             58.320   \n",
       "4               28.188                             28.188   \n",
       "\n",
       "  CURRENT PRICE IN SELECTED CURRENCY SELECTED CURRENCY  \\\n",
       "0                             99.144               EUR   \n",
       "1                             62.820               EUR   \n",
       "2                             31.104               EUR   \n",
       "3                             28.764               EUR   \n",
       "4                             28.188               EUR   \n",
       "\n",
       "  PRODUCT INTRODUCTION DATE    DISCOUNTED SINCE PRODUCT EXIT DATE  \\\n",
       "0                 2/22/2016          12/26/2016          1/2/2017   \n",
       "1                 2/22/2016            4/5/2016         7/26/2016   \n",
       "2                 2/15/2016  Not discounted yet         8/29/2016   \n",
       "3                 2/15/2016           2/27/2017         6/27/2017   \n",
       "4                 2/15/2016  Not discounted yet         7/19/2016   \n",
       "\n",
       "                                 PRODUCT DESCRIPTION  \\\n",
       "0  整理しやすいゴルフバッグ。快適な持ち運び。 ナイキ コア ハーフ KV ゴルフバッグは、専用...   \n",
       "1  高級感のあるレトロスタイル   ナイキ コルテッツ QS キッズシューズは、上質なレザーのア...   \n",
       "2  高初速でより遠くへ ナイキ レジン スピード レッド ゴルフボールは、更にソフトになった新開...   \n",
       "3  低スピンでより遠くへ ナイキ レジン ツアー ブラック ゴルフボールは、更にソフトになったR...   \n",
       "4  軽く、速く、カスタマイズも可能。 ナイキ ATG スピード ジャンプ ロープは、滑りにくいボ...   \n",
       "\n",
       "                                         PRODUCT URL  \\\n",
       "0  http://store.nike.com/jp/ja_jp/pd/%25E3%2583%2...   \n",
       "1  http://store.nike.com/jp/ja_jp/pd/%25E3%2583%2...   \n",
       "2  http://store.nike.com/jp/ja_jp/pd/%25E3%2583%2...   \n",
       "3  http://store.nike.com/jp/ja_jp/pd/%25E3%2583%2...   \n",
       "4  http://store.nike.com/jp/ja_jp/pd/%25E3%2583%2...   \n",
       "\n",
       "                                    IMAGE-SERVER URL  \n",
       "0  http://usporamap287.am.adsint.biz/zoomimages/1...  \n",
       "1  http://usporamap287.am.adsint.biz/zoomimages/1...  \n",
       "2  http://usporamap287.am.adsint.biz/zoomimages/1...  \n",
       "3  http://usporamap287.am.adsint.biz/zoomimages/1...  \n",
       "4  http://usporamap287.am.adsint.biz/zoomimages/1...  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Japan_Not_Encoded.csv\", encoding='utf-8')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "    :param actual: Array containing the actual target classes\n",
    "    :param predicted: Matrix with class predictions, one probability per class\n",
    "    \"\"\"\n",
    "    # Convert 'actual' to a binary array if it's not already:\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "\n",
    "    clip = np.clip(predicted, eps, 1 - eps)\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip))\n",
    "    return -1.0 / rows * vsota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req = data.loc[:,[\"COMPANY\", \"COUNTRY\", \"ARTICLE NAME\",\"SUBBRAND\", \"PRODUCT DESCRIPTION\", \"PRODUCT URL\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req = data_req.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req[\"description\"]  = data_req[\"COMPANY\"] +\" \" + data_req[\"ARTICLE NAME\"] +\" \" + data_req[\"PRODUCT DESCRIPTION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req = data_req.drop([\"COUNTRY\", \"ARTICLE NAME\", \"PRODUCT DESCRIPTION\", \"PRODUCT URL\"], axis = 1)\n",
    "data_req.columns = [\"COMPANY\", \"subBrand\", \"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req.description = data_req.description.fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req[\"subBrand\"] = data_req[\"subBrand\"].str.lower()\n",
    "data_req.description = data_req.description.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(data_req[\"subBrand\"].fillna(\"unknown\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [\"description\", \"COMPANY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "performance       33771\n",
       "sport inspired    27764\n",
       "Name: subBrand, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_req[\"subBrand\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(data_req[X], y, \n",
    "                                                  stratify=y, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿|¡§£₤‘’])')\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train = [tokenize(x) for x in xtrain.description]\n",
    "texts_valid = [tokenize(x) for x in xvalid.description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = tinysegmenter.TinySegmenter()\n",
    "tokenized_text_train = [segmenter.tokenize(x) for x in texts_train]\n",
    "tokenized_text_valid = [segmenter.tokenize(x) for x in texts_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_token_train = [' '.join(x) for x in tokenized_text_train]\n",
    "joined_token_valid = [' '.join(x) for x in tokenized_text_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using keras tokenizer here\n",
    "token = text.Tokenizer(num_words=None)\n",
    "max_len = 300\n",
    "\n",
    "token.fit_on_texts(joined_token_train + joined_token_valid)\n",
    "xtrain_seq = token.texts_to_sequences(joined_token_train)\n",
    "xvalid_seq = token.texts_to_sequences(joined_token_valid)\n",
    "\n",
    "# zero pad the sequences\n",
    "xtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\n",
    "xvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\n",
    "\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_keras_words = list(token.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "keras_tokenised_words = [text_to_word_sequence(x, lower=False) for x in (joined_token_train + joined_token_valid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model = gensim.models.Word2Vec(keras_tokenised_words, size=300, min_count=1, window=5, iter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 36954/36954 [00:00<00:00, 147191.20it/s]\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = word_model.wv[word]\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, Flatten, Concatenate, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "# Input: meant to receive sequences of 300 integers\n",
    "main_input = Input(shape=(300,), name='main_input')\n",
    "\n",
    "# This embedding layer will encode the input sequence\n",
    "# into a sequence of dense 300-dimensional vectors.\n",
    "x = Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False)(main_input)\n",
    "\n",
    "x = SpatialDropout1D(0.3)(x)\n",
    "\n",
    "\n",
    "# A LSTM will transform the vector sequence into a single vector,\n",
    "# containing information about the entire sequence\n",
    "lstm_out = LSTM(100, dropout=0.3, recurrent_dropout=0.3)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_input = Input((1,), name='aux_input')\n",
    "x = keras.layers.concatenate([lstm_out, auxiliary_input], axis = 1)\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(2, activation='softmax', name='main_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[main_input, auxiliary_input], outputs=main_output)\n",
    "rmsprop = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy', optimizer= 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to binarize the labels for the neural net\n",
    "ytrain_enc = np_utils.to_categorical(ytrain)\n",
    "yvalid_enc = np_utils.to_categorical(yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "xtrain_company = np.array(xtrain.COMPANY)\n",
    "xtrain_company = le.fit_transform(xtrain_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvalid_company = np.array(xvalid.COMPANY)\n",
    "xvalid_company = le.fit_transform(xvalid_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 300, 300)     11086500    main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 300, 300)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 100)          160400      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "aux_input (InputLayer)          (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 101)          0           lstm_1[0][0]                     \n",
      "                                                                 aux_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         104448      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         1049600     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          524800      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 512)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          131328      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          32896       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 2)            258         dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 13,090,230\n",
      "Trainable params: 2,003,730\n",
      "Non-trainable params: 11,086,500\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "55381/55381 [==============================] - ETA: 22:57 - loss: 0.69 - ETA: 17:53 - loss: 0.69 - ETA: 16:13 - loss: 0.69 - ETA: 15:17 - loss: 0.69 - ETA: 14:30 - loss: 0.69 - ETA: 14:04 - loss: 0.69 - ETA: 13:48 - loss: 0.69 - ETA: 13:29 - loss: 0.69 - ETA: 13:15 - loss: 0.69 - ETA: 13:07 - loss: 0.69 - ETA: 13:00 - loss: 0.69 - ETA: 12:51 - loss: 0.69 - ETA: 12:45 - loss: 0.69 - ETA: 12:40 - loss: 0.69 - ETA: 12:35 - loss: 0.69 - ETA: 12:36 - loss: 0.69 - ETA: 12:33 - loss: 0.69 - ETA: 12:29 - loss: 0.69 - ETA: 12:23 - loss: 0.69 - ETA: 12:19 - loss: 0.69 - ETA: 12:18 - loss: 0.68 - ETA: 12:17 - loss: 0.68 - ETA: 12:12 - loss: 0.68 - ETA: 12:17 - loss: 0.68 - ETA: 12:19 - loss: 0.68 - ETA: 12:14 - loss: 0.68 - ETA: 12:09 - loss: 0.68 - ETA: 12:05 - loss: 0.68 - ETA: 12:01 - loss: 0.68 - ETA: 11:56 - loss: 0.68 - ETA: 11:53 - loss: 0.68 - ETA: 11:50 - loss: 0.68 - ETA: 11:46 - loss: 0.68 - ETA: 11:41 - loss: 0.68 - ETA: 11:37 - loss: 0.68 - ETA: 11:34 - loss: 0.68 - ETA: 11:30 - loss: 0.68 - ETA: 11:26 - loss: 0.68 - ETA: 11:23 - loss: 0.68 - ETA: 11:20 - loss: 0.68 - ETA: 11:16 - loss: 0.67 - ETA: 11:12 - loss: 0.67 - ETA: 11:10 - loss: 0.67 - ETA: 11:06 - loss: 0.67 - ETA: 11:02 - loss: 0.67 - ETA: 11:01 - loss: 0.67 - ETA: 11:01 - loss: 0.67 - ETA: 10:59 - loss: 0.67 - ETA: 10:57 - loss: 0.67 - ETA: 10:56 - loss: 0.67 - ETA: 10:53 - loss: 0.67 - ETA: 10:49 - loss: 0.67 - ETA: 10:46 - loss: 0.67 - ETA: 10:42 - loss: 0.67 - ETA: 10:38 - loss: 0.67 - ETA: 10:34 - loss: 0.67 - ETA: 10:31 - loss: 0.67 - ETA: 10:28 - loss: 0.67 - ETA: 10:24 - loss: 0.67 - ETA: 10:21 - loss: 0.67 - ETA: 10:18 - loss: 0.67 - ETA: 10:15 - loss: 0.67 - ETA: 10:10 - loss: 0.67 - ETA: 10:07 - loss: 0.66 - ETA: 10:03 - loss: 0.66 - ETA: 10:00 - loss: 0.66 - ETA: 9:56 - loss: 0.6677 - ETA: 9:53 - loss: 0.667 - ETA: 9:49 - loss: 0.666 - ETA: 9:45 - loss: 0.665 - ETA: 9:42 - loss: 0.664 - ETA: 9:39 - loss: 0.663 - ETA: 9:35 - loss: 0.662 - ETA: 9:31 - loss: 0.662 - ETA: 9:28 - loss: 0.662 - ETA: 9:25 - loss: 0.662 - ETA: 9:21 - loss: 0.661 - ETA: 9:18 - loss: 0.660 - ETA: 9:14 - loss: 0.660 - ETA: 9:10 - loss: 0.659 - ETA: 9:07 - loss: 0.659 - ETA: 9:03 - loss: 0.659 - ETA: 9:00 - loss: 0.658 - ETA: 8:56 - loss: 0.658 - ETA: 8:52 - loss: 0.657 - ETA: 8:49 - loss: 0.656 - ETA: 8:45 - loss: 0.655 - ETA: 8:42 - loss: 0.655 - ETA: 8:38 - loss: 0.654 - ETA: 8:35 - loss: 0.653 - ETA: 8:31 - loss: 0.653 - ETA: 8:27 - loss: 0.652 - ETA: 8:24 - loss: 0.651 - ETA: 8:21 - loss: 0.651 - ETA: 8:17 - loss: 0.650 - ETA: 8:13 - loss: 0.650 - ETA: 8:09 - loss: 0.649 - ETA: 8:06 - loss: 0.648 - ETA: 8:02 - loss: 0.647 - ETA: 7:58 - loss: 0.647 - ETA: 7:55 - loss: 0.646 - ETA: 7:51 - loss: 0.645 - ETA: 7:47 - loss: 0.644 - ETA: 7:44 - loss: 0.644 - ETA: 7:40 - loss: 0.643 - ETA: 7:37 - loss: 0.643 - ETA: 7:33 - loss: 0.642 - ETA: 7:29 - loss: 0.641 - ETA: 7:25 - loss: 0.640 - ETA: 7:22 - loss: 0.639 - ETA: 7:18 - loss: 0.638 - ETA: 7:14 - loss: 0.637 - ETA: 7:10 - loss: 0.637 - ETA: 7:07 - loss: 0.636 - ETA: 7:03 - loss: 0.635 - ETA: 7:00 - loss: 0.634 - ETA: 6:56 - loss: 0.633 - ETA: 6:52 - loss: 0.632 - ETA: 6:48 - loss: 0.632 - ETA: 6:44 - loss: 0.631 - ETA: 6:40 - loss: 0.630 - ETA: 6:36 - loss: 0.629 - ETA: 6:33 - loss: 0.629 - ETA: 6:29 - loss: 0.628 - ETA: 6:25 - loss: 0.628 - ETA: 6:21 - loss: 0.627 - ETA: 6:17 - loss: 0.626 - ETA: 6:13 - loss: 0.626 - ETA: 6:10 - loss: 0.625 - ETA: 6:06 - loss: 0.624 - ETA: 6:02 - loss: 0.623 - ETA: 5:58 - loss: 0.623 - ETA: 5:54 - loss: 0.622 - ETA: 5:50 - loss: 0.621 - ETA: 5:46 - loss: 0.620 - ETA: 5:42 - loss: 0.619 - ETA: 5:38 - loss: 0.618 - ETA: 5:34 - loss: 0.617 - ETA: 5:30 - loss: 0.616 - ETA: 5:26 - loss: 0.616 - ETA: 5:23 - loss: 0.615 - ETA: 5:19 - loss: 0.614 - ETA: 5:15 - loss: 0.614 - ETA: 5:11 - loss: 0.613 - ETA: 5:07 - loss: 0.612 - ETA: 5:03 - loss: 0.612 - ETA: 4:59 - loss: 0.611 - ETA: 4:55 - loss: 0.611 - ETA: 4:51 - loss: 0.610 - ETA: 4:47 - loss: 0.610 - ETA: 4:43 - loss: 0.609 - ETA: 4:38 - loss: 0.608 - ETA: 4:34 - loss: 0.608 - ETA: 4:30 - loss: 0.607 - ETA: 4:26 - loss: 0.607 - ETA: 4:22 - loss: 0.606 - ETA: 4:18 - loss: 0.605 - ETA: 4:14 - loss: 0.605 - ETA: 4:10 - loss: 0.604 - ETA: 4:06 - loss: 0.604 - ETA: 4:01 - loss: 0.603 - ETA: 3:57 - loss: 0.602 - ETA: 3:53 - loss: 0.601 - ETA: 3:49 - loss: 0.601 - ETA: 3:45 - loss: 0.600 - ETA: 3:41 - loss: 0.599 - ETA: 3:36 - loss: 0.599 - ETA: 3:32 - loss: 0.598 - ETA: 3:28 - loss: 0.598 - ETA: 3:24 - loss: 0.597 - ETA: 3:20 - loss: 0.597 - ETA: 3:15 - loss: 0.597 - ETA: 3:11 - loss: 0.596 - ETA: 3:07 - loss: 0.595 - ETA: 3:03 - loss: 0.594 - ETA: 2:58 - loss: 0.594 - ETA: 2:54 - loss: 0.593 - ETA: 2:50 - loss: 0.593 - ETA: 2:46 - loss: 0.592 - ETA: 2:41 - loss: 0.592 - ETA: 2:37 - loss: 0.591 - ETA: 2:33 - loss: 0.591 - ETA: 2:28 - loss: 0.591 - ETA: 2:24 - loss: 0.590 - ETA: 2:20 - loss: 0.589 - ETA: 2:15 - loss: 0.589 - ETA: 2:11 - loss: 0.588 - ETA: 2:07 - loss: 0.588 - ETA: 2:02 - loss: 0.587 - ETA: 1:58 - loss: 0.587 - ETA: 1:53 - loss: 0.586 - ETA: 1:49 - loss: 0.586 - ETA: 1:45 - loss: 0.585 - ETA: 1:40 - loss: 0.585 - ETA: 1:36 - loss: 0.584 - ETA: 1:31 - loss: 0.584 - ETA: 1:27 - loss: 0.583 - ETA: 1:22 - loss: 0.582 - ETA: 1:18 - loss: 0.582 - ETA: 1:13 - loss: 0.582 - ETA: 1:09 - loss: 0.581 - ETA: 1:05 - loss: 0.581 - ETA: 1:00 - loss: 0.580 - ETA: 56s - loss: 0.580 - ETA: 51s - loss: 0.57 - ETA: 47s - loss: 0.57 - ETA: 42s - loss: 0.57 - ETA: 37s - loss: 0.57 - ETA: 33s - loss: 0.57 - ETA: 28s - loss: 0.57 - ETA: 24s - loss: 0.57 - ETA: 19s - loss: 0.57 - ETA: 15s - loss: 0.57 - ETA: 10s - loss: 0.57 - ETA: 6s - loss: 0.5750 - ETA: 1s - loss: 0.574 - 995s 18ms/step - loss: 0.5745\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55381/55381 [==============================] - ETA: 19:14 - loss: 0.46 - ETA: 19:33 - loss: 0.46 - ETA: 19:20 - loss: 0.46 - ETA: 19:01 - loss: 0.47 - ETA: 18:52 - loss: 0.47 - ETA: 18:50 - loss: 0.47 - ETA: 18:46 - loss: 0.47 - ETA: 18:40 - loss: 0.46 - ETA: 18:36 - loss: 0.47 - ETA: 18:32 - loss: 0.47 - ETA: 18:24 - loss: 0.47 - ETA: 18:17 - loss: 0.47 - ETA: 18:14 - loss: 0.47 - ETA: 18:05 - loss: 0.47 - ETA: 17:54 - loss: 0.47 - ETA: 17:48 - loss: 0.47 - ETA: 17:48 - loss: 0.46 - ETA: 17:44 - loss: 0.46 - ETA: 17:38 - loss: 0.46 - ETA: 17:33 - loss: 0.47 - ETA: 17:30 - loss: 0.47 - ETA: 17:23 - loss: 0.47 - ETA: 17:17 - loss: 0.46 - ETA: 17:13 - loss: 0.47 - ETA: 17:07 - loss: 0.47 - ETA: 17:01 - loss: 0.47 - ETA: 16:58 - loss: 0.47 - ETA: 16:54 - loss: 0.46 - ETA: 16:49 - loss: 0.46 - ETA: 16:44 - loss: 0.47 - ETA: 16:40 - loss: 0.47 - ETA: 16:34 - loss: 0.47 - ETA: 16:28 - loss: 0.46 - ETA: 16:25 - loss: 0.46 - ETA: 16:20 - loss: 0.47 - ETA: 16:14 - loss: 0.47 - ETA: 16:09 - loss: 0.46 - ETA: 16:04 - loss: 0.46 - ETA: 15:59 - loss: 0.46 - ETA: 15:53 - loss: 0.46 - ETA: 15:47 - loss: 0.46 - ETA: 15:43 - loss: 0.46 - ETA: 15:37 - loss: 0.46 - ETA: 15:31 - loss: 0.46 - ETA: 15:27 - loss: 0.46 - ETA: 15:22 - loss: 0.46 - ETA: 15:16 - loss: 0.46 - ETA: 15:11 - loss: 0.46 - ETA: 15:06 - loss: 0.46 - ETA: 15:00 - loss: 0.46 - ETA: 14:55 - loss: 0.46 - ETA: 14:50 - loss: 0.46 - ETA: 14:46 - loss: 0.46 - ETA: 14:40 - loss: 0.46 - ETA: 14:35 - loss: 0.46 - ETA: 14:30 - loss: 0.46 - ETA: 14:24 - loss: 0.46 - ETA: 14:18 - loss: 0.46 - ETA: 14:13 - loss: 0.46 - ETA: 14:08 - loss: 0.46 - ETA: 14:03 - loss: 0.46 - ETA: 13:58 - loss: 0.46 - ETA: 13:53 - loss: 0.46 - ETA: 13:48 - loss: 0.46 - ETA: 13:42 - loss: 0.46 - ETA: 13:37 - loss: 0.46 - ETA: 13:32 - loss: 0.46 - ETA: 13:26 - loss: 0.46 - ETA: 13:21 - loss: 0.46 - ETA: 13:16 - loss: 0.46 - ETA: 13:11 - loss: 0.46 - ETA: 13:05 - loss: 0.46 - ETA: 13:00 - loss: 0.46 - ETA: 12:55 - loss: 0.46 - ETA: 12:50 - loss: 0.46 - ETA: 12:44 - loss: 0.46 - ETA: 12:39 - loss: 0.46 - ETA: 12:33 - loss: 0.46 - ETA: 12:28 - loss: 0.46 - ETA: 12:22 - loss: 0.46 - ETA: 12:17 - loss: 0.46 - ETA: 12:12 - loss: 0.46 - ETA: 12:06 - loss: 0.46 - ETA: 12:01 - loss: 0.46 - ETA: 11:56 - loss: 0.46 - ETA: 11:50 - loss: 0.46 - ETA: 11:45 - loss: 0.46 - ETA: 11:39 - loss: 0.45 - ETA: 11:34 - loss: 0.45 - ETA: 11:29 - loss: 0.45 - ETA: 11:23 - loss: 0.45 - ETA: 11:18 - loss: 0.45 - ETA: 11:13 - loss: 0.45 - ETA: 11:07 - loss: 0.45 - ETA: 11:02 - loss: 0.46 - ETA: 10:57 - loss: 0.46 - ETA: 10:51 - loss: 0.46 - ETA: 10:46 - loss: 0.46 - ETA: 10:41 - loss: 0.46 - ETA: 10:36 - loss: 0.45 - ETA: 10:30 - loss: 0.45 - ETA: 10:25 - loss: 0.45 - ETA: 10:20 - loss: 0.45 - ETA: 10:14 - loss: 0.45 - ETA: 10:09 - loss: 0.45 - ETA: 10:04 - loss: 0.45 - ETA: 9:59 - loss: 0.4596 - ETA: 9:53 - loss: 0.459 - ETA: 9:48 - loss: 0.458 - ETA: 9:43 - loss: 0.459 - ETA: 9:38 - loss: 0.458 - ETA: 9:32 - loss: 0.458 - ETA: 9:27 - loss: 0.458 - ETA: 9:22 - loss: 0.458 - ETA: 9:16 - loss: 0.458 - ETA: 9:11 - loss: 0.457 - ETA: 9:06 - loss: 0.457 - ETA: 9:00 - loss: 0.457 - ETA: 8:54 - loss: 0.457 - ETA: 8:49 - loss: 0.457 - ETA: 8:44 - loss: 0.457 - ETA: 8:38 - loss: 0.457 - ETA: 8:33 - loss: 0.457 - ETA: 8:27 - loss: 0.457 - ETA: 8:22 - loss: 0.457 - ETA: 8:16 - loss: 0.457 - ETA: 8:11 - loss: 0.456 - ETA: 8:06 - loss: 0.457 - ETA: 8:00 - loss: 0.457 - ETA: 7:55 - loss: 0.457 - ETA: 7:49 - loss: 0.456 - ETA: 7:44 - loss: 0.456 - ETA: 7:38 - loss: 0.456 - ETA: 7:33 - loss: 0.456 - ETA: 7:27 - loss: 0.455 - ETA: 7:22 - loss: 0.455 - ETA: 7:17 - loss: 0.455 - ETA: 7:11 - loss: 0.455 - ETA: 7:06 - loss: 0.454 - ETA: 7:00 - loss: 0.454 - ETA: 6:55 - loss: 0.454 - ETA: 6:49 - loss: 0.454 - ETA: 6:44 - loss: 0.454 - ETA: 6:38 - loss: 0.454 - ETA: 6:33 - loss: 0.453 - ETA: 6:27 - loss: 0.453 - ETA: 6:22 - loss: 0.454 - ETA: 6:16 - loss: 0.454 - ETA: 6:11 - loss: 0.454 - ETA: 6:05 - loss: 0.453 - ETA: 6:00 - loss: 0.453 - ETA: 5:55 - loss: 0.453 - ETA: 5:49 - loss: 0.453 - ETA: 5:44 - loss: 0.452 - ETA: 5:38 - loss: 0.452 - ETA: 5:33 - loss: 0.451 - ETA: 5:28 - loss: 0.451 - ETA: 5:22 - loss: 0.451 - ETA: 5:16 - loss: 0.451 - ETA: 5:11 - loss: 0.450 - ETA: 5:06 - loss: 0.450 - ETA: 5:00 - loss: 0.450 - ETA: 4:55 - loss: 0.450 - ETA: 4:49 - loss: 0.450 - ETA: 4:44 - loss: 0.450 - ETA: 4:38 - loss: 0.450 - ETA: 4:33 - loss: 0.450 - ETA: 4:27 - loss: 0.450 - ETA: 4:22 - loss: 0.450 - ETA: 4:16 - loss: 0.450 - ETA: 4:11 - loss: 0.450 - ETA: 4:05 - loss: 0.450 - ETA: 3:59 - loss: 0.450 - ETA: 3:54 - loss: 0.450 - ETA: 3:48 - loss: 0.449 - ETA: 3:43 - loss: 0.450 - ETA: 3:37 - loss: 0.449 - ETA: 3:32 - loss: 0.449 - ETA: 3:26 - loss: 0.449 - ETA: 3:21 - loss: 0.449 - ETA: 3:15 - loss: 0.448 - ETA: 3:10 - loss: 0.448 - ETA: 3:04 - loss: 0.448 - ETA: 2:59 - loss: 0.448 - ETA: 2:53 - loss: 0.448 - ETA: 2:48 - loss: 0.447 - ETA: 2:42 - loss: 0.447 - ETA: 2:36 - loss: 0.446 - ETA: 2:31 - loss: 0.446 - ETA: 2:25 - loss: 0.446 - ETA: 2:20 - loss: 0.445 - ETA: 2:14 - loss: 0.445 - ETA: 2:09 - loss: 0.445 - ETA: 2:03 - loss: 0.445 - ETA: 1:58 - loss: 0.445 - ETA: 1:52 - loss: 0.445 - ETA: 1:47 - loss: 0.444 - ETA: 1:41 - loss: 0.444 - ETA: 1:36 - loss: 0.444 - ETA: 1:30 - loss: 0.444 - ETA: 1:25 - loss: 0.444 - ETA: 1:19 - loss: 0.444 - ETA: 1:13 - loss: 0.443 - ETA: 1:08 - loss: 0.443 - ETA: 1:02 - loss: 0.443 - ETA: 57s - loss: 0.443 - ETA: 51s - loss: 0.44 - ETA: 46s - loss: 0.44 - ETA: 40s - loss: 0.44 - ETA: 35s - loss: 0.44 - ETA: 29s - loss: 0.44 - ETA: 24s - loss: 0.44 - ETA: 18s - loss: 0.44 - ETA: 12s - loss: 0.44 - ETA: 7s - loss: 0.4422 - ETA: 1s - loss: 0.441 - 1201s 22ms/step - loss: 0.4419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2498b2acc50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = [xtrain_pad, xtrain_company] , y=ytrain_enc, batch_size=256, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55381,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_company.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([xvalid_pad, xvalid_company])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = [np.argmax(i) for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\narendran.thesma\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "predict_label = lbl_enc.inverse_transform(predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\narendran.thesma\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "yvalid_label = lbl_enc.inverse_transform(yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({'description' : xvalid.description, 'actuals' : yvalid_label, 'predictions' : predict_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8347948792989917"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_df.actuals, test_df.predictions,average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8378290542736432"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_df.actuals, test_df.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
