{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\narendran.thesma\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\narendran.thesma\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "import gensim\n",
    "import re, string\n",
    "import tinysegmenter\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "import pickle\n",
    "import feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          tqdm:   1.0KiB\n",
      "                         Model:   1.0KiB\n",
      "                    Sequential:   1.0KiB\n",
      "                     Embedding:   1.0KiB\n",
      "                          LSTM:   1.0KiB\n",
      "                         Dense:   1.0KiB\n",
      "                       Flatten:   1.0KiB\n",
      "                   Concatenate:   1.0KiB\n",
      "                       Dropout:   1.0KiB\n",
      "              SpatialDropout1D:   1.0KiB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' By Fred Cirera, after https://stackoverflow.com/a/1094933/1870254'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name,value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name,sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\narendran.thesma\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (20,24,25,27,34,42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>companyName</th>\n",
       "      <th>currency</th>\n",
       "      <th>language</th>\n",
       "      <th>countryName</th>\n",
       "      <th>distributorName</th>\n",
       "      <th>ageGroup</th>\n",
       "      <th>articleId</th>\n",
       "      <th>colors</th>\n",
       "      <th>...</th>\n",
       "      <th>CURRENT_PRICE_IN_EUR_OUTPUT</th>\n",
       "      <th>INITIAL_PRICE_IN_SELECTED_CURRENCY_OUTPUT</th>\n",
       "      <th>CURRENT_PRICE_IN_SELECTED_CURRENCY_OUTPUT</th>\n",
       "      <th>SELECTED_CURRENCY_OUTPUT</th>\n",
       "      <th>PRODUCT_INTRODUCTION_DATE_OUTPUT</th>\n",
       "      <th>DISCOUNTED_SINCE_OUTPUT</th>\n",
       "      <th>PRODUCT_EXIT_DATE_OUTPUT</th>\n",
       "      <th>PRODUCT_DESCRIPTION_OUTPUT</th>\n",
       "      <th>PRODUCT_URL_OUTPUT</th>\n",
       "      <th>IMAGE_SERVER_URL_OUTPUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>03/17/2016</td>\n",
       "      <td>adidas</td>\n",
       "      <td>JPY</td>\n",
       "      <td>ja-JP</td>\n",
       "      <td>jpn</td>\n",
       "      <td>own ecom</td>\n",
       "      <td>adults</td>\n",
       "      <td>AA0647</td>\n",
       "      <td>ホワイト</td>\n",
       "      <td>...</td>\n",
       "      <td>24.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2/29/2016</td>\n",
       "      <td>9/18/2017</td>\n",
       "      <td>11/21/2017</td>\n",
       "      <td>3æ¬ç·ã®ãã¶ã¤ã³ãæ°ãããªã£ãã¬...</td>\n",
       "      <td>https://shop.adidas.jp/products/AA0647/</td>\n",
       "      <td>http://usporamap287.am.adsint.biz/zoomimages/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>03/22/2016</td>\n",
       "      <td>adidas</td>\n",
       "      <td>JPY</td>\n",
       "      <td>ja-JP</td>\n",
       "      <td>jpn</td>\n",
       "      <td>own ecom</td>\n",
       "      <td>adults</td>\n",
       "      <td>AA0647</td>\n",
       "      <td>ホワイト</td>\n",
       "      <td>...</td>\n",
       "      <td>24.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2/29/2016</td>\n",
       "      <td>9/18/2017</td>\n",
       "      <td>11/21/2017</td>\n",
       "      <td>3æ¬ç·ã®ãã¶ã¤ã³ãæ°ãããªã£ãã¬...</td>\n",
       "      <td>https://shop.adidas.jp/products/AA0647/</td>\n",
       "      <td>http://usporamap287.am.adsint.biz/zoomimages/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>03/30/2016</td>\n",
       "      <td>adidas</td>\n",
       "      <td>JPY</td>\n",
       "      <td>ja-JP</td>\n",
       "      <td>jpn</td>\n",
       "      <td>own ecom</td>\n",
       "      <td>adults</td>\n",
       "      <td>AA0647</td>\n",
       "      <td>ホワイト</td>\n",
       "      <td>...</td>\n",
       "      <td>24.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2/29/2016</td>\n",
       "      <td>9/18/2017</td>\n",
       "      <td>11/21/2017</td>\n",
       "      <td>3æ¬ç·ã®ãã¶ã¤ã³ãæ°ãããªã£ãã¬...</td>\n",
       "      <td>https://shop.adidas.jp/products/AA0647/</td>\n",
       "      <td>http://usporamap287.am.adsint.biz/zoomimages/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>04/06/2016</td>\n",
       "      <td>adidas</td>\n",
       "      <td>JPY</td>\n",
       "      <td>ja-JP</td>\n",
       "      <td>jpn</td>\n",
       "      <td>own ecom</td>\n",
       "      <td>adults</td>\n",
       "      <td>AA0647</td>\n",
       "      <td>ホワイト</td>\n",
       "      <td>...</td>\n",
       "      <td>24.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2/29/2016</td>\n",
       "      <td>9/18/2017</td>\n",
       "      <td>11/21/2017</td>\n",
       "      <td>3æ¬ç·ã®ãã¶ã¤ã³ãæ°ãããªã£ãã¬...</td>\n",
       "      <td>https://shop.adidas.jp/products/AA0647/</td>\n",
       "      <td>http://usporamap287.am.adsint.biz/zoomimages/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>04/14/2016</td>\n",
       "      <td>adidas</td>\n",
       "      <td>JPY</td>\n",
       "      <td>ja-JP</td>\n",
       "      <td>jpn</td>\n",
       "      <td>own ecom</td>\n",
       "      <td>adults</td>\n",
       "      <td>AA0647</td>\n",
       "      <td>ホワイト</td>\n",
       "      <td>...</td>\n",
       "      <td>24.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>24.3</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2/29/2016</td>\n",
       "      <td>9/18/2017</td>\n",
       "      <td>11/21/2017</td>\n",
       "      <td>3æ¬ç·ã®ãã¶ã¤ã³ãæ°ãããªã£ãã¬...</td>\n",
       "      <td>https://shop.adidas.jp/products/AA0647/</td>\n",
       "      <td>http://usporamap287.am.adsint.biz/zoomimages/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        date companyName currency language countryName  \\\n",
       "0           0  03/17/2016      adidas      JPY    ja-JP         jpn   \n",
       "1           1  03/22/2016      adidas      JPY    ja-JP         jpn   \n",
       "2           2  03/30/2016      adidas      JPY    ja-JP         jpn   \n",
       "3           3  04/06/2016      adidas      JPY    ja-JP         jpn   \n",
       "4           4  04/14/2016      adidas      JPY    ja-JP         jpn   \n",
       "\n",
       "  distributorName ageGroup articleId colors  \\\n",
       "0        own ecom   adults    AA0647   ホワイト   \n",
       "1        own ecom   adults    AA0647   ホワイト   \n",
       "2        own ecom   adults    AA0647   ホワイト   \n",
       "3        own ecom   adults    AA0647   ホワイト   \n",
       "4        own ecom   adults    AA0647   ホワイト   \n",
       "\n",
       "                         ...                          \\\n",
       "0                        ...                           \n",
       "1                        ...                           \n",
       "2                        ...                           \n",
       "3                        ...                           \n",
       "4                        ...                           \n",
       "\n",
       "  CURRENT_PRICE_IN_EUR_OUTPUT  INITIAL_PRICE_IN_SELECTED_CURRENCY_OUTPUT  \\\n",
       "0                        24.3                                       24.3   \n",
       "1                        24.3                                       24.3   \n",
       "2                        24.3                                       24.3   \n",
       "3                        24.3                                       24.3   \n",
       "4                        24.3                                       24.3   \n",
       "\n",
       "   CURRENT_PRICE_IN_SELECTED_CURRENCY_OUTPUT SELECTED_CURRENCY_OUTPUT  \\\n",
       "0                                       24.3                      EUR   \n",
       "1                                       24.3                      EUR   \n",
       "2                                       24.3                      EUR   \n",
       "3                                       24.3                      EUR   \n",
       "4                                       24.3                      EUR   \n",
       "\n",
       "  PRODUCT_INTRODUCTION_DATE_OUTPUT DISCOUNTED_SINCE_OUTPUT  \\\n",
       "0                        2/29/2016               9/18/2017   \n",
       "1                        2/29/2016               9/18/2017   \n",
       "2                        2/29/2016               9/18/2017   \n",
       "3                        2/29/2016               9/18/2017   \n",
       "4                        2/29/2016               9/18/2017   \n",
       "\n",
       "  PRODUCT_EXIT_DATE_OUTPUT                         PRODUCT_DESCRIPTION_OUTPUT  \\\n",
       "0               11/21/2017  3æ¬ç·ã®ãã¶ã¤ã³ãæ°ãããªã£ãã¬...   \n",
       "1               11/21/2017  3æ¬ç·ã®ãã¶ã¤ã³ãæ°ãããªã£ãã¬...   \n",
       "2               11/21/2017  3æ¬ç·ã®ãã¶ã¤ã³ãæ°ãããªã£ãã¬...   \n",
       "3               11/21/2017  3æ¬ç·ã®ãã¶ã¤ã³ãæ°ãããªã£ãã¬...   \n",
       "4               11/21/2017  3æ¬ç·ã®ãã¶ã¤ã³ãæ°ãããªã£ãã¬...   \n",
       "\n",
       "                        PRODUCT_URL_OUTPUT  \\\n",
       "0  https://shop.adidas.jp/products/AA0647/   \n",
       "1  https://shop.adidas.jp/products/AA0647/   \n",
       "2  https://shop.adidas.jp/products/AA0647/   \n",
       "3  https://shop.adidas.jp/products/AA0647/   \n",
       "4  https://shop.adidas.jp/products/AA0647/   \n",
       "\n",
       "                             IMAGE_SERVER_URL_OUTPUT  \n",
       "0  http://usporamap287.am.adsint.biz/zoomimages/1...  \n",
       "1  http://usporamap287.am.adsint.biz/zoomimages/1...  \n",
       "2  http://usporamap287.am.adsint.biz/zoomimages/1...  \n",
       "3  http://usporamap287.am.adsint.biz/zoomimages/1...  \n",
       "4  http://usporamap287.am.adsint.biz/zoomimages/1...  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Merged/JPN-1/data_joined_deu.csv\", encoding='utf-8')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2008008 entries, 0 to 2008007\n",
      "Data columns (total 62 columns):\n",
      "Unnamed: 0                                   int64\n",
      "date                                         object\n",
      "companyName                                  object\n",
      "currency                                     object\n",
      "language                                     object\n",
      "countryName                                  object\n",
      "distributorName                              object\n",
      "ageGroup                                     object\n",
      "articleId                                    object\n",
      "colors                                       object\n",
      "colorGroup                                   object\n",
      "consumerRating                               float64\n",
      "currentPrice                                 float64\n",
      "description                                  object\n",
      "discountedSince                              object\n",
      "division                                     object\n",
      "gender                                       object\n",
      "group                                        object\n",
      "imageUrl                                     object\n",
      "initialPrice                                 float64\n",
      "modelNumber                                  object\n",
      "name4                                        object\n",
      "ped                                          object\n",
      "pid                                          object\n",
      "sportsCategory                               object\n",
      "subBrand                                     object\n",
      "technologies                                 object\n",
      "type                                         object\n",
      "url                                          object\n",
      "key                                          object\n",
      "COMPANY                                      object\n",
      "COUNTRY_OUTPUT                               object\n",
      "DISTRIBUTOR_OUTPUT                           object\n",
      "ARTICLE_ID_OUTPUT                            object\n",
      "MODEL_NUMBER_OUTPUT                          object\n",
      "ARTICLE_NAME_OUTPUT                          object\n",
      "SUBBRAND_OUTPUT                              object\n",
      "SPORTS_CATEGORY_OUTPUT                       object\n",
      "PRODUCT_DIVISION_OUTPUT                      object\n",
      "PRODUCT_GROUP_OUTPUT                         object\n",
      "PRODUCT_TYPE_OUTPUT                          object\n",
      "FRANCHISE_OUTPUT                             object\n",
      "TECHNOLOGIES_OUTPUT                          object\n",
      "COLOUR_GROUP_OUTPUT                          object\n",
      "COLOUR_OUTPUT                                object\n",
      "GENDER_OUTPUT                                object\n",
      "AGE_GROUP_OUTPUT                             object\n",
      "CONSUMER_RATING_OUTPUT                       float64\n",
      "INITIAL_PRICE_IN_LOCAL_CURRENCY_OUTPUT       float64\n",
      "CURRENT_PRICE_IN_LOCAL_CURRENCY_OUTPUT       float64\n",
      "LOCAL_CURRENCY_OUTPUT                        object\n",
      "INITIAL_PRICE_IN_EUR_OUTPUT                  float64\n",
      "CURRENT_PRICE_IN_EUR_OUTPUT                  float64\n",
      "INITIAL_PRICE_IN_SELECTED_CURRENCY_OUTPUT    float64\n",
      "CURRENT_PRICE_IN_SELECTED_CURRENCY_OUTPUT    float64\n",
      "SELECTED_CURRENCY_OUTPUT                     object\n",
      "PRODUCT_INTRODUCTION_DATE_OUTPUT             object\n",
      "DISCOUNTED_SINCE_OUTPUT                      object\n",
      "PRODUCT_EXIT_DATE_OUTPUT                     object\n",
      "PRODUCT_DESCRIPTION_OUTPUT                   object\n",
      "PRODUCT_URL_OUTPUT                           object\n",
      "IMAGE_SERVER_URL_OUTPUT                      object\n",
      "dtypes: float64(10), int64(1), object(51)\n",
      "memory usage: 949.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.date = pd.to_datetime(data.date, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.date.dt.year > 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-10-15 00:00:00')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(data.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "    :param actual: Array containing the actual target classes\n",
    "    :param predicted: Matrix with class predictions, one probability per class\n",
    "    \"\"\"\n",
    "    # Convert 'actual' to a binary array if it's not already:\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "\n",
    "    clip = np.clip(predicted, eps, 1 - eps)\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip))\n",
    "    return -1.0 / rows * vsota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'date', 'companyName', 'currency', 'language',\n",
       "       'countryName', 'distributorName', 'ageGroup', 'articleId', 'colors',\n",
       "       'colorGroup', 'consumerRating', 'currentPrice', 'description',\n",
       "       'discountedSince', 'division', 'gender', 'group', 'imageUrl',\n",
       "       'initialPrice', 'modelNumber', 'name4', 'ped', 'pid', 'sportsCategory',\n",
       "       'subBrand', 'technologies', 'type', 'url', 'key', 'COMPANY',\n",
       "       'COUNTRY_OUTPUT', 'DISTRIBUTOR_OUTPUT', 'ARTICLE_ID_OUTPUT',\n",
       "       'MODEL_NUMBER_OUTPUT', 'ARTICLE_NAME_OUTPUT', 'SUBBRAND_OUTPUT',\n",
       "       'SPORTS_CATEGORY_OUTPUT', 'PRODUCT_DIVISION_OUTPUT',\n",
       "       'PRODUCT_GROUP_OUTPUT', 'PRODUCT_TYPE_OUTPUT', 'FRANCHISE_OUTPUT',\n",
       "       'TECHNOLOGIES_OUTPUT', 'COLOUR_GROUP_OUTPUT', 'COLOUR_OUTPUT',\n",
       "       'GENDER_OUTPUT', 'AGE_GROUP_OUTPUT', 'CONSUMER_RATING_OUTPUT',\n",
       "       'INITIAL_PRICE_IN_LOCAL_CURRENCY_OUTPUT',\n",
       "       'CURRENT_PRICE_IN_LOCAL_CURRENCY_OUTPUT', 'LOCAL_CURRENCY_OUTPUT',\n",
       "       'INITIAL_PRICE_IN_EUR_OUTPUT', 'CURRENT_PRICE_IN_EUR_OUTPUT',\n",
       "       'INITIAL_PRICE_IN_SELECTED_CURRENCY_OUTPUT',\n",
       "       'CURRENT_PRICE_IN_SELECTED_CURRENCY_OUTPUT', 'SELECTED_CURRENCY_OUTPUT',\n",
       "       'PRODUCT_INTRODUCTION_DATE_OUTPUT', 'DISCOUNTED_SINCE_OUTPUT',\n",
       "       'PRODUCT_EXIT_DATE_OUTPUT', 'PRODUCT_DESCRIPTION_OUTPUT',\n",
       "       'PRODUCT_URL_OUTPUT', 'IMAGE_SERVER_URL_OUTPUT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req = data.loc[:,[\"date\", \"companyName\", \"distributorName\", \"ageGroup\",\"description\", \"division\", \"gender\", \"group\", \"name4\", \"sportsCategory\",\"subBrand\", \"SUBBRAND_OUTPUT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req[\"ID\"] = data_req.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_req = data_req.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_req[\"description\"]  = data_req[\"COMPANY\"] +\" \" + data_req[\"ARTICLE NAME\"] +\" \" + data_req[\"PRODUCT DESCRIPTION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_req = data_req.drop([\"COUNTRY\", \"ARTICLE NAME\", \"PRODUCT DESCRIPTION\", \"PRODUCT URL\"], axis = 1)\n",
    "# data_req.columns = [\"COMPANY\", \"subBrand\", \"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req[[\"companyName\", \"distributorName\", \"ageGroup\",\"description\", \"division\", \"gender\", \"group\",\"name4\", \"sportsCategory\", \"subBrand\"]] = data_req[[\"companyName\", \"distributorName\", \"ageGroup\",\"description\", \"division\", \"gender\", \"group\", \"name4\", \"sportsCategory\", \"subBrand\"]].fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req = data_req.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date               0\n",
       "companyName        0\n",
       "distributorName    0\n",
       "ageGroup           0\n",
       "description        0\n",
       "division           0\n",
       "gender             0\n",
       "group              0\n",
       "name4              0\n",
       "sportsCategory     0\n",
       "subBrand           0\n",
       "SUBBRAND_OUTPUT    0\n",
       "ID                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_req.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(data_req[\"SUBBRAND_OUTPUT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"y_Jpn_lbl_enc.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(lbl_enc, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req[[\"companyName\", \"distributorName\", \"ageGroup\", \"division\", \"gender\", \"group\", \"sportsCategory\", \"subBrand\"]] = \\\n",
    "    data_req[[\"companyName\", \"distributorName\", \"ageGroup\", \"division\", \"gender\", \"group\", \"sportsCategory\", \"subBrand\"]].apply(preprocessing.LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_req[\"SUBRAND_OUTPUT_ENC\"] = data_req[[\"SUBBRAND_OUTPUT\"]].apply(preprocessing.LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [\"companyName\", \"distributorName\", \"ageGroup\",\"description\", \"division\", \"gender\", \"group\",\"name4\", \"sportsCategory\", \"subBrand\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "performance       870429\n",
       "sport inspired    648380\n",
       "Name: SUBBRAND_OUTPUT, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_req[\"SUBBRAND_OUTPUT\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req[\"SUBRAND_OUTPUT_ENC\"] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"SUBRAND_OUTPUT_ENC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>companyName</th>\n",
       "      <th>distributorName</th>\n",
       "      <th>ageGroup</th>\n",
       "      <th>description</th>\n",
       "      <th>division</th>\n",
       "      <th>gender</th>\n",
       "      <th>group</th>\n",
       "      <th>name4</th>\n",
       "      <th>sportsCategory</th>\n",
       "      <th>subBrand</th>\n",
       "      <th>SUBBRAND_OUTPUT</th>\n",
       "      <th>ID</th>\n",
       "      <th>SUBRAND_OUTPUT_ENC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>489199</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>幅の広めのラージサイズ。長時間の着用でも疲れを感じさせない人間工学から考えられたテンプル形状...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>サングラス a164 6050 adivista l</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>performance</td>\n",
       "      <td>489199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489200</th>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>幅の広めのラージサイズ。長時間の着用でも疲れを感じさせない人間工学から考えられたテンプル形状...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>サングラス a164 6050 adivista l</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>performance</td>\n",
       "      <td>489200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489201</th>\n",
       "      <td>2017-01-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>幅の広めのラージサイズ。長時間の着用でも疲れを感じさせない人間工学から考えられたテンプル形状...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>サングラス a164 6050 adivista l</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>performance</td>\n",
       "      <td>489201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489202</th>\n",
       "      <td>2017-01-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>幅の広めのラージサイズ。長時間の着用でも疲れを感じさせない人間工学から考えられたテンプル形状...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>サングラス a164 6050 adivista l</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>performance</td>\n",
       "      <td>489202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489203</th>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>幅の広めのラージサイズ。長時間の着用でも疲れを感じさせない人間工学から考えられたテンプル形状...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>サングラス a164 6050 adivista l</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>performance</td>\n",
       "      <td>489203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  companyName  distributorName  ageGroup  \\\n",
       "489199  2017-01-02            0                0         0   \n",
       "489200  2017-01-11            0                0         0   \n",
       "489201  2017-01-17            0                0         0   \n",
       "489202  2017-01-25            0                0         0   \n",
       "489203  2017-01-30            0                0         0   \n",
       "\n",
       "                                              description  division  gender  \\\n",
       "489199  幅の広めのラージサイズ。長時間の着用でも疲れを感じさせない人間工学から考えられたテンプル形状...         1       1   \n",
       "489200  幅の広めのラージサイズ。長時間の着用でも疲れを感じさせない人間工学から考えられたテンプル形状...         1       1   \n",
       "489201  幅の広めのラージサイズ。長時間の着用でも疲れを感じさせない人間工学から考えられたテンプル形状...         1       1   \n",
       "489202  幅の広めのラージサイズ。長時間の着用でも疲れを感じさせない人間工学から考えられたテンプル形状...         1       1   \n",
       "489203  幅の広めのラージサイズ。長時間の着用でも疲れを感じさせない人間工学から考えられたテンプル形状...         1       1   \n",
       "\n",
       "        group                       name4  sportsCategory  subBrand  \\\n",
       "489199     26  サングラス a164 6050 adivista l              12         5   \n",
       "489200     26  サングラス a164 6050 adivista l              12         5   \n",
       "489201     26  サングラス a164 6050 adivista l              21         5   \n",
       "489202     26  サングラス a164 6050 adivista l              12         5   \n",
       "489203     26  サングラス a164 6050 adivista l              12         5   \n",
       "\n",
       "       SUBBRAND_OUTPUT      ID  SUBRAND_OUTPUT_ENC  \n",
       "489199     performance  489199                   0  \n",
       "489200     performance  489200                   0  \n",
       "489201     performance  489201                   0  \n",
       "489202     performance  489202                   0  \n",
       "489203     performance  489203                   0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_req.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xtrain, xvalid, ytrain, yvalid = train_test_split(data_req[X], y, \n",
    "#                                                   stratify=y, \n",
    "#                                                   random_state=42, \n",
    "#                                                   test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_req[data_req.date < \"2018-05-01\"]\n",
    "valid = data_req[(data_req.date >= \"2018-05-01\") & (data_req.date <= \"2018-07-31\")]\n",
    "test = data_req[data_req.date >= \"2018-08-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feather.write_dataframe(train, \"train_japan_input_output\")\n",
    "feather.write_dataframe(valid, \"valid_japan_input_output\")\n",
    "feather.write_dataframe(test, \"test_japan_input_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2018-04-23', '2018-05-03', '2018-07-31', '2018-08-08')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(train.date), min(valid.date), max(valid.date), min(test.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = train[X]\n",
    "xvalid = valid[X]\n",
    "xtest = test[X]\n",
    "\n",
    "ytrain = train[y]\n",
    "yvalid = valid[y]\n",
    "ytest = test[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿|¡§£₤‘’])')\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data, data_req, train, test, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train = [tokenize(x) for x in xtrain.description]\n",
    "texts_valid = [tokenize(x) for x in xvalid.description]\n",
    "texts_test = [tokenize(x) for x in xtest.description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "del xtrain, xvalid, xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = tinysegmenter.TinySegmenter()\n",
    "tokenized_text_train = [segmenter.tokenize(x) for x in texts_train]\n",
    "tokenized_text_valid = [segmenter.tokenize(x) for x in texts_valid]\n",
    "tokenized_text_test = [segmenter.tokenize(x) for x in texts_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "del texts_train, texts_valid, texts_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"train_tokenizer_japan.pkl\"\n",
    "# filehandler = open(filename, 'wb')\n",
    "# pickle.dump(tokenized_text_train, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"train_tokenizer_japan.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(tokenized_text_train, filehandler)\n",
    "\n",
    "filename = \"valid_tokenizer_japan.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(tokenized_text_valid, filehandler)\n",
    "\n",
    "filename = \"test_tokenizer_japan.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(tokenized_text_test, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_pi1 = open('train_tokenizer_japan.pkl', 'rb')\n",
    "# chk = pickle.load(file_pi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_pi1 = open('train_tokenizer_japan.pkl', 'rb')\n",
    "# tokenized_text_train = pickle.load(file_pi1)\n",
    "\n",
    "# file_pi2 = open('valid_tokenizer_japan.pkl', 'rb')\n",
    "# tokenized_text_valid = pickle.load(file_pi2)\n",
    "\n",
    "# file_pi3 = open('test_tokenizer_japan.pkl', 'rb')\n",
    "# tokenized_text_test = pickle.load(file_pi3)\n",
    "\n",
    "train = feather.read_dataframe(\"train_japan_input_output\")\n",
    "valid = feather.read_dataframe(\"valid_japan_input_output\")\n",
    "test = feather.read_dataframe(\"test_japan_input_output\")\n",
    "\n",
    "X = [\"companyName\", \"distributorName\", \"ageGroup\",\"description\", \"division\", \"gender\", \"group\",\"name4\", \"sportsCategory\", \"subBrand\"]\n",
    "y = \"SUBRAND_OUTPUT_ENC\"\n",
    "\n",
    "xtrain = train[X]\n",
    "xvalid = valid[X]\n",
    "xtest = test[X]\n",
    "\n",
    "ytrain = train[y]\n",
    "yvalid = valid[y]\n",
    "ytest = test[y]\n",
    "\n",
    "del train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_token_train = [' '.join(x) for x in tokenized_text_train]\n",
    "joined_token_valid = [' '.join(x) for x in tokenized_text_valid]\n",
    "joined_token_test = [' '.join(x) for x in tokenized_text_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tokenized_text_train,tokenized_text_valid, tokenized_text_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"joined_word_model.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(joined_token_train, filehandler)\n",
    "\n",
    "filename = \"joined_token_valid.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(joined_token_valid, filehandler)\n",
    "\n",
    "filename = \"joined_token_test.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(joined_token_test, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pi1 = open('joined_token_train.pkl', 'rb')\n",
    "joined_token_train = pickle.load(file_pi1)\n",
    "\n",
    "file_pi2 = open('joined_token_valid.pkl', 'rb')\n",
    "joined_token_valid = pickle.load(file_pi2)\n",
    "\n",
    "file_pi3 = open('joined_token_test.pkl', 'rb')\n",
    "joined_token_test = pickle.load(file_pi3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using keras tokenizer here\n",
    "token = text.Tokenizer(num_words=None)\n",
    "max_len = 300\n",
    "\n",
    "token.fit_on_texts(joined_token_train + joined_token_valid + joined_token_test)\n",
    "xtrain_seq = token.texts_to_sequences(joined_token_train)\n",
    "xvalid_seq = token.texts_to_sequences(joined_token_valid)\n",
    "xtest_seq = token.texts_to_sequences(joined_token_test)\n",
    "\n",
    "# zero pad the sequences\n",
    "xtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\n",
    "xvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\n",
    "xtest_pad = sequence.pad_sequences(xtest_seq, maxlen=max_len)\n",
    "\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"japan_xtrain_pad.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(xtrain_pad, filehandler)\n",
    "\n",
    "filename = \"japan_xvalid_pad.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(xvalid_pad, filehandler)\n",
    "\n",
    "filename = \"japan_xtest_pad.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(xtest_pad, filehandler)\n",
    "\n",
    "filename = \"japan_word_index.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(word_index, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute\n",
    "file_pi1 = open('japan_word_index.pkl', 'rb')\n",
    "word_index = pickle.load(file_pi1)\n",
    "\n",
    "file_pi1 = open('japan_xtrain_pad.pkl', 'rb')\n",
    "xtrain_pad = pickle.load(file_pi1)\n",
    "\n",
    "file_pi1 = open('japan_xvalid_pad.pkl', 'rb')\n",
    "xvalid_pad = pickle.load(file_pi1)\n",
    "\n",
    "file_pi1 = open('japan_xtest_pad.pkl', 'rb')\n",
    "xtest_pad = pickle.load(file_pi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_keras_words = list(token.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "keras_tokenised_words = [text_to_word_sequence(x, lower=False) for x in (joined_token_train + joined_token_valid + joined_token_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "del joined_token_train, joined_token_test, joined_token_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model = gensim.models.Word2Vec(keras_tokenised_words, size=300, min_count=1, window=5, iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del keras_tokenised_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"joined_word_model.pkl\"\n",
    "filehandler = open(filename, 'wb')\n",
    "pickle.dump(word_model, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute\n",
    "file_pi1 = open('joined_word_model.pkl', 'rb')\n",
    "word_model = pickle.load(file_pi1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Everything together here. MY REFERENCE\n",
    "\n",
    "train = feather.read_dataframe(\"train_japan_input_output\")\n",
    "valid = feather.read_dataframe(\"valid_japan_input_output\")\n",
    "test = feather.read_dataframe(\"test_japan_input_output\")\n",
    "\n",
    "X = [\"companyName\", \"distributorName\", \"ageGroup\",\"description\", \"division\", \"gender\", \"group\",\"name4\", \"sportsCategory\", \"subBrand\"]\n",
    "y = \"SUBRAND_OUTPUT_ENC\"\n",
    "\n",
    "xtrain = train[X]\n",
    "xvalid = valid[X]\n",
    "xtest = test[X]\n",
    "\n",
    "ytrain = train[y]\n",
    "yvalid = valid[y]\n",
    "ytest = test[y]\n",
    "\n",
    "del train, valid, test\n",
    "\n",
    "\n",
    "file_pi1 = open('japan_word_index.pkl', 'rb')\n",
    "word_index = pickle.load(file_pi1)\n",
    "\n",
    "file_pi1 = open('japan_xtrain_pad.pkl', 'rb')\n",
    "xtrain_pad = pickle.load(file_pi1)\n",
    "\n",
    "file_pi1 = open('japan_xvalid_pad.pkl', 'rb')\n",
    "xvalid_pad = pickle.load(file_pi1)\n",
    "\n",
    "file_pi1 = open('japan_xtest_pad.pkl', 'rb')\n",
    "xtest_pad = pickle.load(file_pi1)\n",
    "\n",
    "file_pi1 = open('joined_word_model.pkl', 'rb')\n",
    "word_model = pickle.load(file_pi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 35613/35613 [00:00<00:00, 145550.89it/s]\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = word_model.wv[word]\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-2.01717353, -0.99233973, -1.08852887, ..., -3.06032372,\n",
       "         1.49680293, -1.42993021],\n",
       "       [-0.50516093, -0.59006751, -1.52408195, ..., -1.79377186,\n",
       "         0.24416398, -3.26893067],\n",
       "       ...,\n",
       "       [ 0.04895103, -0.03756456, -0.01938329, ..., -0.00814213,\n",
       "        -0.04584658, -0.08762853],\n",
       "       [ 0.00822348, -0.0179678 ,  0.033421  , ..., -0.03149183,\n",
       "        -0.02039536,  0.0701666 ],\n",
       "       [ 0.05051522,  0.02162825, -0.04719217, ..., -0.00573608,\n",
       "         0.04827156, -0.06946177]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: meant to receive sequences of 300 integers\n",
    "main_input = Input(shape=(300,), name='main_input')\n",
    "max_len = 300\n",
    "# This embedding layer will encode the input sequence\n",
    "# into a sequence of dense 300-dimensional vectors.\n",
    "x = Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False)(main_input)\n",
    "\n",
    "x = SpatialDropout1D(0.3)(x)\n",
    "\n",
    "\n",
    "# A LSTM will transform the vector sequence into a single vector,\n",
    "# containing information about the entire sequence\n",
    "lstm_out = LSTM(300, dropout=0.3, recurrent_dropout=0.3)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_input_1 = Input((1,), name='aux_input_1')\n",
    "auxiliary_input_2 = Input((1,), name='aux_input_2')\n",
    "auxiliary_input_3 = Input((1,), name='aux_input_3')\n",
    "auxiliary_input_4 = Input((1,), name='aux_input_4')\n",
    "auxiliary_input_5 = Input((1,), name='aux_input_5')\n",
    "auxiliary_input_6 = Input((1,), name='aux_input_6')\n",
    "auxiliary_input_7 = Input((1,), name='aux_input_7')\n",
    "auxiliary_input_8 = Input((1,), name='aux_input_8')\n",
    "auxiliary_input_9 = Input((1,), name='aux_input_9')\n",
    "\n",
    "x = keras.layers.concatenate([lstm_out, auxiliary_input_1, auxiliary_input_2, auxiliary_input_3, auxiliary_input_4, \n",
    "                             auxiliary_input_5, auxiliary_input_6, auxiliary_input_7, \n",
    "                             auxiliary_input_8, auxiliary_input_9], axis = 1)\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.7)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# Output softmax layer\n",
    "main_output = Dense(2, activation='softmax', name='main_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[main_input, auxiliary_input_1, auxiliary_input_2, auxiliary_input_3, auxiliary_input_4, auxiliary_input_5, auxiliary_input_6, auxiliary_input_7, auxiliary_input_8, auxiliary_input_9], outputs=main_output)\n",
    "rmsprop = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0, clipvalue=0.5)\n",
    "model.compile(loss='categorical_crossentropy', optimizer= 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to binarize the labels for the neural net\n",
    "ytrain_enc = np_utils.to_categorical(ytrain)\n",
    "yvalid_enc = np_utils.to_categorical(yvalid)\n",
    "ytest_enc = np_utils.to_categorical(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le = preprocessing.LabelEncoder()\n",
    "# xtrain_company = np.array(xtrain.COMPANY)\n",
    "# xtrain_company = le.fit_transform(xtrain_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xvalid_company = np.array(xvalid.COMPANY)\n",
    "# xvalid_company = le.fit_transform(xvalid_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "xtrain_companyName = np.array(xtrain.companyName)\n",
    "xtrain_companyName = le.fit_transform(xtrain_companyName)\n",
    "# xtrain_companyName = (xtrain_companyName - xtrain_companyName.mean())/xtrain_companyName.std()\n",
    "\n",
    "xtrain_distributorName = np.array(xtrain.distributorName)\n",
    "xtrain_distributorName = le.fit_transform(xtrain_distributorName)\n",
    "# xtrain_distributorName = (xtrain_distributorName - xtrain_distributorName.mean())/xtrain_distributorName.std()\n",
    "\n",
    "xtrain_ageGroup = np.array(xtrain.ageGroup)\n",
    "xtrain_ageGroup = le.fit_transform(xtrain_ageGroup)\n",
    "# xtrain_ageGroup = (xtrain_ageGroup - xtrain_ageGroup.mean())/xtrain_ageGroup.std()\n",
    "\n",
    "xtrain_division = np.array(xtrain.division)\n",
    "xtrain_division = le.fit_transform(xtrain_division)\n",
    "# xtrain_division = (xtrain_division - xtrain_division.mean())/xtrain_division.std()\n",
    "\n",
    "xtrain_gender = np.array(xtrain.gender)\n",
    "xtrain_gender = le.fit_transform(xtrain_gender)\n",
    "# xtrain_gender = (xtrain_gender - xtrain_gender.mean())/xtrain_gender.std()\n",
    "\n",
    "xtrain_group = np.array(xtrain.group)\n",
    "xtrain_group = le.fit_transform(xtrain_group)\n",
    "# xtrain_group = (xtrain_group - xtrain_group.mean())/xtrain_group.std()\n",
    "\n",
    "xtrain_name4 = np.array(xtrain.name4)\n",
    "xtrain_name4 = le.fit_transform(xtrain_name4)\n",
    "# xtrain_name4 = (xtrain_name4 - xtrain_name4.mean())/xtrain_name4.std()\n",
    "\n",
    "\n",
    "xtrain_sportsCategory = np.array(xtrain.sportsCategory)\n",
    "xtrain_sportsCategory = le.fit_transform(xtrain_sportsCategory)\n",
    "# xtrain_sportsCategory = (xtrain_sportsCategory - xtrain_sportsCategory.mean())/xtrain_sportsCategory.std()\n",
    "\n",
    "\n",
    "xtrain_subBrand = np.array(xtrain.subBrand)\n",
    "xtrain_subBrand = le.fit_transform(xtrain_subBrand)\n",
    "# xtrain_subBrand = (xtrain_subBrand - xtrain_subBrand.mean())/xtrain_subBrand.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xtrain_sportsCategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvalid_companyName = np.array(xvalid.companyName)\n",
    "xvalid_companyName = le.fit_transform(xvalid_companyName)\n",
    "# xvalid_companyName = (xvalid_companyName - xvalid_companyName.mean())/xvalid_companyName.std()\n",
    "\n",
    "xvalid_distributorName = np.array(xvalid.distributorName)\n",
    "xvalid_distributorName = le.fit_transform(xvalid_distributorName)\n",
    "# xvalid_distributorName = (xvalid_distributorName - xvalid_distributorName.mean())/xvalid_distributorName.std()\n",
    "\n",
    "xvalid_ageGroup = np.array(xvalid.ageGroup)\n",
    "xvalid_ageGroup = le.fit_transform(xvalid_ageGroup)\n",
    "# xvalid_ageGroup = (xvalid_ageGroup - xvalid_ageGroup.mean())/xvalid_ageGroup.std()\n",
    "\n",
    "xvalid_division = np.array(xvalid.division)\n",
    "xvalid_division = le.fit_transform(xvalid_division)\n",
    "# xvalid_division = (xvalid_division - xvalid_division.mean())/xvalid_division.std()\n",
    "\n",
    "xvalid_gender = np.array(xvalid.gender)\n",
    "xvalid_gender = le.fit_transform(xvalid_gender)\n",
    "# xvalid_gender = (xvalid_gender - xvalid_gender.mean())/xvalid_gender.std()\n",
    "\n",
    "xvalid_group = np.array(xvalid.group)\n",
    "xvalid_group = le.fit_transform(xvalid_group)\n",
    "# xvalid_group = (xvalid_group - xvalid_group.mean())/xvalid_group.std()\n",
    "\n",
    "xvalid_name4 = np.array(xvalid.name4)\n",
    "xvalid_name4 = le.fit_transform(xvalid_name4)\n",
    "# xvalid_name4 = (xvalid_name4 - xvalid_name4.mean())/xvalid_name4.std()\n",
    "\n",
    "xvalid_sportsCategory = np.array(xvalid.sportsCategory)\n",
    "xvalid_sportsCategory = le.fit_transform(xvalid_sportsCategory)\n",
    "# xvalid_sportsCategory = (xvalid_sportsCategory - xvalid_sportsCategory.mean())/xvalid_sportsCategory.std()\n",
    "\n",
    "xvalid_subBrand = np.array(xvalid.subBrand)\n",
    "xvalid_subBrand = le.fit_transform(xvalid_subBrand)\n",
    "# xvalid_subBrand = (xvalid_subBrand - xvalid_subBrand.mean())/xvalid_subBrand.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_companyName = np.array(xtest.companyName)\n",
    "xtest_companyName = le.fit_transform(xtest_companyName)\n",
    "# xtest_companyName = (xtest_companyName - xtest_companyName.mean())/xtest_companyName.std()\n",
    "\n",
    "xtest_distributorName = np.array(xtest.distributorName)\n",
    "xtest_distributorName = le.fit_transform(xtest_distributorName)\n",
    "# xtest_distributorName = (xtest_distributorName - xtest_distributorName.mean())/xtest_distributorName.std()\n",
    "\n",
    "xtest_ageGroup = np.array(xtest.ageGroup)\n",
    "xtest_ageGroup = le.fit_transform(xtest_ageGroup)\n",
    "# xtest_ageGroup = (xtest_ageGroup - xtest_ageGroup.mean())/xtest_ageGroup.std()\n",
    "\n",
    "xtest_division = np.array(xtest.division)\n",
    "xtest_division = le.fit_transform(xtest_division)\n",
    "# xtest_division = (xtest_division - xtest_division.mean())/xtest_division.std()\n",
    "\n",
    "xtest_gender = np.array(xtest.gender)\n",
    "xtest_gender = le.fit_transform(xtest_gender)\n",
    "# xtest_gender = (xtest_gender - xtest_gender.mean())/xtest_gender.std()\n",
    "\n",
    "xtest_group = np.array(xtest.group)\n",
    "xtest_group = le.fit_transform(xtest_group)\n",
    "# xtest_group = (xtest_group - xtest_group.mean())/xtest_group.std()\n",
    "\n",
    "\n",
    "xtest_name4 = np.array(xtest.name4)\n",
    "xtest_name4 = le.fit_transform(xtest_name4)\n",
    "# xtest_name4 = (xtest_name4 - xtest_name4.mean())/xtest_name4.std()\n",
    "\n",
    "xtest_sportsCategory = np.array(xtest.sportsCategory)\n",
    "xtest_sportsCategory = le.fit_transform(xtest_sportsCategory)\n",
    "# xtest_sportsCategory = (xtest_sportsCategory - xtest_sportsCategory.mean())/xtest_sportsCategory.std()\n",
    "\n",
    "xtest_subBrand = np.array(xtest.subBrand)\n",
    "xtest_subBrand = le.fit_transform(xtest_subBrand)\n",
    "# xtest_subBrand = (xtest_subBrand - xtest_subBrand.mean())/xtest_subBrand.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 300, 300)     10684200    main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 300, 300)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 300)          721200      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "aux_input_1 (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aux_input_2 (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aux_input_3 (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aux_input_4 (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aux_input_5 (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aux_input_6 (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aux_input_7 (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aux_input_8 (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aux_input_9 (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 309)          0           lstm_1[0][0]                     \n",
      "                                                                 aux_input_1[0][0]                \n",
      "                                                                 aux_input_2[0][0]                \n",
      "                                                                 aux_input_3[0][0]                \n",
      "                                                                 aux_input_4[0][0]                \n",
      "                                                                 aux_input_5[0][0]                \n",
      "                                                                 aux_input_6[0][0]                \n",
      "                                                                 aux_input_7[0][0]                \n",
      "                                                                 aux_input_8[0][0]                \n",
      "                                                                 aux_input_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         317440      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         1049600     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          524800      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 512)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          131328      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          32896       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 2)            258         dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 13,461,722\n",
      "Trainable params: 2,777,522\n",
      "Non-trainable params: 10,684,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1125047 samples, validate on 222889 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  34560/1125047 [..............................] - ETA: 18:32:35 - loss: 9.722 - ETA: 15:38:28 - loss: 8.707 - ETA: 14:38:05 - loss: 8.113 - ETA: 14:03:27 - loss: 7.916 - ETA: 13:43:20 - loss: 7.966 - ETA: 13:27:14 - loss: 7.835 - ETA: 13:14:39 - loss: 7.903 - ETA: 13:09:33 - loss: 7.616 - ETA: 13:07:10 - loss: 7.441 - ETA: 13:05:53 - loss: 7.365 - ETA: 13:01:48 - loss: 7.313 - ETA: 13:01:45 - loss: 7.256 - ETA: 13:00:19 - loss: 7.260 - ETA: 12:57:28 - loss: 7.200 - ETA: 12:58:59 - loss: 7.232 - ETA: 12:59:35 - loss: 7.181 - ETA: 12:59:54 - loss: 7.122 - ETA: 13:00:28 - loss: 7.069 - ETA: 13:00:28 - loss: 7.081 - ETA: 13:00:17 - loss: 7.111 - ETA: 12:59:20 - loss: 7.042 - ETA: 12:58:32 - loss: 7.043 - ETA: 12:58:49 - loss: 7.026 - ETA: 12:59:10 - loss: 7.090 - ETA: 12:57:52 - loss: 7.089 - ETA: 12:58:50 - loss: 7.034 - ETA: 12:59:11 - loss: 7.007 - ETA: 12:57:55 - loss: 7.058 - ETA: 12:58:12 - loss: 7.079 - ETA: 12:58:52 - loss: 7.057 - ETA: 13:03:10 - loss: 7.045 - ETA: 13:05:29 - loss: 7.022 - ETA: 13:06:11 - loss: 7.007 - ETA: 13:06:32 - loss: 7.012 - ETA: 13:05:26 - loss: 6.985 - ETA: 13:04:51 - loss: 7.007 - ETA: 13:06:09 - loss: 7.012 - ETA: 13:06:18 - loss: 7.016 - ETA: 13:05:23 - loss: 7.033 - ETA: 13:05:39 - loss: 7.028 - ETA: 13:06:15 - loss: 7.016 - ETA: 13:05:44 - loss: 7.008 - ETA: 13:05:17 - loss: 7.023 - ETA: 13:07:41 - loss: 7.030 - ETA: 13:07:55 - loss: 7.016 - ETA: 13:08:03 - loss: 7.014 - ETA: 13:08:01 - loss: 6.991 - ETA: 13:10:33 - loss: 6.979 - ETA: 13:11:22 - loss: 6.970 - ETA: 13:11:54 - loss: 6.979 - ETA: 13:14:06 - loss: 6.971 - ETA: 13:15:07 - loss: 6.972 - ETA: 13:15:37 - loss: 6.969 - ETA: 13:15:59 - loss: 6.971 - ETA: 13:17:36 - loss: 6.972 - ETA: 13:18:44 - loss: 6.976 - ETA: 13:19:01 - loss: 6.988 - ETA: 13:19:38 - loss: 6.978 - ETA: 13:21:14 - loss: 6.986 - ETA: 13:21:41 - loss: 6.966 - ETA: 13:22:15 - loss: 6.986 - ETA: 13:23:54 - loss: 6.995 - ETA: 13:25:44 - loss: 7.004 - ETA: 13:26:08 - loss: 6.987 - ETA: 13:26:39 - loss: 6.975 - ETA: 13:27:44 - loss: 6.968 - ETA: 13:28:08 - loss: 6.971 - ETA: 13:29:05 - loss: 6.967 - ETA: 13:31:13 - loss: 6.977 - ETA: 13:33:17 - loss: 6.966 - ETA: 13:34:21 - loss: 6.951 - ETA: 13:34:55 - loss: 6.952 - ETA: 13:35:53 - loss: 6.954 - ETA: 13:36:36 - loss: 6.947 - ETA: 13:36:55 - loss: 6.929 - ETA: 13:37:36 - loss: 6.916 - ETA: 13:38:36 - loss: 6.915 - ETA: 13:39:10 - loss: 6.928 - ETA: 13:40:07 - loss: 6.924 - ETA: 13:41:27 - loss: 6.921 - ETA: 13:42:27 - loss: 6.931 - ETA: 13:43:16 - loss: 6.926 - ETA: 13:43:48 - loss: 6.917 - ETA: 13:44:46 - loss: 6.902 - ETA: 13:45:15 - loss: 6.898 - ETA: 13:45:45 - loss: 6.910 - ETA: 13:46:44 - loss: 6.891 - ETA: 13:47:39 - loss: 6.892 - ETA: 13:48:31 - loss: 6.899 - ETA: 13:49:06 - loss: 6.908 - ETA: 13:50:06 - loss: 6.904 - ETA: 13:50:27 - loss: 6.908 - ETA: 13:50:45 - loss: 6.919 - ETA: 13:51:13 - loss: 6.917 - ETA: 13:51:17 - loss: 6.915 - ETA: 13:50:46 - loss: 6.918 - ETA: 13:50:17 - loss: 6.923 - ETA: 13:50:49 - loss: 6.919 - ETA: 13:51:38 - loss: 6.920 - ETA: 13:51:23 - loss: 6.923 - ETA: 14:08:33 - loss: 6.921 - ETA: 14:12:54 - loss: 6.928 - ETA: 14:13:49 - loss: 6.931 - ETA: 14:13:21 - loss: 6.936 - ETA: 14:13:10 - loss: 6.934 - ETA: 14:12:59 - loss: 6.933 - ETA: 14:12:43 - loss: 6.945 - ETA: 14:12:19 - loss: 6.954 - ETA: 14:12:14 - loss: 6.950 - ETA: 14:11:43 - loss: 6.952 - ETA: 14:11:41 - loss: 6.944 - ETA: 14:14:25 - loss: 6.943 - ETA: 14:14:49 - loss: 6.936 - ETA: 14:14:42 - loss: 6.941 - ETA: 14:14:40 - loss: 6.943 - ETA: 14:14:56 - loss: 6.949 - ETA: 14:15:11 - loss: 6.947 - ETA: 14:15:03 - loss: 6.945 - ETA: 14:14:56 - loss: 6.942 - ETA: 14:14:57 - loss: 6.942 - ETA: 14:14:38 - loss: 6.943 - ETA: 14:14:27 - loss: 6.943 - ETA: 14:14:46 - loss: 6.937 - ETA: 14:15:45 - loss: 6.932 - ETA: 14:16:43 - loss: 6.934 - ETA: 14:17:04 - loss: 6.934 - ETA: 14:17:46 - loss: 6.933 - ETA: 14:17:54 - loss: 6.941 - ETA: 14:18:01 - loss: 6.939 - ETA: 14:18:42 - loss: 6.938 - ETA: 14:19:24 - loss: 6.940 - ETA: 14:19:15 - loss: 6.943 - ETA: 14:19:11 - loss: 6.949 - ETA: 14:19:12 - loss: 6.952 - ETA: 14:18:54 - loss: 6.957 - ETA: 14:18:55 - loss: 6.966 - ETA: 14:19:06 - loss: 6.965 - ETA: 14:19:08 - loss: 6.960 - ETA: 14:18:51 - loss: 6.962 - ETA: 14:18:42 - loss: 6.969 - ETA: 14:18:46 - loss: 6.965 - ETA: 14:19:12 - loss: 6.964 - ETA: 14:19:48 - loss: 6.963 - ETA: 14:20:16 - loss: 6.962 - ETA: 14:20:42 - loss: 6.966 - ETA: 14:21:12 - loss: 6.970 - ETA: 14:21:24 - loss: 6.969 - ETA: 14:21:49 - loss: 6.970 - ETA: 14:22:10 - loss: 6.971 - ETA: 14:22:12 - loss: 6.982 - ETA: 14:22:04 - loss: 6.982 - ETA: 14:22:05 - loss: 6.987 - ETA: 14:21:53 - loss: 6.990 - ETA: 14:21:41 - loss: 6.998 - ETA: 14:21:48 - loss: 6.991 - ETA: 14:21:59 - loss: 6.989 - ETA: 14:21:56 - loss: 6.991 - ETA: 14:21:50 - loss: 6.985 - ETA: 14:21:56 - loss: 6.982 - ETA: 14:21:56 - loss: 6.981 - ETA: 14:21:41 - loss: 6.981 - ETA: 14:21:35 - loss: 6.986 - ETA: 14:21:37 - loss: 6.991 - ETA: 14:21:28 - loss: 6.993 - ETA: 14:21:18 - loss: 6.993 - ETA: 14:21:31 - loss: 6.990 - ETA: 14:21:29 - loss: 6.993 - ETA: 14:21:16 - loss: 6.985 - ETA: 14:21:11 - loss: 6.987 - ETA: 14:21:14 - loss: 6.986 - ETA: 14:21:05 - loss: 6.986 - ETA: 14:20:57 - loss: 6.985 - ETA: 14:21:02 - loss: 6.986 - ETA: 14:21:04 - loss: 6.982 - ETA: 14:20:50 - loss: 6.983 - ETA: 14:20:57 - loss: 6.986 - ETA: 14:21:02 - loss: 6.989 - ETA: 14:20:47 - loss: 6.986 - ETA: 14:20:33 - loss: 6.989 - ETA: 14:20:39 - loss: 6.991 - ETA: 14:20:37 - loss: 6.986 - ETA: 14:20:26 - loss: 6.985 - ETA: 14:20:19 - loss: 6.982 - ETA: 14:20:24 - loss: 6.979 - ETA: 14:20:22 - loss: 6.975 - ETA: 14:20:18 - loss: 6.976 - ETA: 14:20:16 - loss: 6.975 - ETA: 14:20:17 - loss: 6.985 - ETA: 14:20:06 - loss: 6.980 - ETA: 14:19:58 - loss: 6.982 - ETA: 14:20:03 - loss: 6.984 - ETA: 14:20:04 - loss: 6.985 - ETA: 14:19:53 - loss: 6.982 - ETA: 14:19:45 - loss: 6.981 - ETA: 14:19:50 - loss: 6.986 - ETA: 14:19:56 - loss: 6.986 - ETA: 14:19:45 - loss: 6.984 - ETA: 14:19:52 - loss: 6.982 - ETA: 14:19:55 - loss: 6.981 - ETA: 14:19:45 - loss: 6.980 - ETA: 14:19:38 - loss: 6.979 - ETA: 14:19:42 - loss: 6.977 - ETA: 14:19:32 - loss: 6.972 - ETA: 14:19:23 - loss: 6.968 - ETA: 14:19:29 - loss: 6.971 - ETA: 14:19:42 - loss: 6.971 - ETA: 14:19:39 - loss: 6.976 - ETA: 14:19:38 - loss: 6.976 - ETA: 14:19:48 - loss: 6.976 - ETA: 14:19:59 - loss: 6.975 - ETA: 14:19:57 - loss: 6.976 - ETA: 14:20:08 - loss: 6.977 - ETA: 14:20:35 - loss: 6.982 - ETA: 14:20:43 - loss: 6.983 - ETA: 14:20:58 - loss: 6.982 - ETA: 14:21:24 - loss: 6.984 - ETA: 14:21:59 - loss: 6.984 - ETA: 14:22:20 - loss: 6.989 - ETA: 14:22:49 - loss: 6.995 - ETA: 14:23:27 - loss: 6.995 - ETA: 14:23:48 - loss: 6.991 - ETA: 14:24:09 - loss: 6.989 - ETA: 14:24:49 - loss: 6.990 - ETA: 14:25:37 - loss: 6.993 - ETA: 14:26:00 - loss: 7.000 - ETA: 14:26:25 - loss: 6.994 - ETA: 14:27:00 - loss: 6.997 - ETA: 14:27:19 - loss: 6.992 - ETA: 14:27:29 - loss: 6.993 - ETA: 14:27:57 - loss: 6.995 - ETA: 14:28:30 - loss: 6.992 - ETA: 14:28:47 - loss: 6.997 - ETA: 14:29:20 - loss: 6.991 - ETA: 14:29:53 - loss: 6.996 - ETA: 14:30:20 - loss: 6.996 - ETA: 14:30:39 - loss: 7.002 - ETA: 14:31:03 - loss: 7.002 - ETA: 14:31:34 - loss: 6.999 - ETA: 14:31:54 - loss: 6.996 - ETA: 14:32:10 - loss: 6.994 - ETA: 14:32:46 - loss: 7.000 - ETA: 14:33:19 - loss: 7.003 - ETA: 14:33:36 - loss: 7.001 - ETA: 14:34:00 - loss: 6.998 - ETA: 14:34:32 - loss: 6.999 - ETA: 14:34:47 - loss: 6.997 - ETA: 14:35:02 - loss: 7.000 - ETA: 14:35:33 - loss: 6.998 - ETA: 14:36:01 - loss: 6.992 - ETA: 14:36:36 - loss: 6.986 - ETA: 14:37:04 - loss: 6.983 - ETA: 14:37:43 - loss: 6.982 - ETA: 14:38:18 - loss: 6.981 - ETA: 14:38:58 - loss: 6.980 - ETA: 14:39:46 - loss: 6.980 - ETA: 14:40:46 - loss: 6.980 - ETA: 14:41:31 - loss: 6.979 - ETA: 14:42:39 - loss: 6.982 - ETA: 14:43:49 - loss: 6.983 - ETA: 14:44:55 - loss: 6.988 - ETA: 14:46:01 - loss: 6.987 - ETA: 14:47:15 - loss: 6.987 - ETA: 14:48:39 - loss: 6.985 - ETA: 14:49:50 - loss: 6.984 - ETA: 14:51:48 - loss: 6.982 - ETA: 14:53:46 - loss: 6.980 - ETA: 14:55:39 - loss: 6.976 - ETA: 14:57:38 - loss: 6.978 - ETA: 14:59:40 - loss: 6.974 - ETA: 15:02:01 - loss: 6.969  69376/1125047 [>.............................] - ETA: 15:04:28 - loss: 6.966 - ETA: 15:06:44 - loss: 6.967 - ETA: 15:10:11 - loss: 6.973 - ETA: 15:13:41 - loss: 6.975 - ETA: 15:17:36 - loss: 6.978 - ETA: 15:21:50 - loss: 6.976 - ETA: 15:26:26 - loss: 6.980 - ETA: 15:31:09 - loss: 6.977 - ETA: 15:37:22 - loss: 6.981 - ETA: 15:44:25 - loss: 6.983 - ETA: 15:51:21 - loss: 6.981 - ETA: 16:01:27 - loss: 6.981 - ETA: 16:13:17 - loss: 6.979 - ETA: 16:36:48 - loss: 6.978 - ETA: 17:08:13 - loss: 6.977 - ETA: 17:33:59 - loss: 6.978 - ETA: 17:58:28 - loss: 6.979 - ETA: 18:23:07 - loss: 6.978 - ETA: 18:47:29 - loss: 6.976 - ETA: 19:03:27 - loss: 6.976 - ETA: 19:17:36 - loss: 6.975 - ETA: 19:27:21 - loss: 6.978 - ETA: 19:33:26 - loss: 6.985 - ETA: 19:39:03 - loss: 6.985 - ETA: 19:44:45 - loss: 6.981 - ETA: 19:48:17 - loss: 6.981 - ETA: 19:51:35 - loss: 6.980 - ETA: 19:54:47 - loss: 6.974 - ETA: 19:57:42 - loss: 6.975 - ETA: 19:59:40 - loss: 6.976 - ETA: 20:01:34 - loss: 6.976 - ETA: 20:03:21 - loss: 6.977 - ETA: 20:04:20 - loss: 6.979 - ETA: 20:05:02 - loss: 6.979 - ETA: 20:05:42 - loss: 6.983 - ETA: 20:06:34 - loss: 6.983 - ETA: 20:07:15 - loss: 6.980 - ETA: 20:07:40 - loss: 6.979 - ETA: 20:08:13 - loss: 6.977 - ETA: 20:08:32 - loss: 6.978 - ETA: 20:08:21 - loss: 6.978 - ETA: 20:08:14 - loss: 6.974 - ETA: 20:08:19 - loss: 6.975 - ETA: 20:08:06 - loss: 6.973 - ETA: 20:07:52 - loss: 6.977 - ETA: 20:07:47 - loss: 6.980 - ETA: 20:07:30 - loss: 6.978 - ETA: 20:06:59 - loss: 6.979 - ETA: 20:06:34 - loss: 6.979 - ETA: 20:06:13 - loss: 6.979 - ETA: 20:05:48 - loss: 6.978 - ETA: 20:05:26 - loss: 6.976 - ETA: 20:05:13 - loss: 6.976 - ETA: 20:04:55 - loss: 6.980 - ETA: 20:04:26 - loss: 6.977 - ETA: 20:03:56 - loss: 6.976 - ETA: 20:03:37 - loss: 6.974 - ETA: 20:03:05 - loss: 6.973 - ETA: 20:02:26 - loss: 6.975 - ETA: 20:02:07 - loss: 6.975 - ETA: 20:01:47 - loss: 6.976 - ETA: 20:01:18 - loss: 6.977 - ETA: 20:00:49 - loss: 6.978 - ETA: 20:00:31 - loss: 6.977 - ETA: 20:00:15 - loss: 6.976 - ETA: 19:59:49 - loss: 6.975 - ETA: 19:59:24 - loss: 6.975 - ETA: 19:59:16 - loss: 6.977 - ETA: 19:58:47 - loss: 6.976 - ETA: 19:58:20 - loss: 6.975 - ETA: 19:58:06 - loss: 6.971 - ETA: 19:57:46 - loss: 6.972 - ETA: 19:57:17 - loss: 6.971 - ETA: 19:56:52 - loss: 6.973 - ETA: 19:56:38 - loss: 6.973 - ETA: 19:56:10 - loss: 6.973 - ETA: 19:55:40 - loss: 6.975 - ETA: 19:55:23 - loss: 6.976 - ETA: 19:55:05 - loss: 6.978 - ETA: 19:54:39 - loss: 6.981 - ETA: 19:54:27 - loss: 6.979 - ETA: 19:54:18 - loss: 6.981 - ETA: 19:54:11 - loss: 6.981 - ETA: 19:54:00 - loss: 6.981 - ETA: 19:53:58 - loss: 6.979 - ETA: 19:53:57 - loss: 6.981 - ETA: 19:54:01 - loss: 6.977 - ETA: 19:54:17 - loss: 6.976 - ETA: 19:54:45 - loss: 6.978 - ETA: 19:55:32 - loss: 6.980 - ETA: 19:55:59 - loss: 6.982 - ETA: 19:56:33 - loss: 6.983 - ETA: 19:57:29 - loss: 6.982 - ETA: 19:58:19 - loss: 6.985 - ETA: 19:59:11 - loss: 6.987 - ETA: 20:00:55 - loss: 6.985 - ETA: 20:02:40 - loss: 6.986 - ETA: 20:04:34 - loss: 6.988 - ETA: 20:06:40 - loss: 6.988 - ETA: 20:09:29 - loss: 6.988 - ETA: 20:11:51 - loss: 6.989 - ETA: 20:15:55 - loss: 6.988 - ETA: 20:20:32 - loss: 6.985 - ETA: 20:25:09 - loss: 6.983 - ETA: 20:31:34 - loss: 6.982 - ETA: 20:40:25 - loss: 6.981 - ETA: 20:55:58 - loss: 6.982 - ETA: 24:06:57 - loss: 6.981 - ETA: 24:26:01 - loss: 6.984 - ETA: 24:35:30 - loss: 6.987 - ETA: 24:41:33 - loss: 6.986 - ETA: 24:45:13 - loss: 6.984 - ETA: 24:48:37 - loss: 6.986 - ETA: 24:51:38 - loss: 6.985 - ETA: 24:53:26 - loss: 6.985 - ETA: 24:55:04 - loss: 6.984 - ETA: 24:56:41 - loss: 6.982 - ETA: 24:58:36 - loss: 6.981 - ETA: 25:00:09 - loss: 6.981 - ETA: 25:01:20 - loss: 6.980 - ETA: 25:02:38 - loss: 6.978 - ETA: 25:03:56 - loss: 6.977 - ETA: 25:04:57 - loss: 6.977 - ETA: 25:06:02 - loss: 6.978 - ETA: 25:07:16 - loss: 6.978 - ETA: 25:08:13 - loss: 6.976 - ETA: 25:09:13 - loss: 6.978 - ETA: 25:10:37 - loss: 6.977 - ETA: 25:11:44 - loss: 6.976 - ETA: 25:12:37 - loss: 6.977 - ETA: 25:13:39 - loss: 6.978 - ETA: 25:14:56 - loss: 6.975 - ETA: 25:16:07 - loss: 6.975 - ETA: 25:17:00 - loss: 6.978 - ETA: 25:17:57 - loss: 6.977 - ETA: 25:19:07 - loss: 6.979 - ETA: 25:20:03 - loss: 6.977 - ETA: 25:20:57 - loss: 6.978 - ETA: 25:22:07 - loss: 6.977 - ETA: 25:23:18 - loss: 6.976 - ETA: 25:24:14 - loss: 6.976 - ETA: 25:25:14 - loss: 6.975 - ETA: 25:26:29 - loss: 6.977 - ETA: 25:27:23 - loss: 6.978 - ETA: 25:28:15 - loss: 6.979 - ETA: 25:29:23 - loss: 6.979 - ETA: 25:30:25 - loss: 6.980 - ETA: 25:31:20 - loss: 6.981 - ETA: 25:32:24 - loss: 6.983 - ETA: 25:33:39 - loss: 6.980 - ETA: 25:34:30 - loss: 6.981 - ETA: 25:35:26 - loss: 6.978 - ETA: 25:36:37 - loss: 6.978 - ETA: 25:37:40 - loss: 6.978 - ETA: 25:38:28 - loss: 6.978 - ETA: 25:39:22 - loss: 6.980 - ETA: 25:40:29 - loss: 6.983 - ETA: 25:41:30 - loss: 6.984 - ETA: 25:42:16 - loss: 6.984 - ETA: 25:43:08 - loss: 6.985 - ETA: 25:44:13 - loss: 6.984 - ETA: 25:45:05 - loss: 6.983 - ETA: 25:45:53 - loss: 6.981 - ETA: 25:46:55 - loss: 6.982 - ETA: 25:47:55 - loss: 6.981 - ETA: 25:48:44 - loss: 6.981 - ETA: 25:49:40 - loss: 6.982 - ETA: 25:50:41 - loss: 6.982 - ETA: 25:51:23 - loss: 6.981 - ETA: 25:52:09 - loss: 6.983 - ETA: 25:53:10 - loss: 6.981 - ETA: 25:54:03 - loss: 6.981 - ETA: 25:54:46 - loss: 6.981 - ETA: 25:55:44 - loss: 6.982 - ETA: 25:56:46 - loss: 6.982 - ETA: 25:57:24 - loss: 6.982 - ETA: 25:58:29 - loss: 6.981 - ETA: 25:59:31 - loss: 6.984 - ETA: 26:00:26 - loss: 6.984 - ETA: 26:01:10 - loss: 6.984 - ETA: 26:01:54 - loss: 6.984 - ETA: 26:02:52 - loss: 6.985 - ETA: 26:03:45 - loss: 6.984 - ETA: 26:04:28 - loss: 6.986 - ETA: 26:05:11 - loss: 6.984 - ETA: 26:06:04 - loss: 6.983 - ETA: 26:06:44 - loss: 6.983 - ETA: 26:07:27 - loss: 6.985 - ETA: 26:08:19 - loss: 6.987 - ETA: 26:09:05 - loss: 6.987 - ETA: 26:09:45 - loss: 6.988 - ETA: 26:10:30 - loss: 6.986 - ETA: 26:11:24 - loss: 6.985 - ETA: 26:12:03 - loss: 6.985 - ETA: 26:12:46 - loss: 6.986 - ETA: 26:13:40 - loss: 6.983 - ETA: 26:14:28 - loss: 6.984 - ETA: 26:15:03 - loss: 6.983 - ETA: 26:15:44 - loss: 6.984 - ETA: 26:16:42 - loss: 6.981 - ETA: 26:17:17 - loss: 6.982 - ETA: 26:17:50 - loss: 6.983 - ETA: 26:19:09 - loss: 6.981 - ETA: 26:20:26 - loss: 6.981 - ETA: 26:21:37 - loss: 6.981 - ETA: 26:22:40 - loss: 6.980 - ETA: 26:23:56 - loss: 6.979 - ETA: 26:25:13 - loss: 6.978 - ETA: 26:26:10 - loss: 6.977 - ETA: 26:27:16 - loss: 6.977 - ETA: 26:28:29 - loss: 6.975 - ETA: 26:29:30 - loss: 6.976 - ETA: 26:30:27 - loss: 6.978 - ETA: 26:31:58 - loss: 6.977 - ETA: 26:33:58 - loss: 6.978 - ETA: 26:34:58 - loss: 6.977 - ETA: 26:35:59 - loss: 6.977 - ETA: 26:37:06 - loss: 6.977 - ETA: 26:38:05 - loss: 6.976 - ETA: 26:39:02 - loss: 6.973 - ETA: 26:41:26 - loss: 6.973 - ETA: 26:43:45 - loss: 6.971 - ETA: 26:46:05 - loss: 6.971 - ETA: 26:49:54 - loss: 6.972 - ETA: 26:54:24 - loss: 6.971 - ETA: 26:58:42 - loss: 6.972 - ETA: 27:02:43 - loss: 6.973 - ETA: 27:07:12 - loss: 6.973 - ETA: 27:11:24 - loss: 6.973 - ETA: 27:15:21 - loss: 6.975 - ETA: 27:19:14 - loss: 6.976 - ETA: 27:24:35 - loss: 6.977 - ETA: 27:29:52 - loss: 6.975 - ETA: 27:35:08 - loss: 6.976 - ETA: 27:40:37 - loss: 6.975 - ETA: 27:47:40 - loss: 6.976 - ETA: 27:53:29 - loss: 6.978 - ETA: 27:59:05 - loss: 6.975 - ETA: 28:05:23 - loss: 6.976 - ETA: 28:11:40 - loss: 6.975 - ETA: 28:17:32 - loss: 6.975 - ETA: 28:23:04 - loss: 6.974 - ETA: 28:29:09 - loss: 6.975 - ETA: 28:35:18 - loss: 6.977 - ETA: 28:41:22 - loss: 6.979 - ETA: 28:47:39 - loss: 6.980 - ETA: 28:53:31 - loss: 6.978 - ETA: 28:58:36 - loss: 6.979 - ETA: 29:03:49 - loss: 6.982 - ETA: 29:09:35 - loss: 6.984 - ETA: 29:17:10 - loss: 6.985 - ETA: 29:23:26 - loss: 6.985 - ETA: 29:29:18 - loss: 6.985 - ETA: 29:35:20 - loss: 6.984 - ETA: 29:40:34 - loss: 6.982 - ETA: 29:46:02 - loss: 6.980 - ETA: 29:51:28 - loss: 6.982 - ETA: 29:56:34 - loss: 6.982 - ETA: 30:01:32 - loss: 6.981 - ETA: 30:06:57 - loss: 6.982 - ETA: 30:12:13 - loss: 6.981 - ETA: 30:17:05 - loss: 6.980 - ETA: 30:22:06 - loss: 6.980 - ETA: 30:27:11 - loss: 6.978 - ETA: 30:32:25 - loss: 6.979 - ETA: 30:37:18 - loss: 6.976 - ETA: 30:43:05 - loss: 6.977 - ETA: 30:48:27 - loss: 6.975 - ETA: 30:53:17 - loss: 6.974 - ETA: 30:57:55 - loss: 6.975 - ETA: 31:02:21 - loss: 6.974 - ETA: 31:05:49 - loss: 6.9744"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 104192/1125047 [=>............................] - ETA: 31:08:45 - loss: 6.974 - ETA: 31:10:48 - loss: 6.975 - ETA: 31:12:22 - loss: 6.975 - ETA: 31:13:50 - loss: 6.975 - ETA: 31:15:08 - loss: 6.976 - ETA: 31:16:43 - loss: 6.974 - ETA: 31:18:30 - loss: 6.972 - ETA: 31:19:52 - loss: 6.973 - ETA: 31:21:27 - loss: 6.972 - ETA: 31:23:11 - loss: 6.971 - ETA: 31:24:21 - loss: 6.971 - ETA: 31:25:34 - loss: 6.971 - ETA: 31:27:08 - loss: 6.971 - ETA: 31:27:34 - loss: 6.972 - ETA: 31:27:45 - loss: 6.973 - ETA: 31:27:59 - loss: 6.975 - ETA: 31:28:28 - loss: 6.977 - ETA: 31:28:36 - loss: 6.978 - ETA: 31:28:32 - loss: 6.978 - ETA: 31:28:48 - loss: 6.978 - ETA: 31:29:15 - loss: 6.976 - ETA: 31:29:26 - loss: 6.976 - ETA: 31:29:41 - loss: 6.975 - ETA: 31:30:08 - loss: 6.975 - ETA: 31:30:36 - loss: 6.975 - ETA: 31:30:49 - loss: 6.976 - ETA: 31:31:08 - loss: 6.974 - ETA: 31:31:34 - loss: 6.974 - ETA: 31:31:49 - loss: 6.973 - ETA: 31:31:58 - loss: 6.971 - ETA: 31:32:22 - loss: 6.970 - ETA: 31:32:48 - loss: 6.969 - ETA: 31:33:03 - loss: 6.970 - ETA: 31:33:23 - loss: 6.969 - ETA: 31:33:48 - loss: 6.970 - ETA: 31:34:11 - loss: 6.972 - ETA: 31:34:22 - loss: 6.973 - ETA: 31:34:45 - loss: 6.973 - ETA: 31:35:05 - loss: 6.970 - ETA: 31:35:20 - loss: 6.970 - ETA: 31:35:34 - loss: 6.970 - ETA: 31:35:53 - loss: 6.970 - ETA: 31:36:04 - loss: 6.972 - ETA: 31:36:09 - loss: 6.975 - ETA: 31:36:21 - loss: 6.975 - ETA: 31:36:43 - loss: 6.975 - ETA: 31:36:49 - loss: 6.973 - ETA: 31:37:06 - loss: 6.970 - ETA: 31:37:38 - loss: 6.971 - ETA: 31:38:07 - loss: 6.970 - ETA: 31:38:33 - loss: 6.971 - ETA: 31:40:19 - loss: 6.971 - ETA: 31:40:59 - loss: 6.969 - ETA: 31:41:06 - loss: 6.967 - ETA: 31:41:25 - loss: 6.967 - ETA: 31:41:49 - loss: 6.966 - ETA: 31:42:08 - loss: 6.965 - ETA: 31:42:30 - loss: 6.965 - ETA: 31:42:59 - loss: 6.967 - ETA: 31:43:17 - loss: 6.966 - ETA: 31:43:24 - loss: 6.967 - ETA: 31:43:36 - loss: 6.965 - ETA: 31:44:11 - loss: 6.965 - ETA: 31:44:48 - loss: 6.965 - ETA: 31:45:20 - loss: 6.964 - ETA: 31:45:58 - loss: 6.966 - ETA: 31:46:18 - loss: 6.966 - ETA: 31:46:26 - loss: 6.965 - ETA: 31:46:56 - loss: 6.966 - ETA: 31:48:11 - loss: 6.964 - ETA: 31:49:32 - loss: 6.965 - ETA: 31:50:46 - loss: 6.965 - ETA: 31:51:59 - loss: 6.966 - ETA: 31:53:13 - loss: 6.966 - ETA: 31:55:48 - loss: 6.967 - ETA: 31:59:18 - loss: 6.968 - ETA: 32:06:12 - loss: 6.971 - ETA: 32:51:41 - loss: 6.969 - ETA: 33:12:05 - loss: 6.970 - ETA: 33:17:12 - loss: 6.970 - ETA: 33:21:09 - loss: 6.969 - ETA: 33:24:10 - loss: 6.970 - ETA: 33:25:55 - loss: 6.970 - ETA: 33:26:17 - loss: 6.970 - ETA: 33:26:27 - loss: 6.971 - ETA: 33:26:15 - loss: 6.969 - ETA: 33:25:44 - loss: 6.968 - ETA: 33:25:19 - loss: 6.967 - ETA: 33:24:39 - loss: 6.966 - ETA: 33:23:42 - loss: 6.967 - ETA: 33:22:44 - loss: 6.968 - ETA: 33:21:44 - loss: 6.968 - ETA: 33:20:34 - loss: 6.968 - ETA: 33:19:21 - loss: 6.967 - ETA: 33:18:10 - loss: 6.966 - ETA: 33:17:04 - loss: 6.966 - ETA: 33:15:42 - loss: 6.966 - ETA: 33:14:10 - loss: 6.965 - ETA: 33:12:45 - loss: 6.962 - ETA: 33:11:18 - loss: 6.962 - ETA: 33:09:41 - loss: 6.962 - ETA: 33:08:07 - loss: 6.962 - ETA: 33:06:36 - loss: 6.961 - ETA: 33:04:59 - loss: 6.961 - ETA: 33:03:19 - loss: 6.964 - ETA: 33:01:45 - loss: 6.966 - ETA: 33:00:10 - loss: 6.967 - ETA: 32:58:40 - loss: 6.968 - ETA: 32:57:08 - loss: 6.966 - ETA: 32:55:44 - loss: 6.967 - ETA: 32:54:10 - loss: 6.968 - ETA: 32:52:33 - loss: 6.967 - ETA: 32:51:01 - loss: 6.967 - ETA: 32:49:26 - loss: 6.964 - ETA: 32:47:47 - loss: 6.964 - ETA: 32:46:07 - loss: 6.963 - ETA: 32:44:22 - loss: 6.964 - ETA: 32:42:29 - loss: 6.965 - ETA: 32:40:30 - loss: 6.965 - ETA: 32:38:35 - loss: 6.966 - ETA: 32:36:44 - loss: 6.966 - ETA: 32:34:49 - loss: 6.965 - ETA: 32:32:56 - loss: 6.963 - ETA: 32:31:03 - loss: 6.964 - ETA: 32:29:10 - loss: 6.964 - ETA: 32:27:14 - loss: 6.963 - ETA: 32:25:24 - loss: 6.963 - ETA: 32:23:32 - loss: 6.963 - ETA: 32:21:38 - loss: 6.962 - ETA: 32:19:42 - loss: 6.962 - ETA: 32:17:50 - loss: 6.961 - ETA: 32:15:57 - loss: 6.961 - ETA: 32:14:02 - loss: 6.962 - ETA: 32:12:08 - loss: 6.961 - ETA: 32:10:22 - loss: 6.963 - ETA: 32:08:36 - loss: 6.962 - ETA: 32:06:54 - loss: 6.960 - ETA: 32:05:09 - loss: 6.960 - ETA: 32:03:20 - loss: 6.960 - ETA: 32:01:27 - loss: 6.960 - ETA: 31:59:35 - loss: 6.960 - ETA: 31:57:47 - loss: 6.960 - ETA: 31:55:56 - loss: 6.959 - ETA: 31:54:02 - loss: 6.957 - ETA: 31:52:13 - loss: 6.956 - ETA: 31:50:28 - loss: 6.955 - ETA: 31:48:38 - loss: 6.956 - ETA: 31:46:48 - loss: 6.955 - ETA: 31:45:03 - loss: 6.956 - ETA: 31:43:16 - loss: 6.957 - ETA: 31:41:27 - loss: 6.959 - ETA: 31:39:40 - loss: 6.958 - ETA: 31:37:55 - loss: 6.960 - ETA: 31:36:07 - loss: 6.959 - ETA: 31:34:18 - loss: 6.959 - ETA: 31:32:34 - loss: 6.958 - ETA: 31:30:51 - loss: 6.960 - ETA: 31:29:04 - loss: 6.961 - ETA: 31:27:18 - loss: 6.962 - ETA: 31:25:34 - loss: 6.961 - ETA: 31:23:48 - loss: 6.962 - ETA: 31:22:02 - loss: 6.962 - ETA: 31:20:21 - loss: 6.960 - ETA: 31:18:41 - loss: 6.961 - ETA: 31:16:55 - loss: 6.959 - ETA: 31:15:12 - loss: 6.958 - ETA: 31:13:33 - loss: 6.958 - ETA: 31:11:52 - loss: 6.959 - ETA: 31:10:10 - loss: 6.960 - ETA: 31:08:27 - loss: 6.958 - ETA: 31:06:47 - loss: 6.958 - ETA: 31:05:03 - loss: 6.959 - ETA: 31:03:21 - loss: 6.959 - ETA: 31:01:42 - loss: 6.957 - ETA: 31:00:02 - loss: 6.957 - ETA: 30:58:21 - loss: 6.958 - ETA: 30:56:41 - loss: 6.958 - ETA: 30:55:03 - loss: 6.959 - ETA: 30:53:21 - loss: 6.959 - ETA: 30:51:40 - loss: 6.960 - ETA: 30:50:03 - loss: 6.959 - ETA: 30:48:25 - loss: 6.960 - ETA: 30:46:45 - loss: 6.959 - ETA: 30:45:06 - loss: 6.960 - ETA: 30:43:29 - loss: 6.960 - ETA: 30:41:51 - loss: 6.960 - ETA: 30:40:12 - loss: 6.959 - ETA: 30:38:37 - loss: 6.959 - ETA: 30:37:12 - loss: 6.961 - ETA: 30:35:37 - loss: 6.961 - ETA: 30:34:05 - loss: 6.960 - ETA: 30:32:42 - loss: 6.960 - ETA: 30:31:17 - loss: 6.960 - ETA: 30:29:45 - loss: 6.958 - ETA: 30:28:12 - loss: 6.957 - ETA: 30:26:41 - loss: 6.958 - ETA: 30:25:50 - loss: 6.957 - ETA: 30:25:05 - loss: 6.958 - ETA: 30:24:07 - loss: 6.957 - ETA: 30:23:09 - loss: 6.957 - ETA: 30:21:49 - loss: 6.955 - ETA: 30:20:27 - loss: 6.956 - ETA: 30:19:08 - loss: 6.956 - ETA: 30:17:44 - loss: 6.956 - ETA: 30:16:20 - loss: 6.956 - ETA: 30:15:01 - loss: 6.956 - ETA: 30:13:44 - loss: 6.956 - ETA: 30:12:21 - loss: 6.955 - ETA: 30:10:59 - loss: 6.955 - ETA: 30:09:41 - loss: 6.958 - ETA: 30:08:14 - loss: 6.959 - ETA: 30:06:53 - loss: 6.959 - ETA: 30:05:35 - loss: 6.959 - ETA: 30:04:14 - loss: 6.961 - ETA: 30:02:46 - loss: 6.961 - ETA: 30:01:20 - loss: 6.960 - ETA: 29:59:57 - loss: 6.960 - ETA: 29:58:33 - loss: 6.960 - ETA: 29:57:14 - loss: 6.961 - ETA: 29:55:59 - loss: 6.962 - ETA: 29:54:44 - loss: 6.962 - ETA: 29:53:25 - loss: 6.962 - ETA: 29:52:12 - loss: 6.962 - ETA: 29:51:00 - loss: 6.963 - ETA: 29:49:35 - loss: 6.962 - ETA: 29:48:05 - loss: 6.963 - ETA: 29:46:37 - loss: 6.962 - ETA: 29:45:10 - loss: 6.963 - ETA: 29:43:40 - loss: 6.963 - ETA: 29:42:09 - loss: 6.962 - ETA: 29:40:42 - loss: 6.961 - ETA: 29:39:17 - loss: 6.963 - ETA: 29:37:46 - loss: 6.963 - ETA: 29:36:18 - loss: 6.962 - ETA: 29:34:52 - loss: 6.962 - ETA: 29:33:23 - loss: 6.962 - ETA: 29:31:55 - loss: 6.962 - ETA: 29:30:32 - loss: 6.962 - ETA: 29:29:06 - loss: 6.962 - ETA: 29:27:38 - loss: 6.963 - ETA: 29:26:11 - loss: 6.961 - ETA: 29:24:49 - loss: 6.960 - ETA: 29:23:29 - loss: 6.960 - ETA: 29:22:07 - loss: 6.962 - ETA: 29:20:42 - loss: 6.965 - ETA: 29:19:18 - loss: 6.965 - ETA: 29:17:53 - loss: 6.965 - ETA: 29:16:28 - loss: 6.965 - ETA: 29:15:06 - loss: 6.965 - ETA: 29:13:43 - loss: 6.967 - ETA: 29:12:17 - loss: 6.966 - ETA: 29:10:53 - loss: 6.967 - ETA: 29:09:37 - loss: 6.966 - ETA: 29:08:16 - loss: 6.966 - ETA: 29:06:53 - loss: 6.967 - ETA: 29:05:31 - loss: 6.966 - ETA: 29:04:10 - loss: 6.968 - ETA: 29:02:46 - loss: 6.967 - ETA: 29:01:22 - loss: 6.968 - ETA: 29:00:01 - loss: 6.968 - ETA: 28:58:37 - loss: 6.969 - ETA: 28:57:14 - loss: 6.968 - ETA: 28:55:54 - loss: 6.968 - ETA: 28:54:33 - loss: 6.968 - ETA: 28:53:10 - loss: 6.968 - ETA: 28:51:48 - loss: 6.967 - ETA: 28:50:29 - loss: 6.968 - ETA: 28:49:09 - loss: 6.969 - ETA: 28:47:46 - loss: 6.969 - ETA: 28:46:24 - loss: 6.968 - ETA: 28:45:04 - loss: 6.968 - ETA: 28:43:43 - loss: 6.9698"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 139008/1125047 [==>...........................] - ETA: 28:42:23 - loss: 6.970 - ETA: 28:41:05 - loss: 6.969 - ETA: 28:39:46 - loss: 6.969 - ETA: 28:38:25 - loss: 6.970 - ETA: 28:37:06 - loss: 6.969 - ETA: 28:35:49 - loss: 6.969 - ETA: 28:34:28 - loss: 6.969 - ETA: 28:33:07 - loss: 6.968 - ETA: 28:31:50 - loss: 6.968 - ETA: 28:30:32 - loss: 6.968 - ETA: 28:29:13 - loss: 6.968 - ETA: 28:27:55 - loss: 6.967 - ETA: 28:26:41 - loss: 6.968 - ETA: 28:25:22 - loss: 6.969 - ETA: 28:24:04 - loss: 6.970 - ETA: 28:22:50 - loss: 6.971 - ETA: 28:21:37 - loss: 6.971 - ETA: 28:20:21 - loss: 6.971 - ETA: 28:19:04 - loss: 6.971 - ETA: 28:17:48 - loss: 6.971 - ETA: 28:16:33 - loss: 6.973 - ETA: 28:15:16 - loss: 6.973 - ETA: 28:14:01 - loss: 6.975 - ETA: 28:12:46 - loss: 6.975 - ETA: 28:11:30 - loss: 6.974 - ETA: 28:10:13 - loss: 6.974 - ETA: 28:08:59 - loss: 6.975 - ETA: 28:07:43 - loss: 6.975 - ETA: 28:06:26 - loss: 6.974 - ETA: 28:05:11 - loss: 6.973 - ETA: 28:03:57 - loss: 6.972 - ETA: 28:02:42 - loss: 6.971 - ETA: 28:01:32 - loss: 6.971 - ETA: 28:00:20 - loss: 6.971 - ETA: 27:59:08 - loss: 6.969 - ETA: 27:57:53 - loss: 6.970 - ETA: 27:56:39 - loss: 6.971 - ETA: 27:55:27 - loss: 6.970 - ETA: 27:54:11 - loss: 6.969 - ETA: 27:52:56 - loss: 6.969 - ETA: 27:51:45 - loss: 6.970 - ETA: 27:50:33 - loss: 6.971 - ETA: 27:49:19 - loss: 6.970 - ETA: 27:48:05 - loss: 6.970 - ETA: 27:46:56 - loss: 6.970 - ETA: 27:45:45 - loss: 6.971 - ETA: 27:44:31 - loss: 6.971 - ETA: 27:43:18 - loss: 6.972 - ETA: 27:42:08 - loss: 6.970 - ETA: 27:40:54 - loss: 6.969 - ETA: 27:39:41 - loss: 6.969 - ETA: 27:38:30 - loss: 6.970 - ETA: 27:37:19 - loss: 6.971 - ETA: 27:36:07 - loss: 6.970 - ETA: 27:34:58 - loss: 6.970 - ETA: 27:33:48 - loss: 6.970 - ETA: 27:32:35 - loss: 6.971 - ETA: 27:31:23 - loss: 6.970 - ETA: 27:30:14 - loss: 6.971 - ETA: 27:29:05 - loss: 6.970 - ETA: 27:27:53 - loss: 6.970 - ETA: 27:26:42 - loss: 6.971 - ETA: 27:25:33 - loss: 6.971 - ETA: 27:24:21 - loss: 6.972 - ETA: 27:23:09 - loss: 6.972 - ETA: 27:22:03 - loss: 6.973 - ETA: 27:21:05 - loss: 6.973 - ETA: 27:19:54 - loss: 6.974 - ETA: 27:18:47 - loss: 6.975 - ETA: 27:17:41 - loss: 6.975 - ETA: 27:16:32 - loss: 6.974 - ETA: 27:15:22 - loss: 6.974 - ETA: 27:14:13 - loss: 6.973 - ETA: 27:13:09 - loss: 6.973 - ETA: 27:12:06 - loss: 6.975 - ETA: 27:10:57 - loss: 6.976 - ETA: 27:09:50 - loss: 6.976 - ETA: 27:08:43 - loss: 6.976 - ETA: 27:07:36 - loss: 6.975 - ETA: 27:06:33 - loss: 6.975 - ETA: 27:05:31 - loss: 6.975 - ETA: 27:04:26 - loss: 6.974 - ETA: 27:03:21 - loss: 6.974 - ETA: 27:02:22 - loss: 6.973 - ETA: 27:01:19 - loss: 6.973 - ETA: 27:00:13 - loss: 6.973 - ETA: 26:59:09 - loss: 6.974 - ETA: 26:58:11 - loss: 6.973 - ETA: 26:57:18 - loss: 6.973 - ETA: 26:56:21 - loss: 6.973 - ETA: 26:55:23 - loss: 6.974 - ETA: 26:54:22 - loss: 6.974 - ETA: 26:53:19 - loss: 6.973 - ETA: 26:52:18 - loss: 6.974 - ETA: 26:51:24 - loss: 6.975 - ETA: 26:50:29 - loss: 6.976 - ETA: 26:49:27 - loss: 6.976 - ETA: 26:48:25 - loss: 6.976 - ETA: 26:47:23 - loss: 6.977 - ETA: 26:46:21 - loss: 6.977 - ETA: 26:45:19 - loss: 6.977 - ETA: 26:44:21 - loss: 6.978 - ETA: 26:43:21 - loss: 6.977 - ETA: 26:42:18 - loss: 6.977 - ETA: 26:41:17 - loss: 6.976 - ETA: 26:40:18 - loss: 6.976 - ETA: 26:39:15 - loss: 6.979 - ETA: 26:38:13 - loss: 6.980 - ETA: 26:37:15 - loss: 6.981 - ETA: 26:36:16 - loss: 6.981 - ETA: 26:35:18 - loss: 6.981 - ETA: 26:34:17 - loss: 6.983 - ETA: 26:33:17 - loss: 6.983 - ETA: 26:32:18 - loss: 6.984 - ETA: 26:31:18 - loss: 6.983 - ETA: 26:30:17 - loss: 6.984 - ETA: 26:29:18 - loss: 6.985 - ETA: 26:28:17 - loss: 6.985 - ETA: 26:27:14 - loss: 6.984 - ETA: 26:26:15 - loss: 6.984 - ETA: 26:25:14 - loss: 6.982 - ETA: 26:24:10 - loss: 6.982 - ETA: 26:23:09 - loss: 6.983 - ETA: 26:22:08 - loss: 6.983 - ETA: 26:21:04 - loss: 6.983 - ETA: 26:20:01 - loss: 6.982 - ETA: 26:19:00 - loss: 6.982 - ETA: 26:17:59 - loss: 6.981 - ETA: 26:16:57 - loss: 6.981 - ETA: 26:15:58 - loss: 6.980 - ETA: 26:14:58 - loss: 6.980 - ETA: 26:13:55 - loss: 6.980 - ETA: 26:12:53 - loss: 6.979 - ETA: 26:11:55 - loss: 6.980 - ETA: 26:10:55 - loss: 6.980 - ETA: 26:09:53 - loss: 6.980 - ETA: 26:08:52 - loss: 6.980 - ETA: 26:07:53 - loss: 6.981 - ETA: 26:06:53 - loss: 6.982 - ETA: 26:05:54 - loss: 6.982 - ETA: 26:04:53 - loss: 6.982 - ETA: 26:03:55 - loss: 6.982 - ETA: 26:02:53 - loss: 6.982 - ETA: 26:01:52 - loss: 6.982 - ETA: 26:00:54 - loss: 6.982 - ETA: 25:59:55 - loss: 6.982 - ETA: 25:58:54 - loss: 6.981 - ETA: 25:57:53 - loss: 6.982 - ETA: 25:56:55 - loss: 6.981 - ETA: 25:55:56 - loss: 6.982 - ETA: 25:54:55 - loss: 6.982 - ETA: 25:53:58 - loss: 6.982 - ETA: 25:53:00 - loss: 6.981 - ETA: 25:52:01 - loss: 6.979 - ETA: 25:51:01 - loss: 6.978 - ETA: 25:50:05 - loss: 6.976 - ETA: 25:49:05 - loss: 6.975 - ETA: 25:48:04 - loss: 6.976 - ETA: 25:47:05 - loss: 6.976 - ETA: 25:46:10 - loss: 6.975 - ETA: 25:45:11 - loss: 6.974 - ETA: 25:44:13 - loss: 6.975 - ETA: 25:43:16 - loss: 6.975 - ETA: 25:42:19 - loss: 6.975 - ETA: 25:41:20 - loss: 6.975 - ETA: 25:40:22 - loss: 6.975 - ETA: 25:39:25 - loss: 6.975 - ETA: 25:38:27 - loss: 6.975 - ETA: 25:37:28 - loss: 6.975 - ETA: 25:36:34 - loss: 6.975 - ETA: 25:35:38 - loss: 6.975 - ETA: 25:34:41 - loss: 6.976 - ETA: 25:33:45 - loss: 6.976 - ETA: 25:32:49 - loss: 6.976 - ETA: 25:31:51 - loss: 6.976 - ETA: 25:30:55 - loss: 6.975 - ETA: 25:30:01 - loss: 6.975 - ETA: 25:29:06 - loss: 6.976 - ETA: 25:28:10 - loss: 6.975 - ETA: 25:27:16 - loss: 6.975 - ETA: 25:26:21 - loss: 6.974 - ETA: 25:25:24 - loss: 6.974 - ETA: 25:24:26 - loss: 6.974 - ETA: 25:23:31 - loss: 6.975 - ETA: 25:22:37 - loss: 6.975 - ETA: 25:21:40 - loss: 6.975 - ETA: 25:20:43 - loss: 6.975 - ETA: 25:19:50 - loss: 6.975 - ETA: 25:18:55 - loss: 6.976 - ETA: 25:18:00 - loss: 6.976 - ETA: 25:17:05 - loss: 6.976 - ETA: 25:16:12 - loss: 6.976 - ETA: 25:15:15 - loss: 6.975 - ETA: 25:14:19 - loss: 6.975 - ETA: 25:13:26 - loss: 6.973 - ETA: 25:12:33 - loss: 6.973 - ETA: 25:11:37 - loss: 6.972 - ETA: 25:10:42 - loss: 6.973 - ETA: 25:09:49 - loss: 6.973 - ETA: 25:08:54 - loss: 6.972 - ETA: 25:07:59 - loss: 6.972 - ETA: 25:07:07 - loss: 6.971 - ETA: 25:06:15 - loss: 6.971 - ETA: 25:05:20 - loss: 6.970 - ETA: 25:04:26 - loss: 6.971 - ETA: 25:03:34 - loss: 6.971 - ETA: 25:02:41 - loss: 6.971 - ETA: 25:01:46 - loss: 6.971 - ETA: 25:00:54 - loss: 6.971 - ETA: 25:00:02 - loss: 6.971 - ETA: 24:59:07 - loss: 6.970 - ETA: 24:58:14 - loss: 6.971 - ETA: 24:57:23 - loss: 6.970 - ETA: 24:56:31 - loss: 6.969 - ETA: 24:55:38 - loss: 6.968 - ETA: 24:54:45 - loss: 6.968 - ETA: 24:53:54 - loss: 6.968 - ETA: 24:53:00 - loss: 6.968 - ETA: 24:52:09 - loss: 6.968 - ETA: 24:51:18 - loss: 6.967 - ETA: 24:50:26 - loss: 6.968 - ETA: 24:49:32 - loss: 6.968 - ETA: 24:48:41 - loss: 6.968 - ETA: 24:47:51 - loss: 6.969 - ETA: 24:46:58 - loss: 6.969 - ETA: 24:46:05 - loss: 6.968 - ETA: 24:45:15 - loss: 6.968 - ETA: 24:44:24 - loss: 6.968 - ETA: 24:43:33 - loss: 6.968 - ETA: 24:42:41 - loss: 6.969 - ETA: 24:41:50 - loss: 6.969 - ETA: 24:41:00 - loss: 6.969 - ETA: 24:40:07 - loss: 6.969 - ETA: 24:39:16 - loss: 6.969 - ETA: 24:38:27 - loss: 6.968 - ETA: 24:37:34 - loss: 6.968 - ETA: 24:36:42 - loss: 6.969 - ETA: 24:35:53 - loss: 6.968 - ETA: 24:35:04 - loss: 6.969 - ETA: 24:34:13 - loss: 6.969 - ETA: 24:33:22 - loss: 6.970 - ETA: 24:32:34 - loss: 6.972 - ETA: 24:31:43 - loss: 6.971 - ETA: 24:30:52 - loss: 6.971 - ETA: 24:30:03 - loss: 6.971 - ETA: 24:29:14 - loss: 6.970 - ETA: 24:28:23 - loss: 6.971 - ETA: 24:27:33 - loss: 6.971 - ETA: 24:26:46 - loss: 6.972 - ETA: 24:25:55 - loss: 6.973 - ETA: 24:25:05 - loss: 6.972 - ETA: 24:24:17 - loss: 6.972 - ETA: 24:23:28 - loss: 6.972 - ETA: 24:22:37 - loss: 6.971 - ETA: 24:21:47 - loss: 6.972 - ETA: 24:20:59 - loss: 6.972 - ETA: 24:20:10 - loss: 6.971 - ETA: 24:19:19 - loss: 6.972 - ETA: 24:18:31 - loss: 6.973 - ETA: 24:17:43 - loss: 6.973 - ETA: 24:16:53 - loss: 6.972 - ETA: 24:16:04 - loss: 6.973 - ETA: 24:15:16 - loss: 6.972 - ETA: 24:14:28 - loss: 6.971 - ETA: 24:13:39 - loss: 6.972 - ETA: 24:12:50 - loss: 6.972 - ETA: 24:12:02 - loss: 6.972 - ETA: 24:11:13 - loss: 6.972 - ETA: 24:10:25 - loss: 6.973 - ETA: 24:09:41 - loss: 6.972 - ETA: 24:08:54 - loss: 6.972 - ETA: 24:08:05 - loss: 6.9726"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 173824/1125047 [===>..........................] - ETA: 24:07:16 - loss: 6.971 - ETA: 24:06:30 - loss: 6.970 - ETA: 24:05:42 - loss: 6.971 - ETA: 24:04:53 - loss: 6.971 - ETA: 24:04:07 - loss: 6.971 - ETA: 24:03:22 - loss: 6.971 - ETA: 24:02:33 - loss: 6.971 - ETA: 24:01:45 - loss: 6.971 - ETA: 24:00:59 - loss: 6.972 - ETA: 24:00:12 - loss: 6.972 - ETA: 23:59:23 - loss: 6.973 - ETA: 23:58:36 - loss: 6.974 - ETA: 23:57:50 - loss: 6.973 - ETA: 23:57:02 - loss: 6.973 - ETA: 23:56:15 - loss: 6.972 - ETA: 23:55:30 - loss: 6.972 - ETA: 23:54:44 - loss: 6.972 - ETA: 23:53:56 - loss: 6.972 - ETA: 23:53:09 - loss: 6.973 - ETA: 23:52:24 - loss: 6.972 - ETA: 23:51:37 - loss: 6.971 - ETA: 23:50:49 - loss: 6.971 - ETA: 23:50:04 - loss: 6.971 - ETA: 23:49:18 - loss: 6.970 - ETA: 23:48:31 - loss: 6.971 - ETA: 23:47:46 - loss: 6.971 - ETA: 23:47:00 - loss: 6.972 - ETA: 23:46:13 - loss: 6.972 - ETA: 23:45:26 - loss: 6.973 - ETA: 23:44:41 - loss: 6.973 - ETA: 23:43:56 - loss: 6.972 - ETA: 23:43:09 - loss: 6.971 - ETA: 23:42:23 - loss: 6.971 - ETA: 23:41:38 - loss: 6.971 - ETA: 23:40:53 - loss: 6.971 - ETA: 23:40:09 - loss: 6.971 - ETA: 23:39:23 - loss: 6.971 - ETA: 23:38:39 - loss: 6.972 - ETA: 23:37:53 - loss: 6.971 - ETA: 23:37:07 - loss: 6.971 - ETA: 23:36:23 - loss: 6.971 - ETA: 23:35:38 - loss: 6.970 - ETA: 23:34:52 - loss: 6.968 - ETA: 23:34:07 - loss: 6.969 - ETA: 23:33:23 - loss: 6.969 - ETA: 23:32:39 - loss: 6.970 - ETA: 23:31:53 - loss: 6.969 - ETA: 23:31:10 - loss: 6.969 - ETA: 23:30:26 - loss: 6.968 - ETA: 23:29:40 - loss: 6.967 - ETA: 23:28:55 - loss: 6.967 - ETA: 23:28:12 - loss: 6.967 - ETA: 23:27:26 - loss: 6.968 - ETA: 23:26:39 - loss: 6.968 - ETA: 23:25:55 - loss: 6.968 - ETA: 23:25:13 - loss: 6.968 - ETA: 23:24:27 - loss: 6.969 - ETA: 23:23:43 - loss: 6.969 - ETA: 23:23:00 - loss: 6.969 - ETA: 23:22:17 - loss: 6.969 - ETA: 23:21:32 - loss: 6.969 - ETA: 23:20:49 - loss: 6.968 - ETA: 23:20:06 - loss: 6.969 - ETA: 23:19:21 - loss: 6.968 - ETA: 23:18:37 - loss: 6.967 - ETA: 23:17:56 - loss: 6.968 - ETA: 23:17:13 - loss: 6.967 - ETA: 23:16:29 - loss: 6.967 - ETA: 23:15:45 - loss: 6.967 - ETA: 23:15:02 - loss: 6.966 - ETA: 23:14:18 - loss: 6.966 - ETA: 23:13:34 - loss: 6.966 - ETA: 23:12:52 - loss: 6.966 - ETA: 23:12:10 - loss: 6.965 - ETA: 23:11:26 - loss: 6.965 - ETA: 23:10:43 - loss: 6.965 - ETA: 23:10:02 - loss: 6.964 - ETA: 23:09:18 - loss: 6.965 - ETA: 23:08:33 - loss: 6.964 - ETA: 23:07:50 - loss: 6.964 - ETA: 23:07:08 - loss: 6.964 - ETA: 23:06:24 - loss: 6.964 - ETA: 23:05:41 - loss: 6.963 - ETA: 23:05:02 - loss: 6.962 - ETA: 23:04:28 - loss: 6.961 - ETA: 23:03:47 - loss: 6.961 - ETA: 23:03:05 - loss: 6.962 - ETA: 23:02:24 - loss: 6.962 - ETA: 23:01:41 - loss: 6.962 - ETA: 23:00:58 - loss: 6.962 - ETA: 23:00:18 - loss: 6.963 - ETA: 22:59:36 - loss: 6.962 - ETA: 22:58:54 - loss: 6.962 - ETA: 22:58:13 - loss: 6.963 - ETA: 22:57:32 - loss: 6.964 - ETA: 22:56:51 - loss: 6.964 - ETA: 22:56:08 - loss: 6.965 - ETA: 22:55:28 - loss: 6.964 - ETA: 22:54:47 - loss: 6.964 - ETA: 22:54:04 - loss: 6.963 - ETA: 22:53:23 - loss: 6.964 - ETA: 22:52:44 - loss: 6.965 - ETA: 22:52:03 - loss: 6.965 - ETA: 22:51:19 - loss: 6.964 - ETA: 22:50:38 - loss: 6.963 - ETA: 22:50:00 - loss: 6.963 - ETA: 22:49:18 - loss: 6.963 - ETA: 22:48:37 - loss: 6.963 - ETA: 22:47:57 - loss: 6.963 - ETA: 22:47:17 - loss: 6.962 - ETA: 22:46:35 - loss: 6.963 - ETA: 22:45:54 - loss: 6.963 - ETA: 22:45:14 - loss: 6.962 - ETA: 22:44:32 - loss: 6.961 - ETA: 22:43:51 - loss: 6.962 - ETA: 22:43:13 - loss: 6.962 - ETA: 22:42:33 - loss: 6.963 - ETA: 22:41:53 - loss: 6.963 - ETA: 22:41:14 - loss: 6.964 - ETA: 22:40:41 - loss: 6.964 - ETA: 22:40:09 - loss: 6.965 - ETA: 22:39:35 - loss: 6.964 - ETA: 22:38:57 - loss: 6.965 - ETA: 22:38:19 - loss: 6.965 - ETA: 22:37:39 - loss: 6.966 - ETA: 22:36:58 - loss: 6.966 - ETA: 22:36:20 - loss: 6.966 - ETA: 22:35:39 - loss: 6.965 - ETA: 22:34:57 - loss: 6.966 - ETA: 22:34:17 - loss: 6.966 - ETA: 22:33:39 - loss: 6.966 - ETA: 22:32:59 - loss: 6.966 - ETA: 22:32:19 - loss: 6.966 - ETA: 22:31:41 - loss: 6.966 - ETA: 22:31:03 - loss: 6.967 - ETA: 22:30:23 - loss: 6.968 - ETA: 22:29:45 - loss: 6.968 - ETA: 22:29:06 - loss: 6.968 - ETA: 22:28:26 - loss: 6.968 - ETA: 22:27:46 - loss: 6.970 - ETA: 22:27:09 - loss: 6.969 - ETA: 22:26:32 - loss: 6.969 - ETA: 22:25:52 - loss: 6.968 - ETA: 22:25:14 - loss: 6.969 - ETA: 22:24:38 - loss: 6.969 - ETA: 22:23:59 - loss: 6.969 - ETA: 22:23:20 - loss: 6.968 - ETA: 22:22:42 - loss: 6.969 - ETA: 22:22:04 - loss: 6.968 - ETA: 22:21:25 - loss: 6.968 - ETA: 22:20:46 - loss: 6.968 - ETA: 22:20:08 - loss: 6.969 - ETA: 22:19:30 - loss: 6.969 - ETA: 22:18:51 - loss: 6.969 - ETA: 22:18:14 - loss: 6.969 - ETA: 22:17:37 - loss: 6.969 - ETA: 22:16:57 - loss: 6.970 - ETA: 22:16:18 - loss: 6.969 - ETA: 22:15:42 - loss: 6.970 - ETA: 22:15:05 - loss: 6.969 - ETA: 22:14:27 - loss: 6.970 - ETA: 22:13:49 - loss: 6.971 - ETA: 22:13:12 - loss: 6.971 - ETA: 22:12:33 - loss: 6.971 - ETA: 22:11:55 - loss: 6.972 - ETA: 22:11:18 - loss: 6.971 - ETA: 22:10:42 - loss: 6.971 - ETA: 22:10:04 - loss: 6.972 - ETA: 22:09:26 - loss: 6.971 - ETA: 22:08:49 - loss: 6.972 - ETA: 22:08:11 - loss: 6.971 - ETA: 22:07:32 - loss: 6.971 - ETA: 22:06:57 - loss: 6.971 - ETA: 22:06:20 - loss: 6.971 - ETA: 22:05:43 - loss: 6.972 - ETA: 22:05:06 - loss: 6.972 - ETA: 22:04:30 - loss: 6.973 - ETA: 22:03:52 - loss: 6.973 - ETA: 22:03:16 - loss: 6.973 - ETA: 22:02:39 - loss: 6.973 - ETA: 22:02:03 - loss: 6.972 - ETA: 22:01:25 - loss: 6.971 - ETA: 22:00:49 - loss: 6.970 - ETA: 22:00:15 - loss: 6.971 - ETA: 21:59:41 - loss: 6.970 - ETA: 21:59:04 - loss: 6.970 - ETA: 21:58:27 - loss: 6.970 - ETA: 21:57:52 - loss: 6.969 - ETA: 21:57:14 - loss: 6.969 - ETA: 21:56:37 - loss: 6.969 - ETA: 21:56:02 - loss: 6.971 - ETA: 21:55:26 - loss: 6.970 - ETA: 21:54:49 - loss: 6.970 - ETA: 21:54:14 - loss: 6.970 - ETA: 21:53:44 - loss: 6.970 - ETA: 21:53:11 - loss: 6.971 - ETA: 21:52:38 - loss: 6.971 - ETA: 21:52:04 - loss: 6.972 - ETA: 21:51:30 - loss: 6.972 - ETA: 21:50:54 - loss: 6.972 - ETA: 21:50:17 - loss: 6.971 - ETA: 21:49:43 - loss: 6.971 - ETA: 21:49:07 - loss: 6.973 - ETA: 21:48:32 - loss: 6.973 - ETA: 21:47:56 - loss: 6.972 - ETA: 21:47:21 - loss: 6.971 - ETA: 21:46:44 - loss: 6.972 - ETA: 21:46:07 - loss: 6.972 - ETA: 21:45:33 - loss: 6.972 - ETA: 21:44:57 - loss: 6.971 - ETA: 21:44:21 - loss: 6.971 - ETA: 21:43:45 - loss: 6.971 - ETA: 21:43:10 - loss: 6.971 - ETA: 21:42:35 - loss: 6.971 - ETA: 21:41:59 - loss: 6.972 - ETA: 21:41:25 - loss: 6.971 - ETA: 21:40:50 - loss: 6.971 - ETA: 21:40:14 - loss: 6.971 - ETA: 21:39:40 - loss: 6.971 - ETA: 21:39:05 - loss: 6.970 - ETA: 21:38:29 - loss: 6.970 - ETA: 21:37:53 - loss: 6.970 - ETA: 21:37:20 - loss: 6.970 - ETA: 21:36:47 - loss: 6.970 - ETA: 21:36:11 - loss: 6.969 - ETA: 21:35:35 - loss: 6.968 - ETA: 21:35:05 - loss: 6.969 - ETA: 21:34:34 - loss: 6.969 - ETA: 21:34:03 - loss: 6.969 - ETA: 21:33:31 - loss: 6.969 - ETA: 21:32:57 - loss: 6.968 - ETA: 21:32:22 - loss: 6.968 - ETA: 21:31:48 - loss: 6.968 - ETA: 21:31:15 - loss: 6.967 - ETA: 21:30:41 - loss: 6.967 - ETA: 21:30:06 - loss: 6.966 - ETA: 21:29:31 - loss: 6.967 - ETA: 21:28:57 - loss: 6.967 - ETA: 21:28:22 - loss: 6.967 - ETA: 21:27:47 - loss: 6.968 - ETA: 21:27:14 - loss: 6.967 - ETA: 21:26:40 - loss: 6.967 - ETA: 21:26:06 - loss: 6.967 - ETA: 21:25:32 - loss: 6.967 - ETA: 21:24:59 - loss: 6.967 - ETA: 21:24:24 - loss: 6.968 - ETA: 21:23:48 - loss: 6.968 - ETA: 21:23:14 - loss: 6.968 - ETA: 21:22:41 - loss: 6.969 - ETA: 21:22:06 - loss: 6.969 - ETA: 21:21:32 - loss: 6.968 - ETA: 21:20:59 - loss: 6.967 - ETA: 21:20:27 - loss: 6.967 - ETA: 21:19:52 - loss: 6.966 - ETA: 21:19:18 - loss: 6.966 - ETA: 21:18:46 - loss: 6.967 - ETA: 21:18:11 - loss: 6.967 - ETA: 21:17:36 - loss: 6.966 - ETA: 21:17:04 - loss: 6.966 - ETA: 21:16:31 - loss: 6.966 - ETA: 21:15:56 - loss: 6.966 - ETA: 21:15:24 - loss: 6.966 - ETA: 21:14:52 - loss: 6.966 - ETA: 21:14:18 - loss: 6.966 - ETA: 21:13:43 - loss: 6.966 - ETA: 21:13:11 - loss: 6.967 - ETA: 21:12:39 - loss: 6.967 - ETA: 21:12:05 - loss: 6.966 - ETA: 21:11:31 - loss: 6.966 - ETA: 21:10:59 - loss: 6.966 - ETA: 21:10:26 - loss: 6.966 - ETA: 21:09:51 - loss: 6.9671"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 208640/1125047 [====>.........................] - ETA: 21:09:19 - loss: 6.967 - ETA: 21:08:46 - loss: 6.967 - ETA: 21:08:12 - loss: 6.968 - ETA: 21:07:39 - loss: 6.969 - ETA: 21:07:08 - loss: 6.969 - ETA: 21:06:35 - loss: 6.969 - ETA: 21:06:02 - loss: 6.969 - ETA: 21:05:29 - loss: 6.970 - ETA: 21:04:56 - loss: 6.970 - ETA: 21:04:23 - loss: 6.970 - ETA: 21:03:53 - loss: 6.971 - ETA: 21:03:21 - loss: 6.970 - ETA: 21:02:49 - loss: 6.970 - ETA: 21:02:16 - loss: 6.970 - ETA: 21:01:43 - loss: 6.970 - ETA: 21:01:12 - loss: 6.970 - ETA: 21:00:38 - loss: 6.970 - ETA: 21:00:08 - loss: 6.970 - ETA: 20:59:45 - loss: 6.970 - ETA: 20:59:22 - loss: 6.969 - ETA: 20:58:50 - loss: 6.970 - ETA: 20:58:17 - loss: 6.970 - ETA: 20:57:46 - loss: 6.970 - ETA: 20:57:13 - loss: 6.970 - ETA: 20:56:41 - loss: 6.970 - ETA: 20:56:09 - loss: 6.970 - ETA: 20:55:38 - loss: 6.969 - ETA: 20:55:05 - loss: 6.969 - ETA: 20:54:33 - loss: 6.970 - ETA: 20:54:03 - loss: 6.970 - ETA: 20:53:32 - loss: 6.970 - ETA: 20:52:59 - loss: 6.969 - ETA: 20:52:27 - loss: 6.968 - ETA: 20:51:56 - loss: 6.969 - ETA: 20:51:24 - loss: 6.969 - ETA: 20:50:52 - loss: 6.970 - ETA: 20:50:21 - loss: 6.970 - ETA: 20:49:51 - loss: 6.971 - ETA: 20:49:18 - loss: 6.971 - ETA: 20:48:48 - loss: 6.971 - ETA: 20:48:17 - loss: 6.971 - ETA: 20:47:45 - loss: 6.971 - ETA: 20:47:13 - loss: 6.971 - ETA: 20:46:42 - loss: 6.972 - ETA: 20:46:12 - loss: 6.972 - ETA: 20:45:40 - loss: 6.973 - ETA: 20:45:08 - loss: 6.972 - ETA: 20:44:37 - loss: 6.971 - ETA: 20:44:07 - loss: 6.970 - ETA: 20:43:37 - loss: 6.970 - ETA: 20:43:06 - loss: 6.970 - ETA: 20:42:35 - loss: 6.969 - ETA: 20:42:03 - loss: 6.970 - ETA: 20:41:31 - loss: 6.971 - ETA: 20:41:01 - loss: 6.970 - ETA: 20:40:31 - loss: 6.969 - ETA: 20:40:01 - loss: 6.969 - ETA: 20:39:33 - loss: 6.970 - ETA: 20:39:07 - loss: 6.970 - ETA: 20:38:36 - loss: 6.969 - ETA: 20:38:04 - loss: 6.969 - ETA: 20:37:35 - loss: 6.970 - ETA: 20:37:04 - loss: 6.970 - ETA: 20:36:33 - loss: 6.969 - ETA: 20:36:02 - loss: 6.969 - ETA: 20:35:32 - loss: 6.969 - ETA: 20:35:01 - loss: 6.969 - ETA: 20:34:30 - loss: 6.969 - ETA: 20:34:02 - loss: 6.969 - ETA: 20:33:35 - loss: 6.968 - ETA: 20:33:05 - loss: 6.969 - ETA: 20:32:34 - loss: 6.968 - ETA: 20:32:05 - loss: 6.969 - ETA: 20:31:35 - loss: 6.968 - ETA: 20:31:04 - loss: 6.968 - ETA: 20:30:34 - loss: 6.970 - ETA: 20:30:05 - loss: 6.970 - ETA: 20:29:34 - loss: 6.971 - ETA: 20:29:04 - loss: 6.970 - ETA: 20:28:36 - loss: 6.970 - ETA: 20:28:08 - loss: 6.971 - ETA: 20:27:38 - loss: 6.972 - ETA: 20:27:08 - loss: 6.971 - ETA: 20:26:38 - loss: 6.971 - ETA: 20:26:08 - loss: 6.970 - ETA: 20:25:37 - loss: 6.969 - ETA: 20:25:08 - loss: 6.969 - ETA: 20:24:39 - loss: 6.969 - ETA: 20:24:10 - loss: 6.969 - ETA: 20:23:40 - loss: 6.969 - ETA: 20:23:11 - loss: 6.969 - ETA: 20:22:41 - loss: 6.970 - ETA: 20:22:10 - loss: 6.970 - ETA: 20:21:42 - loss: 6.971 - ETA: 20:21:13 - loss: 6.971 - ETA: 20:20:43 - loss: 6.972 - ETA: 20:20:13 - loss: 6.972 - ETA: 20:19:44 - loss: 6.972 - ETA: 20:19:16 - loss: 6.973 - ETA: 20:18:46 - loss: 6.973 - ETA: 20:18:16 - loss: 6.972 - ETA: 20:17:48 - loss: 6.973 - ETA: 20:17:19 - loss: 6.972 - ETA: 20:16:55 - loss: 6.972 - ETA: 20:16:27 - loss: 6.971 - ETA: 20:15:58 - loss: 6.971 - ETA: 20:15:28 - loss: 6.971 - ETA: 20:15:00 - loss: 6.971 - ETA: 20:14:32 - loss: 6.971 - ETA: 20:14:02 - loss: 6.971 - ETA: 20:13:32 - loss: 6.972 - ETA: 20:13:04 - loss: 6.971 - ETA: 20:12:36 - loss: 6.972 - ETA: 20:12:06 - loss: 6.972 - ETA: 20:11:36 - loss: 6.972 - ETA: 20:11:09 - loss: 6.972 - ETA: 20:10:39 - loss: 6.973 - ETA: 20:10:10 - loss: 6.973 - ETA: 20:09:42 - loss: 6.973 - ETA: 20:09:14 - loss: 6.974 - ETA: 20:08:44 - loss: 6.974 - ETA: 20:08:15 - loss: 6.973 - ETA: 20:07:49 - loss: 6.973 - ETA: 20:07:21 - loss: 6.973 - ETA: 20:06:52 - loss: 6.972 - ETA: 20:06:26 - loss: 6.972 - ETA: 20:05:58 - loss: 6.972 - ETA: 20:05:30 - loss: 6.973 - ETA: 20:05:01 - loss: 6.972 - ETA: 20:04:33 - loss: 6.973 - ETA: 20:04:05 - loss: 6.973 - ETA: 20:03:36 - loss: 6.972 - ETA: 20:03:07 - loss: 6.973 - ETA: 20:02:40 - loss: 6.973 - ETA: 20:02:10 - loss: 6.973 - ETA: 20:01:41 - loss: 6.974 - ETA: 20:01:14 - loss: 6.973 - ETA: 20:00:47 - loss: 6.973 - ETA: 20:00:18 - loss: 6.973 - ETA: 19:59:49 - loss: 6.973 - ETA: 19:59:22 - loss: 6.973 - ETA: 19:58:52 - loss: 6.973 - ETA: 19:58:23 - loss: 6.974 - ETA: 19:57:56 - loss: 6.974 - ETA: 19:57:29 - loss: 6.974 - ETA: 19:57:00 - loss: 6.974 - ETA: 19:56:32 - loss: 6.973 - ETA: 19:56:05 - loss: 6.973 - ETA: 19:55:37 - loss: 6.973 - ETA: 19:55:09 - loss: 6.973 - ETA: 19:54:41 - loss: 6.974 - ETA: 19:54:13 - loss: 6.974 - ETA: 19:53:45 - loss: 6.973 - ETA: 19:53:16 - loss: 6.973 - ETA: 19:52:50 - loss: 6.973 - ETA: 19:52:23 - loss: 6.974 - ETA: 19:51:55 - loss: 6.973 - ETA: 19:51:28 - loss: 6.972 - ETA: 19:51:02 - loss: 6.972 - ETA: 19:50:33 - loss: 6.972 - ETA: 19:50:05 - loss: 6.973 - ETA: 19:49:38 - loss: 6.973 - ETA: 19:49:11 - loss: 6.973 - ETA: 19:48:44 - loss: 6.973 - ETA: 19:48:17 - loss: 6.974 - ETA: 19:47:50 - loss: 6.974 - ETA: 19:47:21 - loss: 6.974 - ETA: 19:46:54 - loss: 6.974 - ETA: 19:46:27 - loss: 6.975 - ETA: 19:46:00 - loss: 6.975 - ETA: 19:45:32 - loss: 6.975 - ETA: 19:45:05 - loss: 6.974 - ETA: 19:44:38 - loss: 6.975 - ETA: 19:44:11 - loss: 6.975 - ETA: 19:43:43 - loss: 6.974 - ETA: 19:43:16 - loss: 6.974 - ETA: 19:42:49 - loss: 6.975 - ETA: 19:42:22 - loss: 6.975 - ETA: 19:41:54 - loss: 6.974 - ETA: 19:41:30 - loss: 6.974 - ETA: 19:41:04 - loss: 6.974 - ETA: 19:40:36 - loss: 6.974 - ETA: 19:40:09 - loss: 6.974 - ETA: 19:39:43 - loss: 6.974 - ETA: 19:39:15 - loss: 6.974 - ETA: 19:38:47 - loss: 6.974 - ETA: 19:38:21 - loss: 6.974 - ETA: 19:37:55 - loss: 6.975 - ETA: 19:37:27 - loss: 6.975 - ETA: 19:37:00 - loss: 6.975 - ETA: 19:36:34 - loss: 6.975 - ETA: 19:36:06 - loss: 6.975 - ETA: 19:35:39 - loss: 6.975 - ETA: 19:35:13 - loss: 6.974 - ETA: 19:34:47 - loss: 6.974 - ETA: 19:34:19 - loss: 6.974 - ETA: 19:33:52 - loss: 6.974 - ETA: 19:33:27 - loss: 6.974 - ETA: 19:33:01 - loss: 6.973 - ETA: 19:32:34 - loss: 6.973 - ETA: 19:32:07 - loss: 6.973 - ETA: 19:31:41 - loss: 6.973 - ETA: 19:31:13 - loss: 6.973 - ETA: 19:30:47 - loss: 6.973 - ETA: 19:30:21 - loss: 6.974 - ETA: 19:29:57 - loss: 6.974 - ETA: 19:29:30 - loss: 6.974 - ETA: 19:29:03 - loss: 6.974 - ETA: 19:28:38 - loss: 6.974 - ETA: 19:28:12 - loss: 6.974 - ETA: 19:27:45 - loss: 6.974 - ETA: 19:27:19 - loss: 6.973 - ETA: 19:26:54 - loss: 6.973 - ETA: 19:26:27 - loss: 6.973 - ETA: 19:26:00 - loss: 6.973 - ETA: 19:25:35 - loss: 6.973 - ETA: 19:25:08 - loss: 6.974 - ETA: 19:24:40 - loss: 6.974 - ETA: 19:24:15 - loss: 6.975 - ETA: 19:23:49 - loss: 6.975 - ETA: 19:23:23 - loss: 6.975 - ETA: 19:22:58 - loss: 6.975 - ETA: 19:22:32 - loss: 6.976 - ETA: 19:22:07 - loss: 6.976 - ETA: 19:21:41 - loss: 6.976 - ETA: 19:21:14 - loss: 6.976 - ETA: 19:20:50 - loss: 6.976 - ETA: 19:20:23 - loss: 6.975 - ETA: 19:19:57 - loss: 6.975 - ETA: 19:19:32 - loss: 6.975 - ETA: 19:19:06 - loss: 6.975 - ETA: 19:18:40 - loss: 6.975 - ETA: 19:18:14 - loss: 6.975 - ETA: 19:17:49 - loss: 6.976 - ETA: 19:17:22 - loss: 6.976 - ETA: 19:16:56 - loss: 6.975 - ETA: 19:16:32 - loss: 6.975 - ETA: 19:16:07 - loss: 6.975 - ETA: 19:15:42 - loss: 6.975 - ETA: 19:15:17 - loss: 6.975 - ETA: 19:14:52 - loss: 6.975 - ETA: 19:14:26 - loss: 6.974 - ETA: 19:13:59 - loss: 6.974 - ETA: 19:13:33 - loss: 6.974 - ETA: 19:13:08 - loss: 6.974 - ETA: 19:12:42 - loss: 6.973 - ETA: 19:12:17 - loss: 6.973 - ETA: 19:11:53 - loss: 6.974 - ETA: 19:11:28 - loss: 6.974 - ETA: 19:11:02 - loss: 6.974 - ETA: 19:10:37 - loss: 6.974 - ETA: 19:10:13 - loss: 6.974 - ETA: 19:09:46 - loss: 6.975 - ETA: 19:09:20 - loss: 6.975 - ETA: 19:08:56 - loss: 6.974 - ETA: 19:08:31 - loss: 6.974 - ETA: 19:08:06 - loss: 6.974 - ETA: 19:07:41 - loss: 6.973 - ETA: 19:07:17 - loss: 6.973 - ETA: 19:06:51 - loss: 6.974 - ETA: 19:06:26 - loss: 6.973 - ETA: 19:06:02 - loss: 6.973 - ETA: 19:05:37 - loss: 6.973 - ETA: 19:05:12 - loss: 6.973 - ETA: 19:04:47 - loss: 6.973 - ETA: 19:04:23 - loss: 6.974 - ETA: 19:03:58 - loss: 6.972 - ETA: 19:03:32 - loss: 6.973 - ETA: 19:03:07 - loss: 6.973 - ETA: 19:02:43 - loss: 6.973 - ETA: 19:02:17 - loss: 6.973 - ETA: 19:01:52 - loss: 6.9725"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 231168/1125047 [=====>........................] - ETA: 19:01:28 - loss: 6.972 - ETA: 19:01:04 - loss: 6.972 - ETA: 19:00:39 - loss: 6.972 - ETA: 19:00:14 - loss: 6.972 - ETA: 18:59:51 - loss: 6.972 - ETA: 18:59:26 - loss: 6.972 - ETA: 18:59:00 - loss: 6.972 - ETA: 18:58:37 - loss: 6.972 - ETA: 18:58:12 - loss: 6.971 - ETA: 18:57:47 - loss: 6.972 - ETA: 18:57:23 - loss: 6.972 - ETA: 18:56:59 - loss: 6.972 - ETA: 18:56:33 - loss: 6.972 - ETA: 18:56:08 - loss: 6.972 - ETA: 18:55:45 - loss: 6.972 - ETA: 18:55:21 - loss: 6.972 - ETA: 18:54:56 - loss: 6.971 - ETA: 18:54:32 - loss: 6.970 - ETA: 18:54:08 - loss: 6.970 - ETA: 18:53:43 - loss: 6.971 - ETA: 18:53:17 - loss: 6.971 - ETA: 18:52:53 - loss: 6.971 - ETA: 18:52:29 - loss: 6.971 - ETA: 18:52:04 - loss: 6.971 - ETA: 18:51:40 - loss: 6.970 - ETA: 18:51:16 - loss: 6.970 - ETA: 18:50:52 - loss: 6.970 - ETA: 18:50:27 - loss: 6.971 - ETA: 18:50:03 - loss: 6.971 - ETA: 18:49:39 - loss: 6.970 - ETA: 18:49:16 - loss: 6.970 - ETA: 18:48:55 - loss: 6.970 - ETA: 18:48:40 - loss: 6.971 - ETA: 18:48:25 - loss: 6.971 - ETA: 18:48:08 - loss: 6.971 - ETA: 18:47:50 - loss: 6.972 - ETA: 18:47:33 - loss: 6.972 - ETA: 18:47:14 - loss: 6.972 - ETA: 18:46:56 - loss: 6.971 - ETA: 18:46:38 - loss: 6.971 - ETA: 18:46:20 - loss: 6.972 - ETA: 18:46:02 - loss: 6.972 - ETA: 18:45:45 - loss: 6.972 - ETA: 18:45:28 - loss: 6.972 - ETA: 18:45:08 - loss: 6.972 - ETA: 18:44:49 - loss: 6.972 - ETA: 18:44:27 - loss: 6.972 - ETA: 18:44:09 - loss: 6.972 - ETA: 18:43:48 - loss: 6.971 - ETA: 18:43:27 - loss: 6.971 - ETA: 18:43:10 - loss: 6.971 - ETA: 18:42:51 - loss: 6.972 - ETA: 18:42:30 - loss: 6.972 - ETA: 18:42:11 - loss: 6.972 - ETA: 18:41:51 - loss: 6.973 - ETA: 18:41:32 - loss: 6.973 - ETA: 18:41:12 - loss: 6.973 - ETA: 18:40:53 - loss: 6.972 - ETA: 18:40:35 - loss: 6.972 - ETA: 18:40:15 - loss: 6.972 - ETA: 18:39:56 - loss: 6.972 - ETA: 18:39:37 - loss: 6.972 - ETA: 18:39:17 - loss: 6.972 - ETA: 18:38:58 - loss: 6.971 - ETA: 18:38:40 - loss: 6.971 - ETA: 18:38:21 - loss: 6.971 - ETA: 18:38:01 - loss: 6.971 - ETA: 18:37:43 - loss: 6.971 - ETA: 18:37:25 - loss: 6.971 - ETA: 18:37:05 - loss: 6.971 - ETA: 18:36:44 - loss: 6.971 - ETA: 18:36:25 - loss: 6.971 - ETA: 18:36:07 - loss: 6.971 - ETA: 18:35:48 - loss: 6.971 - ETA: 18:35:28 - loss: 6.971 - ETA: 18:35:11 - loss: 6.971 - ETA: 18:34:52 - loss: 6.971 - ETA: 18:34:32 - loss: 6.970 - ETA: 18:34:13 - loss: 6.970 - ETA: 18:33:55 - loss: 6.970 - ETA: 18:33:36 - loss: 6.969 - ETA: 18:33:16 - loss: 6.970 - ETA: 18:32:58 - loss: 6.969 - ETA: 18:32:40 - loss: 6.970 - ETA: 18:32:22 - loss: 6.971 - ETA: 18:32:03 - loss: 6.971 - ETA: 18:31:45 - loss: 6.971 - ETA: 18:31:25 - loss: 6.972 - ETA: 18:31:06 - loss: 6.971 - ETA: 18:30:49 - loss: 6.970 - ETA: 18:30:30 - loss: 6.970 - ETA: 18:30:11 - loss: 6.970 - ETA: 18:29:53 - loss: 6.971 - ETA: 18:29:35 - loss: 6.971 - ETA: 18:29:16 - loss: 6.971 - ETA: 18:28:57 - loss: 6.971 - ETA: 18:28:40 - loss: 6.971 - ETA: 18:28:23 - loss: 6.970 - ETA: 18:28:03 - loss: 6.970 - ETA: 18:27:45 - loss: 6.970 - ETA: 18:27:28 - loss: 6.970 - ETA: 18:27:12 - loss: 6.970 - ETA: 18:26:53 - loss: 6.970 - ETA: 18:26:35 - loss: 6.969 - ETA: 18:26:17 - loss: 6.970 - ETA: 18:25:58 - loss: 6.971 - ETA: 18:25:39 - loss: 6.971 - ETA: 18:25:21 - loss: 6.971 - ETA: 18:25:03 - loss: 6.971 - ETA: 18:24:46 - loss: 6.971 - ETA: 18:24:33 - loss: 6.971 - ETA: 18:24:16 - loss: 6.971 - ETA: 18:23:57 - loss: 6.971 - ETA: 18:23:39 - loss: 6.970 - ETA: 18:23:21 - loss: 6.970 - ETA: 18:23:03 - loss: 6.970 - ETA: 18:22:44 - loss: 6.970 - ETA: 18:22:26 - loss: 6.970 - ETA: 18:22:09 - loss: 6.970 - ETA: 18:21:51 - loss: 6.970 - ETA: 18:21:33 - loss: 6.970 - ETA: 18:21:16 - loss: 6.970 - ETA: 18:20:59 - loss: 6.970 - ETA: 18:20:40 - loss: 6.970 - ETA: 18:20:21 - loss: 6.970 - ETA: 18:20:04 - loss: 6.969 - ETA: 18:19:48 - loss: 6.969 - ETA: 18:19:29 - loss: 6.968 - ETA: 18:19:11 - loss: 6.969 - ETA: 18:18:54 - loss: 6.969 - ETA: 18:18:35 - loss: 6.969 - ETA: 18:18:16 - loss: 6.969 - ETA: 18:17:59 - loss: 6.969 - ETA: 18:17:42 - loss: 6.970 - ETA: 18:17:24 - loss: 6.970 - ETA: 18:17:06 - loss: 6.970 - ETA: 18:16:48 - loss: 6.970 - ETA: 18:16:29 - loss: 6.970 - ETA: 18:16:10 - loss: 6.969 - ETA: 18:15:53 - loss: 6.969 - ETA: 18:15:36 - loss: 6.969 - ETA: 18:15:17 - loss: 6.968 - ETA: 18:14:59 - loss: 6.968 - ETA: 18:14:43 - loss: 6.968 - ETA: 18:14:24 - loss: 6.969 - ETA: 18:14:06 - loss: 6.969 - ETA: 18:13:49 - loss: 6.969 - ETA: 18:13:32 - loss: 6.969 - ETA: 18:13:13 - loss: 6.970 - ETA: 18:12:55 - loss: 6.969 - ETA: 18:12:38 - loss: 6.969 - ETA: 18:12:21 - loss: 6.970 - ETA: 18:12:02 - loss: 6.969 - ETA: 18:11:44 - loss: 6.970 - ETA: 18:11:27 - loss: 6.969 - ETA: 18:11:09 - loss: 6.970 - ETA: 18:10:50 - loss: 6.970 - ETA: 18:10:33 - loss: 6.969 - ETA: 18:10:16 - loss: 6.970 - ETA: 18:09:57 - loss: 6.970 - ETA: 18:09:40 - loss: 6.970 - ETA: 18:09:24 - loss: 6.970 - ETA: 18:09:06 - loss: 6.970 - ETA: 18:08:49 - loss: 6.970 - ETA: 18:08:33 - loss: 6.970 - ETA: 18:08:16 - loss: 6.970 - ETA: 18:07:58 - loss: 6.970 - ETA: 18:07:42 - loss: 6.969 - ETA: 18:07:26 - loss: 6.970 - ETA: 18:07:08 - loss: 6.969 - ETA: 18:06:50 - loss: 6.969 - ETA: 18:06:33 - loss: 6.969 - ETA: 18:06:16 - loss: 6.969 - ETA: 18:05:58 - loss: 6.969 - ETA: 18:05:40 - loss: 6.970 - ETA: 18:05:24 - loss: 6.9707"
     ]
    }
   ],
   "source": [
    "model.fit(x = [xtrain_pad, xtrain_companyName, xtrain_distributorName, xtrain_ageGroup, \\\n",
    "               xtrain_division, xtrain_gender, xtrain_group, xtrain_name4, xtrain_sportsCategory, \\\n",
    "               xtrain_subBrand] , y=ytrain_enc, batch_size=128, epochs=2, verbose=1, \n",
    "               validation_data=([xvalid_pad, xvalid_companyName, xvalid_distributorName, xvalid_ageGroup, \\\n",
    "                                 xvalid_division, xvalid_gender, xvalid_group, xvalid_name4, xvalid_sportsCategory, \\\n",
    "                                 xvalid_subBrand], yvalid_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Keras_model_Adam_BS128_V1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('Keras_model_Adam_BS128_V1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55381,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_company.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([xtest_pad, xtest_companyName, xtest_distributorName, xtest_ageGroup, \\\n",
    "                             xtest_division, xtest_gender, xtest_group, xtest_name4, xtest_sportsCategory, \\\n",
    "                             xtest_subBrand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = [np.argmax(i) for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\narendran.thesma\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "predict_label = lbl_enc.inverse_transform(predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\narendran.thesma\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "yvalid_label = lbl_enc.inverse_transform(yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({'description' : xvalid.description, 'actuals' : yvalid_label, 'predictions' : predict_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8347948792989917"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_df.actuals, test_df.predictions,average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8378290542736432"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_df.actuals, test_df.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
